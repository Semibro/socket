{
  
    
        "post0": {
            "title": "IAB딥러닝 10월 25일",
            "content": "Import . import torch import torchvision from fastai.vision.all import * . import os os.environ[&#39;KMP_DUPLICATE_LIB_OK&#39;] = &#39;True&#39; # plt.plot 오류 발생 시 사용 . import gc gc.collect() torch.cuda.empty_cache() . Transfer Learning . path = untar_data(URLs.CIFAR) . path.ls() . (#3) [Path(&#39;C:/Users/USER/.fastai/data/cifar10/labels.txt&#39;),Path(&#39;C:/Users/USER/.fastai/data/cifar10/test&#39;),Path(&#39;C:/Users/USER/.fastai/data/cifar10/train&#39;)] . &#49688;&#51228; &#45348;&#53944;&#50892;&#53356; . (1) dls . dls = ImageDataLoaders.from_folder(path, train = &#39;train&#39;, valid = &#39;test&#39;) . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `number_workers` is changed to 0 to avoid getting stuck . _X, _y = dls.one_batch() _X.shape, _y.shape . (torch.Size([64, 3, 32, 32]), torch.Size([64])) . dls.show_batch() . (2) lrnr . net1 = torch.nn.Sequential(torch.nn.Conv2d(3, 128, (5, 5)), torch.nn.ReLU(), torch.nn.MaxPool2d((2, 2)), torch.nn.Flatten()) . net1(_X.to(&quot;cpu&quot;)).shape . torch.Size([64, 25088]) . net = torch.nn.Sequential(net1, torch.nn.Linear(25088, 10)) loss_fn = torch.nn.CrossEntropyLoss() lrnr = Learner(dls, net, loss_fn, metrics = accuracy) . (3) &#54617;&#49845; . lrnr.fit(10) . epoch train_loss valid_loss accuracy time . 0 | 1.255423 | 1.237127 | 0.566300 | 00:50 | . 1 | 1.107240 | 1.141914 | 0.598900 | 00:48 | . 2 | 0.989954 | 1.069399 | 0.639700 | 00:48 | . 3 | 0.920135 | 1.054571 | 0.640000 | 00:48 | . 4 | 0.834212 | 1.025481 | 0.656600 | 00:48 | . 5 | 0.810602 | 1.131336 | 0.621600 | 00:48 | . 6 | 0.760466 | 1.064430 | 0.650700 | 00:48 | . 7 | 0.665804 | 1.088443 | 0.653300 | 00:48 | . 8 | 0.629648 | 1.087158 | 0.661800 | 00:48 | . 9 | 0.583727 | 1.148374 | 0.647400 | 00:48 | . &#51204;&#51060;&#54617;&#49845; (&#45224;&#51060; &#47564;&#46304; &#45348;&#53944;&#50892;&#53356;) . (2) lrnr . net = torchvision.models.resnet18(weights=torchvision.models.resnet.ResNet18_Weights.IMAGENET1K_V1) net . AttributeError Traceback (most recent call last) Input In [11], in &lt;cell line: 1&gt;() -&gt; 1 net = torchvision.models.resnet18(weights=torchvision.models.resnet.ResNet18_Weights.IMAGENET1K_V1) 2 net AttributeError: module &#39;torchvision.models.resnet&#39; has no attribute &#39;ResNet18_Weights&#39; . net.fc = torch.nn.Linear(in_features=512, out_features=10) . loss_fn = torch.nn.CrossEntropyLoss() lrnr = Learner(dls,net,loss_fn,metrics=accuracy) . lrnr.fit(10) . . 0.00% [0/10 00:00&lt;?] epoch train_loss valid_loss accuracy time . . 0.00% [0/781 00:00&lt;?] &lt;/div&gt; &lt;/div&gt; RuntimeError Traceback (most recent call last) Input In [14], in &lt;cell line: 1&gt;() -&gt; 1 lrnr.fit(10) File ~ anaconda3 lib site-packages fastai learner.py:256, in Learner.fit(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch) 254 self.opt.set_hypers(lr=self.lr if lr is None else lr) 255 self.n_epoch = n_epoch --&gt; 256 self._with_events(self._do_fit, &#39;fit&#39;, CancelFitException, self._end_cleanup) File ~ anaconda3 lib site-packages fastai learner.py:193, in Learner._with_events(self, f, event_type, ex, final) 192 def _with_events(self, f, event_type, ex, final=noop): --&gt; 193 try: self(f&#39;before_{event_type}&#39;); f() 194 except ex: self(f&#39;after_cancel_{event_type}&#39;) 195 self(f&#39;after_{event_type}&#39;); final() File ~ anaconda3 lib site-packages fastai learner.py:245, in Learner._do_fit(self) 243 for epoch in range(self.n_epoch): 244 self.epoch=epoch --&gt; 245 self._with_events(self._do_epoch, &#39;epoch&#39;, CancelEpochException) File ~ anaconda3 lib site-packages fastai learner.py:193, in Learner._with_events(self, f, event_type, ex, final) 192 def _with_events(self, f, event_type, ex, final=noop): --&gt; 193 try: self(f&#39;before_{event_type}&#39;); f() 194 except ex: self(f&#39;after_cancel_{event_type}&#39;) 195 self(f&#39;after_{event_type}&#39;); final() File ~ anaconda3 lib site-packages fastai learner.py:239, in Learner._do_epoch(self) 238 def _do_epoch(self): --&gt; 239 self._do_epoch_train() 240 self._do_epoch_validate() File ~ anaconda3 lib site-packages fastai learner.py:231, in Learner._do_epoch_train(self) 229 def _do_epoch_train(self): 230 self.dl = self.dls.train --&gt; 231 self._with_events(self.all_batches, &#39;train&#39;, CancelTrainException) File ~ anaconda3 lib site-packages fastai learner.py:193, in Learner._with_events(self, f, event_type, ex, final) 192 def _with_events(self, f, event_type, ex, final=noop): --&gt; 193 try: self(f&#39;before_{event_type}&#39;); f() 194 except ex: self(f&#39;after_cancel_{event_type}&#39;) 195 self(f&#39;after_{event_type}&#39;); final() File ~ anaconda3 lib site-packages fastai learner.py:199, in Learner.all_batches(self) 197 def all_batches(self): 198 self.n_iter = len(self.dl) --&gt; 199 for o in enumerate(self.dl): self.one_batch(*o) File ~ anaconda3 lib site-packages fastai learner.py:227, in Learner.one_batch(self, i, b) 225 b = self._set_device(b) 226 self._split(b) --&gt; 227 self._with_events(self._do_one_batch, &#39;batch&#39;, CancelBatchException) File ~ anaconda3 lib site-packages fastai learner.py:193, in Learner._with_events(self, f, event_type, ex, final) 192 def _with_events(self, f, event_type, ex, final=noop): --&gt; 193 try: self(f&#39;before_{event_type}&#39;); f() 194 except ex: self(f&#39;after_cancel_{event_type}&#39;) 195 self(f&#39;after_{event_type}&#39;); final() File ~ anaconda3 lib site-packages fastai learner.py:205, in Learner._do_one_batch(self) 204 def _do_one_batch(self): --&gt; 205 self.pred = self.model(*self.xb) 206 self(&#39;after_pred&#39;) 207 if len(self.yb): File ~ anaconda3 lib site-packages torch nn modules module.py:1110, in Module._call_impl(self, *input, **kwargs) 1106 # If we don&#39;t have any hooks, we want to skip the rest of the logic in 1107 # this function, and just call forward. 1108 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks 1109 or _global_forward_hooks or _global_forward_pre_hooks): -&gt; 1110 return forward_call(*input, **kwargs) 1111 # Do not call functions when jit is used 1112 full_backward_hooks, non_full_backward_hooks = [], [] File ~ anaconda3 lib site-packages torch nn modules container.py:141, in Sequential.forward(self, input) 139 def forward(self, input): 140 for module in self: --&gt; 141 input = module(input) 142 return input File ~ anaconda3 lib site-packages torch nn modules module.py:1110, in Module._call_impl(self, *input, **kwargs) 1106 # If we don&#39;t have any hooks, we want to skip the rest of the logic in 1107 # this function, and just call forward. 1108 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks 1109 or _global_forward_hooks or _global_forward_pre_hooks): -&gt; 1110 return forward_call(*input, **kwargs) 1111 # Do not call functions when jit is used 1112 full_backward_hooks, non_full_backward_hooks = [], [] File ~ anaconda3 lib site-packages torch nn modules linear.py:103, in Linear.forward(self, input) 102 def forward(self, input: Tensor) -&gt; Tensor: --&gt; 103 return F.linear(input, self.weight, self.bias) RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x10 and 512x10) . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; path = untar_data(URLs.PETS) / &#39;images&#39; . files = get_image_files(path) . def label_func(fname): if fname[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms = Resize(512)) . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `number_workers` is changed to 0 to avoid getting stuck . lrnr = vision_learner(dls, resnet34, metrics = accuracy) . lrnr.fine_tune(1) . epoch train_loss valid_loss accuracy time . 0 | 0.158030 | 0.024365 | 0.991881 | 01:43 | . epoch train_loss valid_loss accuracy time . 0 | 0.044585 | 0.028748 | 0.993234 | 02:05 | . lrnr.model . Sequential( (0): Sequential( (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (4): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (5): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (6): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (4): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (5): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (7): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) ) (1): Sequential( (0): AdaptiveConcatPool2d( (ap): AdaptiveAvgPool2d(output_size=1) (mp): AdaptiveMaxPool2d(output_size=1) ) (1): fastai.layers.Flatten(full=False) (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (3): Dropout(p=0.25, inplace=False) (4): Linear(in_features=1024, out_features=512, bias=False) (5): ReLU(inplace=True) (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): Dropout(p=0.5, inplace=False) (8): Linear(in_features=512, out_features=2, bias=False) ) ) . CAM . - Class Activation Mapping(CAM)은 설명가능한 인공지능모형 (eXplainable Artificial Intelligence, XAI) 중 하나로 CNN의 판단근거를 시각화하는 기술 . Data Load . path = untar_data(URLs.PETS) / &#39;images&#39; . path.ls() . (#7393) [Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.mat&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.mat&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_102.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_102.mat&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_103.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_104.jpg&#39;)...] . files = get_image_files(path) def label_func(fname): if fname[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . &#44396;&#54788; 0&#45800;&#44228; --&gt; &#50696;&#48708;&#54617;&#49845; . 하나의 이미지 선택 . ximg = PILImage.create(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;) ximg . x = first(dls.test_dl([ximg]))[0] x . TensorImage([[[[-1.1589, -1.1418, -1.1247, ..., -0.9020, -0.9363, -0.9534], [-1.1589, -1.1418, -1.1247, ..., -0.8849, -0.9192, -0.9363], [-1.1589, -1.1418, -1.1247, ..., -0.8849, -0.9020, -0.9192], ..., [-1.8439, -1.8439, -1.8439, ..., -1.7240, -1.7240, -1.7240], [-1.8439, -1.8439, -1.8439, ..., -1.7240, -1.7240, -1.7240], [-1.8439, -1.8610, -1.8610, ..., -1.7240, -1.7240, -1.7240]], [[-0.8627, -0.8452, -0.8277, ..., -0.6001, -0.6352, -0.6527], [-0.8627, -0.8452, -0.8277, ..., -0.5826, -0.6176, -0.6352], [-0.8627, -0.8452, -0.8277, ..., -0.5826, -0.6001, -0.6176], ..., [-1.6331, -1.6331, -1.6331, ..., -1.5280, -1.5280, -1.5280], [-1.6331, -1.6331, -1.6331, ..., -1.5280, -1.5280, -1.5280], [-1.6331, -1.6506, -1.6506, ..., -1.5280, -1.5280, -1.5280]], [[-0.9330, -0.9156, -0.8981, ..., -0.6715, -0.7064, -0.7238], [-0.9330, -0.9156, -0.8981, ..., -0.6541, -0.6890, -0.7064], [-0.9330, -0.9156, -0.8981, ..., -0.6541, -0.6715, -0.6890], ..., [-1.5430, -1.5430, -1.5430, ..., -1.4733, -1.4733, -1.4733], [-1.5430, -1.5430, -1.5430, ..., -1.4733, -1.4733, -1.4733], [-1.5430, -1.5604, -1.5604, ..., -1.4733, -1.4733, -1.4733]]]], device=&#39;cuda:0&#39;) . AP layer . ap = torch.nn.AdaptiveAvgPool2d(output_size = 1) . X = torch.arange(48).reshape(1, 3, 4, 4) * 1.0 X . tensor([[[[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.]], [[16., 17., 18., 19.], [20., 21., 22., 23.], [24., 25., 26., 27.], [28., 29., 30., 31.]], [[32., 33., 34., 35.], [36., 37., 38., 39.], [40., 41., 42., 43.], [44., 45., 46., 47.]]]]) . ap(X) . tensor([[[[ 7.5000]], [[23.5000]], [[39.5000]]]]) . X[0, 0, ...].mean(), X[0, 1, ...].mean(), X[0, 2, ...].mean() . (tensor(7.5000), tensor(23.5000), tensor(39.5000)) . torch.einsum . (예시 1) . tsr = torch.arange(12).reshape(4, 3) tsr . tensor([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]]) . torch.einsum(&#39;ij-&gt;ji&#39;, tsr) . tensor([[ 0, 3, 6, 9], [ 1, 4, 7, 10], [ 2, 5, 8, 11]]) . (예시 2) . tsr1 = torch.arange(12).reshape(4, 3).float() tsr2 = torch.arange(15).reshape(3, 5).float() . tsr1 @ tsr2 . tensor([[ 25., 28., 31., 34., 37.], [ 70., 82., 94., 106., 118.], [115., 136., 157., 178., 199.], [160., 190., 220., 250., 280.]]) . torch.einsum(&#39;ij, jk -&gt; ik&#39;, tsr1, tsr2) . tensor([[ 25., 28., 31., 34., 37.], [ 70., 82., 94., 106., 118.], [115., 136., 157., 178., 199.], [160., 190., 220., 250., 280.]]) . (예시 3) . x.to(&quot;cpu&quot;).shape . torch.Size([1, 3, 512, 512]) . torch.einsum(&#39;ocij -&gt; ijc&#39;, x.to(&quot;cpu&quot;)).shape . torch.Size([512, 512, 3]) . plt.imshow(torch.einsum(&#39;ocij -&gt; ijc&#39;, x.to(&#39;cpu&#39;))) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . &lt;matplotlib.image.AxesImage at 0x1d66d80e5b0&gt; . &#44396;&#54788; 1&#45800;&#44228; --&gt; &#51060;&#48120;&#51648;&#48516;&#47448; &#51096;&#54616;&#45716; &#45348;&#53944;&#50892;&#53356; &#49440;&#53469; . lrnr = vision_learner(dls, resnet34, metrics = accuracy) . lrnr.fine_tune(1) . epoch train_loss valid_loss accuracy time . 0 | 0.169289 | 0.034462 | 0.989175 | 01:34 | . epoch train_loss valid_loss accuracy time . 0 | 0.050309 | 0.018232 | 0.995940 | 02:10 | . &#44396;&#54788; 2&#45800;&#44228; --&gt; &#45348;&#53944;&#50892;&#53356;&#51032; &#45149; &#48512;&#48516; &#49688;&#51221; . net1 = lrnr.model[0] net2 = lrnr.model[1] . net2 . Sequential( (0): AdaptiveConcatPool2d( (ap): AdaptiveAvgPool2d(output_size=1) (mp): AdaptiveMaxPool2d(output_size=1) ) (1): fastai.layers.Flatten(full=False) (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (3): Dropout(p=0.25, inplace=False) (4): Linear(in_features=1024, out_features=512, bias=False) (5): ReLU(inplace=True) (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): Dropout(p=0.5, inplace=False) (8): Linear(in_features=512, out_features=2, bias=False) ) . _X, _y = dls.one_batch() . net1.to(&#39;cpu&#39;) net2.to(&#39;cpu&#39;) _X = _X.to(&#39;cpu&#39;) . print(net1(_X).shape) print(net2[0](net1(_X)).shape) print(net2[1](net2[0](net1(_X))).shape) print(net2[2](net2[1](net2[0](net1(_X)))).shape) . torch.Size([64, 512, 16, 16]) torch.Size([64, 1024, 1, 1]) torch.Size([64, 1024]) torch.Size([64, 1024]) . - net2를 아래와 같이 수정하고 재학습 . net2 = torch.nn.Sequential(torch.nn.AdaptiveAvgPool2d(output_size = 1), torch.nn.Flatten(), torch.nn.Linear(512, 2, bias = False)) . net = torch.nn.Sequential(net1, net2) . lrnr2 = Learner(dls, net, metrics = accuracy) . lrnr2.loss_func, lrnr.loss_func . (FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss()) . lrnr2.fine_tune(5) . . 0.00% [0/1 00:00&lt;?] epoch train_loss valid_loss accuracy time . . 0.00% [0/92 00:00&lt;?] &lt;/div&gt; &lt;/div&gt; RuntimeError Traceback (most recent call last) Input In [57], in &lt;cell line: 1&gt;() -&gt; 1 lrnr2.fine_tune(5) File ~ anaconda3 lib site-packages fastai callback schedule.py:165, in fine_tune(self, epochs, base_lr, freeze_epochs, lr_mult, pct_start, div, **kwargs) 163 &#34;Fine tune with `Learner.freeze` for `freeze_epochs`, then with `Learner.unfreeze` for `epochs`, using discriminative LR.&#34; 164 self.freeze() --&gt; 165 self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs) 166 base_lr /= 2 167 self.unfreeze() File ~ anaconda3 lib site-packages fastai callback schedule.py:119, in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch) 116 lr_max = np.array([h[&#39;lr&#39;] for h in self.opt.hypers]) 117 scheds = {&#39;lr&#39;: combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final), 118 &#39;mom&#39;: combined_cos(pct_start, *(self.moms if moms is None else moms))} --&gt; 119 self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch) File ~ anaconda3 lib site-packages fastai learner.py:256, in Learner.fit(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch) 254 self.opt.set_hypers(lr=self.lr if lr is None else lr) 255 self.n_epoch = n_epoch --&gt; 256 self._with_events(self._do_fit, &#39;fit&#39;, CancelFitException, self._end_cleanup) File ~ anaconda3 lib site-packages fastai learner.py:193, in Learner._with_events(self, f, event_type, ex, final) 192 def _with_events(self, f, event_type, ex, final=noop): --&gt; 193 try: self(f&#39;before_{event_type}&#39;); f() 194 except ex: self(f&#39;after_cancel_{event_type}&#39;) 195 self(f&#39;after_{event_type}&#39;); final() File ~ anaconda3 lib site-packages fastai learner.py:245, in Learner._do_fit(self) 243 for epoch in range(self.n_epoch): 244 self.epoch=epoch --&gt; 245 self._with_events(self._do_epoch, &#39;epoch&#39;, CancelEpochException) File ~ anaconda3 lib site-packages fastai learner.py:193, in Learner._with_events(self, f, event_type, ex, final) 192 def _with_events(self, f, event_type, ex, final=noop): --&gt; 193 try: self(f&#39;before_{event_type}&#39;); f() 194 except ex: self(f&#39;after_cancel_{event_type}&#39;) 195 self(f&#39;after_{event_type}&#39;); final() File ~ anaconda3 lib site-packages fastai learner.py:239, in Learner._do_epoch(self) 238 def _do_epoch(self): --&gt; 239 self._do_epoch_train() 240 self._do_epoch_validate() File ~ anaconda3 lib site-packages fastai learner.py:231, in Learner._do_epoch_train(self) 229 def _do_epoch_train(self): 230 self.dl = self.dls.train --&gt; 231 self._with_events(self.all_batches, &#39;train&#39;, CancelTrainException) File ~ anaconda3 lib site-packages fastai learner.py:193, in Learner._with_events(self, f, event_type, ex, final) 192 def _with_events(self, f, event_type, ex, final=noop): --&gt; 193 try: self(f&#39;before_{event_type}&#39;); f() 194 except ex: self(f&#39;after_cancel_{event_type}&#39;) 195 self(f&#39;after_{event_type}&#39;); final() File ~ anaconda3 lib site-packages fastai learner.py:199, in Learner.all_batches(self) 197 def all_batches(self): 198 self.n_iter = len(self.dl) --&gt; 199 for o in enumerate(self.dl): self.one_batch(*o) File ~ anaconda3 lib site-packages fastai data load.py:133, in DataLoader.__iter__(self) 131 if self.pin_memory and type(b) == list: b = tuple(b) 132 if self.device is not None: b = to_device(b, self.device) --&gt; 133 yield self.after_batch(b) 134 self.after_iter() 135 if hasattr(self, &#39;it&#39;): del(self.it) File ~ anaconda3 lib site-packages fastcore transform.py:208, in Pipeline.__call__(self, o) --&gt; 208 def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx) File ~ anaconda3 lib site-packages fastcore transform.py:158, in compose_tfms(x, tfms, is_enc, reverse, **kwargs) 156 for f in tfms: 157 if not is_enc: f = f.decode --&gt; 158 x = f(x, **kwargs) 159 return x File ~ anaconda3 lib site-packages fastcore transform.py:81, in Transform.__call__(self, x, **kwargs) 79 @property 80 def name(self): return getattr(self, &#39;_name&#39;, _get_name(self)) &gt; 81 def __call__(self, x, **kwargs): return self._call(&#39;encodes&#39;, x, **kwargs) 82 def decode (self, x, **kwargs): return self._call(&#39;decodes&#39;, x, **kwargs) 83 def __repr__(self): return f&#39;{self.name}: nencodes: {self.encodes}decodes: {self.decodes}&#39; File ~ anaconda3 lib site-packages fastcore transform.py:91, in Transform._call(self, fn, x, split_idx, **kwargs) 89 def _call(self, fn, x, split_idx=None, **kwargs): 90 if split_idx!=self.split_idx and self.split_idx is not None: return x &gt; 91 return self._do_call(getattr(self, fn), x, **kwargs) File ~ anaconda3 lib site-packages fastcore transform.py:98, in Transform._do_call(self, f, x, **kwargs) 96 ret = f.returns(x) if hasattr(f,&#39;returns&#39;) else None 97 return retain_type(f(x, **kwargs), x, ret) &gt; 98 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x) 99 return retain_type(res, x) File ~ anaconda3 lib site-packages fastcore transform.py:98, in &lt;genexpr&gt;(.0) 96 ret = f.returns(x) if hasattr(f,&#39;returns&#39;) else None 97 return retain_type(f(x, **kwargs), x, ret) &gt; 98 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x) 99 return retain_type(res, x) File ~ anaconda3 lib site-packages fastcore transform.py:97, in Transform._do_call(self, f, x, **kwargs) 95 if f is None: return x 96 ret = f.returns(x) if hasattr(f,&#39;returns&#39;) else None &gt; 97 return retain_type(f(x, **kwargs), x, ret) 98 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x) 99 return retain_type(res, x) File ~ anaconda3 lib site-packages fastcore dispatch.py:120, in TypeDispatch.__call__(self, *args, **kwargs) 118 elif self.inst is not None: f = MethodType(f, self.inst) 119 elif self.owner is not None: f = MethodType(f, self.owner) --&gt; 120 return f(*args, **kwargs) File ~ anaconda3 lib site-packages fastai data transforms.py:377, in Normalize.encodes(self, x) --&gt; 377 def encodes(self, x:TensorImage): return (x-self.mean) / self.std File ~ anaconda3 lib site-packages fastai torch_core.py:376, in TensorBase.__torch_function__(cls, func, types, args, kwargs) 374 if cls.debug and func.__name__ not in (&#39;__str__&#39;,&#39;__repr__&#39;): print(func, types, args, kwargs) 375 if _torch_handled(args, cls._opt, func): types = (torch.Tensor,) --&gt; 376 res = super().__torch_function__(func, types, args, ifnone(kwargs, {})) 377 dict_objs = _find_args(args) if args else _find_args(list(kwargs.values())) 378 if issubclass(type(res),TensorBase) and dict_objs: res.set_meta(dict_objs[0],as_copy=True) File ~ anaconda3 lib site-packages torch _tensor.py:1142, in Tensor.__torch_function__(cls, func, types, args, kwargs) 1139 return NotImplemented 1141 with _C.DisableTorchFunction(): -&gt; 1142 ret = func(*args, **kwargs) 1143 if func in get_default_nowrap_functions(): 1144 return ret RuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 12.00 GiB total capacity; 10.81 GiB already allocated; 0 bytes free; 11.29 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation. See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &#44396;&#54788; 3&#45800;&#44228; --&gt; &#49688;&#51221;&#46108; net2&#50640;&#49436; Linear&#50752; AP&#51032; &#49692;&#49436;&#47484; &#48148;&#45000; . - 1개의 observation을 고정하였을 경우 출력과정 상상 . ximg = PILImage.create(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;) x = first(dls.test_dl([ximg]))[0] . net2 . Sequential( (0): AdaptiveAvgPool2d(output_size=1) (1): Flatten(start_dim=1, end_dim=-1) (2): Linear(in_features=512, out_features=2, bias=False) ) . print(net1(x).shape) print(net2[0](net1(x)).shape) print(net2[1](net2[0](net1(x))).shape) print(net2[2](net2[1](net2[0](net1(x)))).shape) . torch.Size([1, 512, 16, 16]) torch.Size([1, 512, 1, 1]) torch.Size([1, 512]) torch.Size([1, 2]) . - 최종결과 확인 . net(x) . TensorImage([[0.3050, 0.9786]], device=&#39;cuda:0&#39;, grad_fn=&lt;AliasBackward0&gt;) . dls.vocab . [&#39;cat&#39;, &#39;dog&#39;] . net(x)에서 뒤쪽의 값이 클수록 &#39;dog&#39;를 의미한다. . _x = torch.tensor([1, 2, 3.14, 4]).reshape(4, 1) _x . tensor([[1.0000], [2.0000], [3.1400], [4.0000]]) . _l1 = torch.nn.Linear(1, 1, bias = False) _l1(_x).mean() . tensor(-0.0184, grad_fn=&lt;MeanBackward0&gt;) . _l1(_x.mean().reshape(1, 1)) . tensor([[-0.0184]], grad_fn=&lt;MmBackward0&gt;) . - https://guebin.github.io/DL2022/2022/10/25/(8%EC%A3%BC%EC%B0%A8)-10%EC%9B%9425%EC%9D%BC.html . &#44396;&#54788; 4&#45800;&#44228; --&gt; CAM &#49884;&#44033;&#54868; . - https://guebin.github.io/DL2022/2022/10/25/(8%EC%A3%BC%EC%B0%A8)-10%EC%9B%9425%EC%9D%BC.html . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. . &lt;/div&gt; .",
            "url": "https://semibro.github.io/socket/2022/10/25/IABDL.html",
            "relUrl": "/2022/10/25/IABDL.html",
            "date": " • Oct 25, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "IAB딥러닝 10월 20일",
            "content": "Import . import torch import torchvision import numpy as np import pandas as pd from fastai.vision.all import * . import os os.environ[&#39;KMP_DUPLICATE_LIB_OK&#39;] = &#39;True&#39; # plt.plot 오류 발생 시 사용 . CNN &#45796;&#51473;&#53364;&#47000;&#49828; &#48516;&#47448; . - 2개의 class를 구분하는 문제가 아니라 $k$개의 class를 구분해야 한다면? . 일반적인 개념 . 손실함수: BCE loss $ to$ Cross Entropy loss | 마지막층의 선형변환: torch.nn.Linear(?,1) $ to$ torch.nn.Linear(?,k) | 마지막층의 활성화: sig $ to$ softmax | . 파이토치 한정 . y의형태: (n,) vector + int형 // (n,k) one-hot encoded vector + float형 | 손실함수: torch.nn.BCEWithLogitsLoss, $ to$ torch.nn.CrossEntropyLoss | 마지막층의 선형변환: torch.nn.Linear(?,1) $ to$ torch.nn.Linear(?,k) | 마지막층의 활성화: None $ to$ None (손실함수에 이미 마지막층의 활성화가 포함) | . &#49892;&#49845; : 3&#44060;&#51032; &#53364;&#47000;&#49828; &#48516;&#47448; . path = untar_data(URLs.MNIST) . training set . X0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;training/0&#39;).ls()]) X1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;training/1&#39;).ls()]) X2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;training/2&#39;).ls()]) X = torch.concat([X0, X1, X2]) / 255 y = torch.tensor([0] * len(X0) + [1] * len(X1) + [2] * len(X2)) . test set . X0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;testing/0&#39;).ls()]) X1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;testing/1&#39;).ls()]) X2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;testing/2&#39;).ls()]) XX = torch.concat([X0, X1, X2]) / 255 yy = torch.tensor([0] * len(X0) + [1] * len(X1) + [2] * len(X2)) . (1) dls . len(X) . 18623 . ds1 = torch.utils.data.TensorDataset(X, y) ds2 = torch.utils.data.TensorDataset(XX, yy) dl1 = torch.utils.data.DataLoader(ds1, batch_size = 1862) dl2 = torch.utils.data.DataLoader(ds2, batch_size = 3147) dls = DataLoaders(dl1, dl2) . (2) lrnr . net1 = torch.nn.Sequential(torch.nn.Conv2d(1, 16, (5, 5)), torch.nn.ReLU(), torch.nn.MaxPool2d((2, 2)), torch.nn.Flatten()) . net1(X).shape . torch.Size([18623, 2304]) . net = torch.nn.Sequential(net1, torch.nn.Linear(2304, 3)) loss_fn = torch.nn.CrossEntropyLoss() . lrnr = Learner(dls, net, loss_fn) . (3) 학습 . lrnr.fit(10) . epoch train_loss valid_loss time . 0 | 1.998352 | 1.096370 | 00:03 | . 1 | 1.286857 | 0.791879 | 00:00 | . 2 | 1.070620 | 0.602117 | 00:00 | . 3 | 0.913583 | 0.393290 | 00:00 | . 4 | 0.753681 | 0.268544 | 00:00 | . 5 | 0.615242 | 0.192265 | 00:00 | . 6 | 0.507522 | 0.143655 | 00:00 | . 7 | 0.420787 | 0.115706 | 00:00 | . 8 | 0.350857 | 0.098498 | 00:00 | . 9 | 0.295269 | 0.086593 | 00:00 | . (4) 예측 . lrnr.model.to(&quot;cpu&quot;) . Sequential( (0): Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): ReLU() (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False) (3): Flatten(start_dim=1, end_dim=-1) ) (1): Linear(in_features=2304, out_features=3, bias=True) ) . pd.DataFrame(lrnr.model(XX)).assign(y = yy) . 0 1 2 y . 0 1.880104 | -8.130291 | -2.155231 | 0 | . 1 0.882850 | -5.683725 | -2.126705 | 0 | . 2 0.742812 | -7.474946 | -0.841271 | 0 | . 3 2.357132 | -6.710110 | -2.852508 | 0 | . 4 1.636409 | -5.533461 | -3.147410 | 0 | . ... ... | ... | ... | ... | . 3142 -4.796888 | -3.905260 | 1.608442 | 2 | . 3143 -2.279605 | -4.870659 | 0.497556 | 2 | . 3144 -1.890238 | -10.070328 | 0.080740 | 2 | . 3145 -3.218306 | -3.560711 | -0.304087 | 2 | . 3146 -4.813123 | -6.452925 | 2.033028 | 2 | . 3147 rows × 4 columns . pd.DataFrame(lrnr.model(XX)).assign(y = yy).query(&#39;y == 0&#39;) . 0 1 2 y . 0 1.880104 | -8.130291 | -2.155231 | 0 | . 1 0.882850 | -5.683725 | -2.126705 | 0 | . 2 0.742812 | -7.474946 | -0.841271 | 0 | . 3 2.357132 | -6.710110 | -2.852508 | 0 | . 4 1.636409 | -5.533461 | -3.147410 | 0 | . ... ... | ... | ... | ... | . 975 1.181577 | -5.826284 | -3.273248 | 0 | . 976 0.435502 | -4.586772 | -2.713910 | 0 | . 977 3.316375 | -8.905706 | -4.568169 | 0 | . 978 3.601776 | -9.048151 | -4.483949 | 0 | . 979 1.933877 | -8.669778 | -4.297437 | 0 | . 980 rows × 4 columns . pd.DataFrame(lrnr.model(XX)).assign(y = yy).query(&#39;y == 1&#39;) . 0 1 2 y . 980 -2.790916 | 1.241377 | -1.840055 | 1 | . 981 -3.233022 | 2.085936 | -1.834126 | 1 | . 982 -3.817043 | 2.344917 | -1.858202 | 1 | . 983 -3.476404 | 2.238732 | -1.470501 | 1 | . 984 -3.451838 | 2.623547 | -1.567843 | 1 | . ... ... | ... | ... | ... | . 2110 -3.838306 | 1.574727 | -0.634061 | 1 | . 2111 -3.700799 | 2.149787 | -1.270558 | 1 | . 2112 -4.055466 | 1.615760 | -0.832332 | 1 | . 2113 -3.835481 | 2.485970 | -1.766641 | 1 | . 2114 -4.225008 | 2.728808 | -1.291302 | 1 | . 1135 rows × 4 columns . pd.DataFrame(lrnr.model(XX)).assign(y = yy).query(&#39;y == 2&#39;) . 0 1 2 y . 2115 -3.230768 | -4.466066 | 0.509366 | 2 | . 2116 -4.079887 | -1.475066 | 0.055470 | 2 | . 2117 -2.693914 | -4.778261 | 1.142449 | 2 | . 2118 -3.897048 | -4.479739 | 1.732418 | 2 | . 2119 -4.540510 | -3.486542 | 1.109208 | 2 | . ... ... | ... | ... | ... | . 3142 -4.796888 | -3.905260 | 1.608442 | 2 | . 3143 -2.279605 | -4.870659 | 0.497556 | 2 | . 3144 -1.890238 | -10.070328 | 0.080740 | 2 | . 3145 -3.218306 | -3.560711 | -0.304087 | 2 | . 3146 -4.813123 | -6.452925 | 2.033028 | 2 | . 1032 rows × 4 columns . - 예측하는 방법 . 칼럼0의 숫자가 크다 --&gt; y = 0일 확률이 크다. . | 칼럼1의 숫자가 크다 --&gt; y = 1일 확률이 크다. . | 칼럼2의 숫자가 크다 --&gt; y = 2일 확률이 크다. . | . Softmax . - torch.nn.Softmax() 손 계산 . (예시 1) 잘못된 계산 . sftmx = torch.nn.Softmax(dim = 0) . _netout = torch.tensor([[-2.0, -2.0, 0.0], [3.14, 3.14, 3.14], [0.0, 0.0, 2.0], [2.0, 2.0, 4.0], [0.0, 0.0, 0.0]]) _netout . tensor([[-2.0000, -2.0000, 0.0000], [ 3.1400, 3.1400, 3.1400], [ 0.0000, 0.0000, 2.0000], [ 2.0000, 2.0000, 4.0000], [ 0.0000, 0.0000, 0.0000]]) . sftmx(_netout) . tensor([[0.0041, 0.0041, 0.0115], [0.7081, 0.7081, 0.2653], [0.0306, 0.0306, 0.0848], [0.2265, 0.2265, 0.6269], [0.0306, 0.0306, 0.0115]]) . (예시 2) 제대로 된 계산 . sftmx = torch.nn.Softmax(dim = 1) . _netout . tensor([[-2.0000, -2.0000, 0.0000], [ 3.1400, 3.1400, 3.1400], [ 0.0000, 0.0000, 2.0000], [ 2.0000, 2.0000, 4.0000], [ 0.0000, 0.0000, 0.0000]]) . sftmx(_netout) . tensor([[0.1065, 0.1065, 0.7870], [0.3333, 0.3333, 0.3333], [0.1065, 0.1065, 0.7870], [0.1065, 0.1065, 0.7870], [0.3333, 0.3333, 0.3333]]) . (예시 3) 차원을 명시안하면 맞게 계산해주고 경고를 줌 . sftmx = torch.nn.Softmax() . _netout . tensor([[-2.0000, -2.0000, 0.0000], [ 3.1400, 3.1400, 3.1400], [ 0.0000, 0.0000, 2.0000], [ 2.0000, 2.0000, 4.0000], [ 0.0000, 0.0000, 0.0000]]) . sftmx(_netout) . C: Users Public Documents ESTsoft CreatorTemp ipykernel_15092 3694084616.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument. sftmx(_netout) . tensor([[0.1065, 0.1065, 0.7870], [0.3333, 0.3333, 0.3333], [0.1065, 0.1065, 0.7870], [0.1065, 0.1065, 0.7870], [0.3333, 0.3333, 0.3333]]) . (예시 4) 손 계산 . _netout . tensor([[-2.0000, -2.0000, 0.0000], [ 3.1400, 3.1400, 3.1400], [ 0.0000, 0.0000, 2.0000], [ 2.0000, 2.0000, 4.0000], [ 0.0000, 0.0000, 0.0000]]) . torch.exp(_netout) . tensor([[ 0.1353, 0.1353, 1.0000], [23.1039, 23.1039, 23.1039], [ 1.0000, 1.0000, 7.3891], [ 7.3891, 7.3891, 54.5981], [ 1.0000, 1.0000, 1.0000]]) . 0.1353 / (0.1353 + 0.1353 + 1.0000), 0.1353 / (0.1353 + 0.1353 + 1.0000), 1.0000 / (0.1353 + 0.1353 + 1.0000) . (0.10648512513773022, 0.10648512513773022, 0.7870297497245397) . np.exp(_netout[1]) / np.exp(_netout[1]).sum() . tensor([0.3333, 0.3333, 0.3333]) . np.apply_along_axis(lambda x : np.exp(x) / np.exp(x).sum(), 1, _netout) . array([[0.10650698, 0.10650698, 0.78698605], [0.33333334, 0.33333334, 0.33333334], [0.10650699, 0.10650699, 0.78698605], [0.10650698, 0.10650698, 0.78698605], [0.33333334, 0.33333334, 0.33333334]], dtype=float32) . CrossEntropyLoss . - torch.nn.CrossEntropyLoss() 손계산 : one-hot version . loss_fn = torch.nn.CrossEntropyLoss() . _netout . tensor([[-2.0000, -2.0000, 0.0000], [ 3.1400, 3.1400, 3.1400], [ 0.0000, 0.0000, 2.0000], [ 2.0000, 2.0000, 4.0000], [ 0.0000, 0.0000, 0.0000]]) . _y_onehot = torch.tensor([[0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0]]) * 1.0 _y_onehot . tensor([[0., 0., 1.], [0., 1., 0.], [0., 0., 1.], [0., 0., 1.], [1., 0., 0.]]) . sftmx = torch.nn.Softmax(dim = 1) sftmx(_netout), _y_onehot . (tensor([[0.1065, 0.1065, 0.7870], [0.3333, 0.3333, 0.3333], [0.1065, 0.1065, 0.7870], [0.1065, 0.1065, 0.7870], [0.3333, 0.3333, 0.3333]]), tensor([[0., 0., 1.], [0., 1., 0.], [0., 0., 1.], [0., 0., 1.], [1., 0., 0.]])) . - 계산결과 . loss_fn(_netout, _y_onehot) . tensor(0.5832) . - torch.sum(torch.log(sftmx(_netout)) * _y_onehot) / 5 . tensor(0.5832) . - 계산하는 방법도 중요하지만 torch.nn.CrossEntropyLoss()에는 softmax 활성화함수가 이미 포함되어 있다는 것을 확인하는 것이 중요함. . - torch.nn.CrossEntropyLoss() 손계산: lenght $n$ vertor version . _netout . tensor([[-2.0000, -2.0000, 0.0000], [ 3.1400, 3.1400, 3.1400], [ 0.0000, 0.0000, 2.0000], [ 2.0000, 2.0000, 4.0000], [ 0.0000, 0.0000, 0.0000]]) . _y = torch.tensor([2, 1, 2, 2, 0]) . loss_fn(_netout, _y) . tensor(0.5832) . $k=2$&#47196; &#46160;&#47732; &#51060;&#51652;&#48516;&#47448;&#46020; &#44032;&#45733; . path = untar_data(URLs.MNIST) . training . X0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;training/0&#39;).ls()]) X1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;training/1&#39;).ls()]) X = torch.concat([X0, X1]) / 255 y = torch.tensor([0] * len(X0) + [1] * len(X1)) . y_onehot = torch.nn.functional.one_hot(y).float() . test . X0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;testing/0&#39;).ls()]) X1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;testing/1&#39;).ls()]) XX = torch.concat([X0, X1]) / 255 yy = torch.tensor([0] * len(X0) + [1] * len(X1)) . yy_onehot = torch.nn.functional.one_hot(yy).float() . dls . ds1 = torch.utils.data.TensorDataset(X, y_onehot) ds2 = torch.utils.data.TensorDataset(XX, yy_onehot) dl1 = torch.utils.data.DataLoader(ds1, batch_size = 1862) dl2 = torch.utils.data.DataLoader(ds2, batch_size = 3147) dls = DataLoaders(dl1, dl2) . lrnr . net = torch.nn.Sequential(torch.nn.Conv2d(1, 16, (5, 5)), torch.nn.ReLU(), torch.nn.MaxPool2d((2, 2)), torch.nn.Flatten(), torch.nn.Linear(2304, 2)) loss_fn = torch.nn.CrossEntropyLoss() lrnr = Learner(dls, net, loss_fn) . 학습 . lrnr.fit(10) . epoch train_loss valid_loss time . 0 | 1.005429 | 0.688885 | 00:00 | . 1 | 0.720879 | 0.388335 | 00:00 | . 2 | 0.558736 | 0.255074 | 00:00 | . 3 | 0.453830 | 0.151560 | 00:00 | . 4 | 0.370357 | 0.087234 | 00:00 | . 5 | 0.303530 | 0.055274 | 00:00 | . 6 | 0.251096 | 0.038038 | 00:00 | . 7 | 0.209842 | 0.027843 | 00:00 | . 8 | 0.177048 | 0.021517 | 00:00 | . 9 | 0.150642 | 0.017311 | 00:00 | . 예측 및 시각화 . lrnr.model.to(&quot;cpu&quot;) . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): ReLU() (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False) (3): Flatten(start_dim=1, end_dim=-1) (4): Linear(in_features=2304, out_features=2, bias=True) ) . sftmx = torch.nn.Softmax(dim = 1) sig = torch.nn.Sigmoid() fig, ax = plt.subplots(1, 2, figsize = (8, 4)) ax[0].plot(net(X).diff(axis = 1).data, &#39;,&#39;, color = &quot;C1&quot;) ax[1].plot(y) ax[1].plot(sftmx(net(X))[:,1].data, &#39;,&#39;) fig.suptitle(&quot;Training Set&quot;, size = 15) . Text(0.5, 0.98, &#39;Training Set&#39;) . fig, ax = plt.subplots(1, 2, figsize = (8, 4)) ax[0].plot(net(XX).diff(axis = 1).data, &#39;,&#39;, color = &quot;C1&quot;) ax[1].plot(yy) ax[1].plot(sftmx(net(XX))[:,1].data, &#39;,&#39;) fig.suptitle(&quot;Test Set&quot;, size = 15) . Text(0.5, 0.98, &#39;Test Set&#39;) . - note: softmax(u1,u2)=[sig(u1-u2), sig(u2-u1)]=[1-sig(u2-u1),sig(u2-u1)] . &#51060;&#51652;&#48516;&#47448;&#50640;&#49436; Softmax vs Sigmoid . - 이진분류문제 = &quot;y=0 or y=1&quot; 을 맞추는 문제 = 성공과 실패를 맞추는 문제 = 성공확률과 실패확률을 추정하는 문제 . - softmax, sigmoid . softmax: (실패확률, 성공확률) 꼴로 결과가 나옴 // softmax는 실패확률과 성공확률을 둘다 추정한다. | sigmoid: (성공확률) 꼴로 결과가 나옴 // sigmoid는 성공확률만 추정한다. | . - 그런데 &quot;실패확률=1-성공확률&quot; 이므로 사실상 둘은 같은걸 추정하는 셈이다. (성공확률만 추정하면 실패확률은 저절로 추정되니까) . - 둘은 사실상 같은 효과를 주는 모형인데 학습할 파라메터는 sigmoid의 경우가 더 적다. $ to$ sigmoid를 사용하는 모형이 비용은 싸고 효과는 동일하다는 말 $ to$ 이진분류 한정해서는 softmax를 쓰지말고 sigmoid를 써야함. . softmax가 갑자기 너무 안좋아보이는데 sigmoid는 k개의 클래스로 확장이 불가능한 반면 softmax는 확장이 용이하다는 장점이 있음 | . Softmax vs Sigmoid &#51221;&#47532; . - 결론 . 소프트맥스는 시그모이드의 확장이다. | 클래스의 수가 2개일 경우에는 (Sigmoid, BCEloss) 조합을 사용해야 하고 클래스의 수가 2개보다 클 경우에는 (Softmax, CrossEntropyLoss) 를 사용해야 한다. | - 그런데 사실.. 클래스의 수가 2개일 경우일때 (Softmax, CrossEntropyLoss)를 사용해도 그렇게 큰일나는것은 아니다. (흑백이미지를 칼라잉크로 출력하는 느낌) . 참고 . $y$ 분포가정 마지막층의 활성화함수 손실함수 . 3.45, 4.43, ... (연속형) | 정규분포 | None (or Identity) | MSE | . 0 or 1 | 이항분포 with $n=1$ (=베르누이) | Sigmoid | BCE | . [0,0,1], [0,1,0], [1,0,0] | 다항분포 with $n=1$ | Softmax | Cross Entropy | . fastai metric &#49324;&#50857; . &#45936;&#51060;&#53552; &#51456;&#48708; . download data . path = untar_data(URLs.MNIST) . training set . X0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;training/0&#39;).ls()]) X1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;training/1&#39;).ls()]) X = torch.concat([X0, X1]) / 255 y = torch.tensor([0.0] * len(X0) + [1.0] * len(X1)).reshape(-1, 1) . test set . X0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;testing/0&#39;).ls()]) X1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;testing/1&#39;).ls()]) XX = torch.concat([X0, X1]) / 255 yy = torch.tensor([0.0] * len(X0) + [1.0] * len(X1)).reshape(-1, 1) . X.shape, XX.shape, y.shape, yy.shape . (torch.Size([12665, 1, 28, 28]), torch.Size([2115, 1, 28, 28]), torch.Size([12665, 1]), torch.Size([2115, 1])) . &#49324;&#50857;&#51088;&#51221;&#51032; &#47700;&#53944;&#47533;&#51060;&#50857; . (1) dls &#47564;&#46308;&#44592; . ds1 = torch.utils.data.TensorDataset(X, y) ds2 = torch.utils.data.TensorDataset(XX, yy) dl1 = torch.utils.data.DataLoader(ds1, batch_size = 1266) dl2 = torch.utils.data.DataLoader(ds2, batch_size = 2115) dls = DataLoaders(dl1, dl2) . (2) lrnr &#49373;&#49457; . net = torch.nn.Sequential(torch.nn.Conv2d(1, 16, (5, 5)), torch.nn.ReLU(), torch.nn.MaxPool2d((2, 2)), torch.nn.Flatten(), torch.nn.Linear(2304, 1), torch.nn.Sigmoid()) loss_fn = torch.nn.BCELoss() . def acc(yhat,y) : return ((yhat&gt;0.5)==y).float().mean() . def err(yhat,y): return 1-((yhat&gt;0.5)==y).float().mean() . lrnr = Learner(dls,net,loss_fn,metrics=[acc,err]) . (3) &#54617;&#49845; . lrnr.fit(10) . epoch train_loss valid_loss acc err time . 0 | 0.964475 | 0.660463 | 0.463357 | 0.536643 | 00:02 | . 1 | 0.721056 | 0.443165 | 0.996217 | 0.003783 | 00:00 | . 2 | 0.571983 | 0.286030 | 0.991962 | 0.008038 | 00:00 | . 3 | 0.456581 | 0.158378 | 0.992435 | 0.007565 | 00:00 | . 4 | 0.359557 | 0.086864 | 0.994799 | 0.005201 | 00:00 | . 5 | 0.282681 | 0.053276 | 0.995745 | 0.004255 | 00:00 | . 6 | 0.223957 | 0.036654 | 0.995745 | 0.004255 | 00:00 | . 7 | 0.179251 | 0.027493 | 0.995745 | 0.004255 | 00:00 | . 8 | 0.144889 | 0.021843 | 0.996217 | 0.003783 | 00:00 | . 9 | 0.118145 | 0.018024 | 0.997636 | 0.002364 | 00:00 | . (4) &#50696;&#52769; . - 생략 . fastai&#51648;&#50896; &#47700;&#53944;&#47533; &#51060;&#50857; --&gt; &#51096;&#47803;&#46108; &#49324;&#50857; . (1) dls &#47564;&#46308;&#44592; . ds1 = torch.utils.data.TensorDataset(X, y) ds2 = torch.utils.data.TensorDataset(XX, yy) dl1 = torch.utils.data.DataLoader(ds1, batch_size = 1266) dl2 = torch.utils.data.DataLoader(ds2, batch_size = 2115) dls = DataLoaders(dl1, dl2) . (2) lrnr &#49373;&#49457; . net = torch.nn.Sequential(torch.nn.Conv2d(1, 16, (5, 5)), torch.nn.ReLU(), torch.nn.MaxPool2d((2, 2)), torch.nn.Flatten(), torch.nn.Linear(2304, 1), torch.nn.Sigmoid()) loss_fn = torch.nn.BCELoss() lrnr = Learner(dls, net, loss_fn, metrics = [accuracy, error_rate]) . (3) &#54617;&#49845; . lrnr.fit(10) . epoch train_loss valid_loss accuracy error_rate time . 0 | 1.063088 | 0.661556 | 0.463357 | 0.536643 | 00:00 | . 1 | 0.721177 | 0.426138 | 0.463357 | 0.536643 | 00:00 | . 2 | 0.574063 | 0.272751 | 0.463357 | 0.536643 | 00:00 | . 3 | 0.459246 | 0.147063 | 0.463357 | 0.536643 | 00:00 | . 4 | 0.359895 | 0.085763 | 0.463357 | 0.536643 | 00:00 | . 5 | 0.282448 | 0.054518 | 0.463357 | 0.536643 | 00:00 | . 6 | 0.224043 | 0.038571 | 0.463357 | 0.536643 | 00:00 | . 7 | 0.179877 | 0.029486 | 0.463357 | 0.536643 | 00:00 | . 8 | 0.145926 | 0.023780 | 0.463357 | 0.536643 | 00:00 | . 9 | 0.119440 | 0.019887 | 0.463357 | 0.536643 | 00:00 | . lrnr.model.to(&quot;cpu&quot;) . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): ReLU() (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False) (3): Flatten(start_dim=1, end_dim=-1) (4): Linear(in_features=2304, out_features=1, bias=True) (5): Sigmoid() ) . plt.plot(yy) plt.plot(lrnr.model(XX).data, &#39;,&#39;) . [&lt;matplotlib.lines.Line2D at 0x19bf8cf2ac0&gt;] . fastai&#51648;&#50896; &#47700;&#53944;&#47533;&#51060;&#50857; --&gt; &#50732;&#48148;&#47480; &#49324;&#50857; 1 . (1) dls &#47564;&#46308;&#44592; . y.to(torch.int64).reshape(-1), yy.to(torch.int64).reshape(-1) . (tensor([0, 0, 0, ..., 1, 1, 1]), tensor([0, 0, 0, ..., 1, 1, 1])) . ds1 = torch.utils.data.TensorDataset(X, y.to(torch.int64).reshape(-1)) ds2 = torch.utils.data.TensorDataset(XX, yy.to(torch.int64).reshape(-1)) dl1 = torch.utils.data.DataLoader(ds1, batch_size = 1266) dl2 = torch.utils.data.DataLoader(ds2, batch_size = 2115) dls = DataLoaders(dl1, dl2) . (2) lrnr &#49373;&#49457; . net = torch.nn.Sequential(torch.nn.Conv2d(1, 16, (5, 5)), torch.nn.ReLU(), torch.nn.MaxPool2d((2, 2)), torch.nn.Flatten(), torch.nn.Linear(2304, 2)) loss_fn = torch.nn.CrossEntropyLoss() lrnr = Learner(dls, net, loss_fn, metrics = [accuracy, error_rate]) . lrnr.fit(10) . epoch train_loss valid_loss accuracy error_rate time . 0 | 1.169649 | 0.602782 | 0.463357 | 0.536643 | 00:00 | . 1 | 0.696552 | 0.323619 | 0.954137 | 0.045863 | 00:00 | . 2 | 0.519975 | 0.144392 | 0.989125 | 0.010875 | 00:00 | . 3 | 0.384531 | 0.067986 | 0.994799 | 0.005201 | 00:00 | . 4 | 0.287451 | 0.037758 | 0.997636 | 0.002364 | 00:00 | . 5 | 0.218949 | 0.023339 | 0.998109 | 0.001891 | 00:00 | . 6 | 0.169778 | 0.016193 | 0.997636 | 0.002364 | 00:00 | . 7 | 0.133592 | 0.012137 | 0.997636 | 0.002364 | 00:00 | . 8 | 0.106303 | 0.009599 | 0.997636 | 0.002364 | 00:00 | . 9 | 0.085338 | 0.007887 | 0.997636 | 0.002364 | 00:00 | . fastai&#51648;&#50896; &#47700;&#53944;&#47533;&#51060;&#50857; --&gt; &#50732;&#48148;&#47480; &#49324;&#50857; 2 . (1) dls &#47564;&#46308;&#44592; . y_onehot = torch.tensor(list(map(lambda x : [1.0, 0.0] if x == 0 else [0.0, 1.0], y))) yy_onehot = torch.tensor(list(map(lambda x : [1.0, 0.0] if x == 0 else [0.0, 1.0], yy))) . ds1 = torch.utils.data.TensorDataset(X, y_onehot) ds2 = torch.utils.data.TensorDataset(XX, yy_onehot) dl1 = torch.utils.data.DataLoader(ds1, batch_size = 1266) dl2 = torch.utils.data.DataLoader(ds2, batch_size = 2115) dls = DataLoaders(dl1, dl2) . (2) lrnr &#47564;&#46308;&#44592; . net = torch.nn.Sequential(torch.nn.Conv2d(1, 16, (5, 5)), torch.nn.ReLU(), torch.nn.MaxPool2d((2, 2)), torch.nn.Flatten(), torch.nn.Linear(2304, 2)) loss_fn = torch.nn.CrossEntropyLoss() lrnr = Learner(dls, net, loss_fn, metrics = [accuracy_multi]) . (3) &#54617;&#49845; . lrnr.fit(10) . epoch train_loss valid_loss accuracy_multi time . 0 | 1.167419 | 0.628575 | 0.463357 | 00:00 | . 1 | 0.718444 | 0.368725 | 0.950118 | 00:00 | . 2 | 0.550238 | 0.172170 | 0.991253 | 00:00 | . 3 | 0.412260 | 0.081312 | 0.995981 | 00:00 | . 4 | 0.309234 | 0.041627 | 0.996217 | 00:00 | . 5 | 0.235456 | 0.024341 | 0.996454 | 00:00 | . 6 | 0.182505 | 0.016696 | 0.997400 | 00:00 | . 7 | 0.143571 | 0.012605 | 0.997636 | 00:00 | . 8 | 0.114232 | 0.010127 | 0.998345 | 00:00 | . 9 | 0.091728 | 0.008435 | 0.998345 | 00:00 | . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/10/20/IABDL.html",
            "relUrl": "/2022/10/20/IABDL.html",
            "date": " • Oct 20, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "IAB딥러닝 10월 18일",
            "content": "Import . import torch import torchvision from fastai.vision.all import * import time . Data . - Download Data . path = untar_data(URLs.MNIST) . - Training Set . X0 = torch.stack([torchvision.io.read_image(Str(fname)) for fname in (path/&#39;training/0&#39;).ls()]) X1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;training/1&#39;).ls()]) X = torch.concat([X0, X1]) / 255 y = torch.tensor([0.0] * len(X0) + [1.0] * len(X1)).reshape(-1, 1) . - Test Set . X0 = torch.stack([torchvision.io.read_image(Str(fname)) for fname in (path/&#39;testing/0&#39;).ls()]) X1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;testing/1&#39;).ls()]) XX = torch.concat([X0, X1]) / 255 yy = torch.tensor([0.0] * len(X0) + [1.0] * len(X1)).reshape(-1, 1) . X.shape, XX.shape, y.shape, yy.shape . (torch.Size([12665, 1, 28, 28]), torch.Size([2115, 1, 28, 28]), torch.Size([12665, 1]), torch.Size([2115, 1])) . CNN &#50696;&#48708;&#54617;&#49845; . &#49352;&#47196;&#50868; &#50500;&#53412;&#53581;&#52376;&#51032; &#51228;&#49884; . - 예전 . $ underset{(n,784)}{ bf X} overset{l_1}{ to} underset{(n,30)}{ boldsymbol u^{(1)}} overset{relu}{ to} underset{(n,30)}{ boldsymbol v^{(1)}} overset{l_2}{ to} underset{(n,1)}{ boldsymbol u^{(2)}} overset{sig}{ to} underset{(n,1)}{ boldsymbol v^{(2)}}= underset{(n,1)}{ hat{ boldsymbol y}}$ . - 새로운 아키텍처 . $conv$: feature를 뻥튀기하는 역할 (2d ver $l_1$ 느낌) | $relu$: | $pooling$: 데이터를 요약하는 역할 | . CONV &#47112;&#51060;&#50612; (&#49440;&#54805;&#48320;&#54872;&#51032; 2D &#48260;&#51204;) . (예시 1) . torch.manual_seed(201715447) _conv = torch.nn.Conv2d(1, 1, (2, 2)) _conv.weight.data, _conv.bias.data . (tensor([[[[ 0.3475, -0.1602], [-0.3039, -0.4139]]]]), tensor([-0.2540])) . _X = torch.arange(0, 4).reshape(1, 2, 2).float() _X . tensor([[[0., 1.], [2., 3.]]]) . (0.3475) * 0 + (-0.1602) * 1 + (-0.3039) * 2 + (-0.4139) * 3 + -0.2540 . -2.2637 . _conv(_X) . tensor([[[-2.2638]]], grad_fn=&lt;SqueezeBackward1&gt;) . (예시 2) 평균구하기 . _conv.weight.data = torch.tensor([[[[1/4, 1/4], [1/4, 1/4]]]]) _conv.bias.data = torch.tensor([0.0]) . _conv(_X), (0 + 1 + 2 + 3) / 4 . (tensor([[[1.5000]]], grad_fn=&lt;SqueezeBackward1&gt;), 1.5) . (예시 3) 이동평균 . _X = torch.arange(0, 25).float().reshape(1, 5, 5) _X . tensor([[[ 0., 1., 2., 3., 4.], [ 5., 6., 7., 8., 9.], [10., 11., 12., 13., 14.], [15., 16., 17., 18., 19.], [20., 21., 22., 23., 24.]]]) . _conv(_X) . tensor([[[ 3., 4., 5., 6.], [ 8., 9., 10., 11.], [13., 14., 15., 16.], [18., 19., 20., 21.]]], grad_fn=&lt;SqueezeBackward1&gt;) . (예시 4) window size가 증가한다면? (2d 이동평균느낌) . _conv = torch.nn.Conv2d(1, 1, (3, 3)) _conv.bias.data = torch.tensor([0.0]) _conv.weight.data = torch.tensor([[[[1/9, 1/9, 1/9], [1/9, 1/9, 1/9], [1/9, 1/9, 1/9]]]]) . _X, _conv(_X) . (tensor([[[ 0., 1., 2., 3., 4.], [ 5., 6., 7., 8., 9.], [10., 11., 12., 13., 14.], [15., 16., 17., 18., 19.], [20., 21., 22., 23., 24.]]]), tensor([[[ 6.0000, 7.0000, 8.0000], [11.0000, 12.0000, 13.0000], [16.0000, 17.0000, 18.0000]]], grad_fn=&lt;SqueezeBackward1&gt;)) . (예시 5) 피처 증가시키기 . _X = torch.tensor([1.0, 1.0, 1.0, 1.0]).reshape(1, 2, 2) _X . tensor([[[1., 1.], [1., 1.]]]) . _conv = torch.nn.Conv2d(1, 8, (2, 2)) _conv.weight.data.shape, _conv.bias.data.shape . (torch.Size([8, 1, 2, 2]), torch.Size([8])) . _conv(_X).reshape(-1) . tensor([ 0.1951, 1.3940, 0.6831, 0.5889, 0.2669, -0.3125, 0.8579, 0.1906], grad_fn=&lt;ReshapeAliasBackward0&gt;) . torch.sum(_conv.weight.data[0,...]) + _conv.bias.data[0], torch.sum(_conv.weight.data[1,...]) + _conv.bias.data[1] . (tensor(0.1951), tensor(1.3940)) . 결국 아래와 같이 계산하는 것과 같다. . torch.sum(_conv.weight.data, axis = (2, 3)).reshape(-1) + _conv.bias.data . tensor([ 0.1951, 1.3940, 0.6831, 0.5889, 0.2669, -0.3125, 0.8579, 0.1906]) . _conv(_X).reshape(-1) . tensor([ 0.1951, 1.3940, 0.6831, 0.5889, 0.2669, -0.3125, 0.8579, 0.1906], grad_fn=&lt;ReshapeAliasBackward0&gt;) . ReLU (2d) . _X = torch.randn(25).reshape(1, 5, 5) _X . tensor([[[-0.0488, 0.2144, -1.0814, 0.4921, 1.2028], [ 0.8151, 0.6953, 0.9054, 0.3448, 1.6039], [-1.1941, -1.4877, -1.0516, -0.6973, -0.1105], [-0.0178, 1.0564, -1.2399, 0.4696, -0.1178], [ 1.0790, -0.9323, -1.8428, -0.9742, -2.0074]]]) . a1 = torch.nn.ReLU() . a1(_X) . tensor([[[0.0000, 0.2144, 0.0000, 0.4921, 1.2028], [0.8151, 0.6953, 0.9054, 0.3448, 1.6039], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 1.0564, 0.0000, 0.4696, 0.0000], [1.0790, 0.0000, 0.0000, 0.0000, 0.0000]]]) . Maxpooling Layer . _maxpooling = torch.nn.MaxPool2d((2, 2)) . _X = torch.arange(16).float().reshape(1, 4, 4) . _X, _maxpooling(_X) . (tensor([[[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.]]]), tensor([[[ 5., 7.], [13., 15.]]])) . _X = torch.arange(25).float().reshape(1, 5, 5) . _X, _maxpooling(_X) . (tensor([[[ 0., 1., 2., 3., 4.], [ 5., 6., 7., 8., 9.], [10., 11., 12., 13., 14.], [15., 16., 17., 18., 19.], [20., 21., 22., 23., 24.]]]), tensor([[[ 6., 8.], [16., 18.]]])) . _X = torch.arange(36).float().reshape(1, 6, 6) . _X, _maxpooling(_X) . (tensor([[[ 0., 1., 2., 3., 4., 5.], [ 6., 7., 8., 9., 10., 11.], [12., 13., 14., 15., 16., 17.], [18., 19., 20., 21., 22., 23.], [24., 25., 26., 27., 28., 29.], [30., 31., 32., 33., 34., 35.]]]), tensor([[[ 7., 9., 11.], [19., 21., 23.], [31., 33., 35.]]])) . CNN &#44396;&#54788; (CPU) . X.shape . torch.Size([12665, 1, 28, 28]) . (1) Conv2d . c1 = torch.nn.Conv2d(1, 16, (5, 5)) print(X.shape) print(c1(X).shape) . torch.Size([12665, 1, 28, 28]) torch.Size([12665, 16, 24, 24]) . (2) ReLU . a1 = torch.nn.ReLU() print(X.shape) print(c1(X).shape) print(a1(c1(X)).shape) . torch.Size([12665, 1, 28, 28]) torch.Size([12665, 16, 24, 24]) torch.Size([12665, 16, 24, 24]) . (3) Maxpool2D . m1 = torch.nn.MaxPool2d((2, 2)) print(X.shape) print(c1(X).shape) print(a1(c1(X)).shape) print(m1(a1(c1(X))).shape) . torch.Size([12665, 1, 28, 28]) torch.Size([12665, 16, 24, 24]) torch.Size([12665, 16, 24, 24]) torch.Size([12665, 16, 12, 12]) . (4) Flatten &amp; Sigmoid . &#48169;&#48277; 1 . m1(a1(c1(X))).reshape(-1, 2304).shape . torch.Size([12665, 2304]) . 16 * 12 * 12 . 2304 . &#48169;&#48277; 2 . flttn = torch.nn.Flatten() . print(X.shape) print(c1(X).shape) print(a1(c1(X)).shape) print(m1(a1(c1(X))).shape) print(flttn(m1(a1(c1(X)))).shape) . torch.Size([12665, 1, 28, 28]) torch.Size([12665, 16, 24, 24]) torch.Size([12665, 16, 24, 24]) torch.Size([12665, 16, 12, 12]) torch.Size([12665, 2304]) . - 2034 -&gt; 1로 차원축소 . l1 = torch.nn.Linear(in_features = 2304, out_features = 1) print(X.shape) print(c1(X).shape) print(a1(c1(X)).shape) print(m1(a1(c1(X))).shape) print(flttn(m1(a1(c1(X)))).shape) print(l1(flttn(m1(a1(c1(X))))).shape) . torch.Size([12665, 1, 28, 28]) torch.Size([12665, 16, 24, 24]) torch.Size([12665, 16, 24, 24]) torch.Size([12665, 16, 12, 12]) torch.Size([12665, 2304]) torch.Size([12665, 1]) . - 시그모이드 . a2 = torch.nn.Sigmoid() . print(X.shape) print(c1(X).shape) print(a1(c1(X)).shape) print(m1(a1(c1(X))).shape) print(flttn(m1(a1(c1(X)))).shape) print(l1(flttn(m1(a1(c1(X))))).shape) print(a2(l1(flttn(m1(a1(c1(X)))))).shape) . torch.Size([12665, 1, 28, 28]) torch.Size([12665, 16, 24, 24]) torch.Size([12665, 16, 24, 24]) torch.Size([12665, 16, 12, 12]) torch.Size([12665, 2304]) torch.Size([12665, 1]) torch.Size([12665, 1]) . - 네트워크 설계 . net = torch.nn.Sequential(c1, a1, m1, flttn, l1, a2) . loss_fn = torch.nn.BCELoss() optimizer = torch.optim.Adam(net.parameters()) . t1 = time.time() for epoch in range(100): ## step 1 yhat = net(X) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() t2 = time.time() t2 - t1 . 52.05671548843384 . plt.plot(y) plt.plot(net(X).data, &#39;.&#39;) plt.title(&#39;Training Set&#39;, size = 15) . Text(0.5, 1.0, &#39;Training Set&#39;) . CNN &#44396;&#54788; (GPU) . 1. dls . ds1 = torch.utils.data.TensorDataset(X, y) ds2 = torch.utils.data.TensorDataset(XX, yy) . X.shape . torch.Size([12665, 1, 28, 28]) . len(X) / 10 . 1266.5 . len(XX) . 2115 . dl1 = torch.utils.data.DataLoader(ds1, batch_size = 1266) dl2 = torch.utils.data.DataLoader(ds2, batch_size = 2115) . dls = DataLoaders(dl1, dl2) . 2. lnrn &#49373;&#49457; : &#50500;&#53412;&#53581;&#52376;, &#49552;&#49892;&#54632;&#49688;, &#50741;&#54000;&#47560;&#51060;&#51200; . net = torch.nn.Sequential(torch.nn.Conv2d(1, 16, (5, 5)), torch.nn.ReLU(), torch.nn.MaxPool2d((2, 2)), torch.nn.Flatten(), torch.nn.Linear(2304, 1), torch.nn.Sigmoid()) loss_fn = torch.nn.BCELoss() . lrnr = Learner(dls, net, loss_fn) . 3. &#54617;&#49845; . lrnr.fit(10) . epoch train_loss valid_loss time . 0 | 0.991282 | 0.619085 | 00:03 | . 1 | 0.670625 | 0.341608 | 00:00 | . 2 | 0.503302 | 0.198077 | 00:00 | . 3 | 0.387530 | 0.104358 | 00:00 | . 4 | 0.299216 | 0.062006 | 00:00 | . 5 | 0.233724 | 0.041215 | 00:00 | . 6 | 0.185017 | 0.029626 | 00:00 | . 7 | 0.148258 | 0.022577 | 00:00 | . 8 | 0.120027 | 0.017928 | 00:00 | . 9 | 0.097999 | 0.014688 | 00:00 | . 4. &#50696;&#52769; &#48143; &#49884;&#44033;&#54868; . net.to(&quot;cpu&quot;) . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): ReLU() (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False) (3): Flatten(start_dim=1, end_dim=-1) (4): Linear(in_features=2304, out_features=1, bias=True) (5): Sigmoid() ) . plt.plot(net(X).data, &#39;.&#39;) plt.title(&quot;Training Set&quot;, size = 15) . Text(0.5, 1.0, &#39;Training Set&#39;) . plt.plot(net(XX).data, &#39;.&#39;) plt.title(&quot;Test Set&quot;, size = 15) . Text(0.5, 1.0, &#39;Test Set&#39;) . - 빠르고 적합결과가 좋음 . Lrnr &#50724;&#48652;&#51229;&#53944; . lrnr.model . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): ReLU() (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False) (3): Flatten(start_dim=1, end_dim=-1) (4): Linear(in_features=2304, out_features=1, bias=True) (5): Sigmoid() ) . net . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): ReLU() (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False) (3): Flatten(start_dim=1, end_dim=-1) (4): Linear(in_features=2304, out_features=1, bias=True) (5): Sigmoid() ) . id(lrnr.model), id(net) . (1730046488000, 1730046488000) . lrnr.model(X) . tensor([[0.0022], [0.0062], [0.0010], ..., [0.9944], [0.9928], [0.9961]], grad_fn=&lt;SigmoidBackward0&gt;) . BCEWithLogitsLoss . - BCEWithLogitsLoss = Sigmoid + BCELoss . 사용하는 이유 : 수치적으로 더 안정적 | . (1) dls &#47564;&#46308;&#44592; . ds1 = torch.utils.data.TensorDataset(X, y) ds2 = torch.utils.data.TensorDataset(XX, yy) . dl1 = torch.utils.data.DataLoader(ds1, batch_size = 1266) dl2 = torch.utils.data.DataLoader(ds2, batch_size = 2115) . dls = DataLoaders(dl1, dl2) . (2) lrnr &#49373;&#49457; . net = torch.nn.Sequential(torch.nn.Conv2d(1, 16, (5, 5)), torch.nn.ReLU(), torch.nn.MaxPool2d((2, 2)), torch.nn.Flatten(), torch.nn.Linear(2304, 1), # torch.nn.Sigmoid ) loss_fn = torch.nn.BCEWithLogitsLoss() lrnr = Learner(dls, net, loss_fn) . (3) &#54617;&#49845; . lrnr.fit(10) . epoch train_loss valid_loss time . 0 | 0.892442 | 0.606591 | 00:00 | . 1 | 0.666649 | 0.397382 | 00:00 | . 2 | 0.523290 | 0.242031 | 00:00 | . 3 | 0.411065 | 0.128731 | 00:00 | . 4 | 0.320348 | 0.071073 | 00:00 | . 5 | 0.250880 | 0.044551 | 00:00 | . 6 | 0.198633 | 0.031172 | 00:00 | . 7 | 0.159071 | 0.023557 | 00:00 | . 8 | 0.128692 | 0.018763 | 00:00 | . 9 | 0.105028 | 0.015471 | 00:00 | . (4) &#50696;&#52769; &#48143; &#49884;&#44033;&#54868; . net.to(&#39;cpu&#39;) . Sequential( (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1)) (1): ReLU() (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False) (3): Flatten(start_dim=1, end_dim=-1) (4): Linear(in_features=2304, out_features=1, bias=True) ) . fig, ax = plt.subplots(1, 2, figsize = (8, 4)) ax[0].plot(net(X).data, &#39;.&#39;, color = &#39;C1&#39;) ax[1].plot(y) ax[1].plot(a2(net(X)).data, &#39;.&#39;) fig.suptitle(&#39;Training Set&#39;, size = 15) . Text(0.5, 0.98, &#39;Training Set&#39;) . fig, ax = plt.subplots(1, 2, figsize = (8, 4)) ax[0].plot(net(XX).data, &#39;.&#39;, color = &#39;C1&#39;) ax[1].plot(yy) ax[1].plot(a2(net(XX)).data, &#39;.&#39;) fig.suptitle(&#39;Training Set&#39;, size = 15) . Text(0.5, 0.98, &#39;Training Set&#39;) . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/10/18/IABDL.html",
            "relUrl": "/2022/10/18/IABDL.html",
            "date": " • Oct 18, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "IAB딥러닝 10월 13일",
            "content": "Import . import torch from fastai.vision.all import * import matplotlib.pyplot as plt . import os os.environ[&#39;KMP_DUPLICATE_LIB_OK&#39;] = &#39;True&#39; # plt.plot 오류 발생 시 사용 . &#45936;&#51060;&#53552; . torch.manual_seed(5) x = torch.linspace(0, 1, 100).reshape(100, 1) y = torch.randn(100).reshape(100, 1) * 0.01 . xtrain = x[:80] ytrain = y[:80] xtest = x[80:] ytest = y[80:] . &#46300;&#46989;&#50500;&#50883; . &#50724;&#48260;&#54588;&#54021;&#51032; &#54644;&#44208; . - 오버피팅 해결책 : 드랍아웃 . torch.manual_seed(1) net = torch.nn.Sequential(torch.nn.Linear(in_features = 1, out_features = 512), torch.nn.ReLU(), torch.nn.Dropout(0.8), torch.nn.Linear(in_features = 512, out_features = 1)) loss_fn = torch.nn.MSELoss() optimizer = torch.optim.Adam(net.parameters()) for epoch in range(1000): ## step 1 # ## stpe 2 loss = loss_fn(net(xtrain), ytrain) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(xtrain, ytrain, &#39;o&#39;) plt.plot(xtest, ytest, &#39;o&#39;) plt.plot(x, net(x).data, &#39;--&#39;) plt.title(r&quot;network is in training mode&quot;, fontsize = 15) . Text(0.5, 1.0, &#39;network is in training mode&#39;) . - 올바른 사용법 . net.training . True . net.eval() net.training . False . plt.plot(xtrain, ytrain, &#39;o&#39;) plt.plot(xtest, ytest, &#39;o&#39;) plt.plot(x, net(x).data, &#39;--&#39;) plt.title(r&#39;network is in evaluation mode&#39;, fontsize = 15) . Text(0.5, 1.0, &#39;network is in evaluation mode&#39;) . _x = torch.linspace(0, 1, 101) _x . tensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800, 0.0900, 0.1000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500, 0.1600, 0.1700, 0.1800, 0.1900, 0.2000, 0.2100, 0.2200, 0.2300, 0.2400, 0.2500, 0.2600, 0.2700, 0.2800, 0.2900, 0.3000, 0.3100, 0.3200, 0.3300, 0.3400, 0.3500, 0.3600, 0.3700, 0.3800, 0.3900, 0.4000, 0.4100, 0.4200, 0.4300, 0.4400, 0.4500, 0.4600, 0.4700, 0.4800, 0.4900, 0.5000, 0.5100, 0.5200, 0.5300, 0.5400, 0.5500, 0.5600, 0.5700, 0.5800, 0.5900, 0.6000, 0.6100, 0.6200, 0.6300, 0.6400, 0.6500, 0.6600, 0.6700, 0.6800, 0.6900, 0.7000, 0.7100, 0.7200, 0.7300, 0.7400, 0.7500, 0.7600, 0.7700, 0.7800, 0.7900, 0.8000, 0.8100, 0.8200, 0.8300, 0.8400, 0.8500, 0.8600, 0.8700, 0.8800, 0.8900, 0.9000, 0.9100, 0.9200, 0.9300, 0.9400, 0.9500, 0.9600, 0.9700, 0.9800, 0.9900, 1.0000]) . dout = torch.nn.Dropout(0.9) dout(_x) . tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.3000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 4.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 5.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 7.1000, 0.0000, 0.0000, 0.0000, 0.0000, 7.6000, 7.7000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 8.9000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) . 90%의 드랍아웃 : 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배만큼 값이 커진다. | . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/10/13/IABDL.html",
            "relUrl": "/2022/10/13/IABDL.html",
            "date": " • Oct 13, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "IAB딥러닝 10월 11일",
            "content": "Import . import torch import torchvision from fastai.data.all import * import matplotlib.pyplot as plt . import os os.environ[&#39;KMP_DUPLICATE_LIB_OK&#39;] = &#39;True&#39; # plt.plot 오류 발생 시 사용 . &#49888;&#44221;&#47581;&#51032; &#54364;&#54788; (${ boldsymbol x} to hat{ boldsymbol y}$ &#47196; &#44032;&#45716; &#44284;&#51221;&#51012; &#44536;&#47548;&#51004;&#47196; &#54364;&#54788;) . https://guebin.github.io/DL2022/2022/10/11/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9411%EC%9D%BC.html | . &#49884;&#48292;&#53076;&#51221;&#47532;&#44032; &#49457;&#47549;&#54616;&#45716; &#51060;&#50976; (&#50628;&#48128;&#54620; &#51613;&#47749; X) . &#44536;&#47548;&#51004;&#47196; &#48372;&#45716; &#51613;&#47749;&#44284;&#51221; . - 데이터 . x = torch.linspace(-10, 10, 200).reshape(-1, 1) . l1 = torch.nn.Linear(in_features = 1, out_features = 2) a1 = torch.nn.Sigmoid() l2 = torch.nn.Linear(in_features = 2, out_features = 1) . - 직관 : $l_1$,$l_2$의 가중치를 잘 결합하다보면 우연히 아래와 같이 만들 수 있다. . l1.weight.data = torch.tensor([[-5.00], [5.00]]) l1.bias.data = torch.tensor([+10.00, +10.00]) . l2.weight.data = torch.tensor([[1.00, 1.00]]) l2.bias.data = torch.tensor([-1.00]) . fig, ax = plt.subplots(1, 3, figsize = (9, 3)) ax[0].plot(x, l1(x).data) ax[0].set_title(&#39;$l_1(x)$&#39;) ax[1].plot(x, a1(l1(x)).data) ax[1].set_title(&#39;$(a_1 circ l_1)(x)$&#39;) ax[2].plot(x, l2(a1(l1(x))).data, color = &#39;C2&#39;) ax[2].set_title(&#39;$(l_2 circ a_1 circ l_1)(x)$&#39;) . Text(0.5, 1.0, &#39;$(l_2 circ a_1 circ l_1)(x)$&#39;) . - 직관 2 : 아래도 가능할듯? . l1.weight.data = torch.tensor([[-5.00], [5.00]]) l1.bias.data = torch.tensor([+0.00, +20.00]) l2.weight.data = torch.tensor([[1.00, 1.00]]) l2.bias.data = torch.tensor([-1.00]) fig, ax = plt.subplots(1, 3, figsize = (9, 3)) ax[0].plot(x, l1(x).data, &#39;--&#39;, color = &#39;C0&#39;) ax[0].set_title(&#39;$l_1(x)$&#39;) ax[1].plot(x, a1(l1(x)).data, &#39;--&#39;, color = &#39;C0&#39;) ax[1].set_title(&#39;$(a_1 circ l_1)(x)$&#39;) ax[2].plot(x, l2(a1(l1(x))).data, &#39;--&#39;, color = &#39;C0&#39;) ax[2].set_title(&#39;$(l_2 circ a_1 circ l_1)(x)$&#39;) . Text(0.5, 1.0, &#39;$(l_2 circ a_1 circ l_1)(x)$&#39;) . l1.weight.data = torch.tensor([[-5.00], [5.00]]) l1.bias.data = torch.tensor([+20.00, +0.00]) l2.weight.data = torch.tensor([[2.50, 2.50]]) l2.bias.data = torch.tensor([-2.50]) ax[0].plot(x, l1(x).data, &#39;--&#39;, color = &#39;C1&#39;) ax[0].set_title(&#39;$l_1(x)$&#39;) ax[1].plot(x, a1(l1(x)).data, &#39;--&#39;, color = &#39;C1&#39;) ax[1].set_title(&#39;$(a_1 circ l_1)(x)$&#39;) ax[2].plot(x, l2(a1(l1(x))).data, &#39;--&#39;, color = &#39;C1&#39;) ax[2].set_title(&#39;$(l_2 circ a_1 circ l_1)(x)$&#39;) fig . - 은닉층의노드수=4로 하고 적당한 가중치를 조정하면 $(l_2 circ a_1 circ l_1)(x)$의 결과로 주황색선 + 파란색선도 가능할 것 같다. $ to$ 실제로 가능 . l1 = torch.nn.Linear(in_features = 1, out_features = 4) a1 = torch.nn.Sigmoid() l2 = torch.nn.Linear(in_features = 4, out_features = 1) . l1.weight.data = torch.tensor([[-5.00], [5.00], [-5.00], [5.00]]) l1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0]) l2.weight.data = torch.tensor([[1.00, 1.00, 2.50, 2.50]]) l2.bias.data = torch.tensor([-1.0 -2.5]) . plt.plot(l2(a1(l1(x))).data) . [&lt;matplotlib.lines.Line2D at 0x2630f0c77f0&gt;] . - 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 함수 $h$를 만들 수 있음 . h = lambda x : torch.sigmoid(200 * (x + 0.5)) + torch.sigmoid(-200 * (x - 0.5)) - 1.0 . plt.plot(x, h(x)) plt.title(&#39;$h(x)$&#39;) . Text(0.5, 1.0, &#39;$h(x)$&#39;) . - 위와 같은 함수 $h$를 활성화함수로 하고 $m$개의 노드를 가지는 은닉층을 생각해보자. 이러한 은닉층을 사용한다면 전체 네트워크를 아래와 같이 표현할 수 있다. . $ underset{(n,1)}{ bf X} overset{l_1}{ to} underset{(n,m)}{ boldsymbol u^{(1)}} overset{h}{ to} underset{(n,m)}{ boldsymbol v^{(1)}} overset{l_2}{ to} underset{(n,1)}{ hat{ boldsymbol y}}$ . 그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함. . $ underset{(n,1)}{ bf X} overset{l_1}{ to} underset{(n,2m)}{ boldsymbol u^{(1)}} overset{sig}{ to} underset{(n,2m)}{ boldsymbol v^{(1)}} overset{l_2}{ to} underset{(n,1)}{ hat{ boldsymbol y}}$ . - $h(x)$를 활성화함수로 가지는 네트워크를 설계하여 보자. . class MyActivation(torch.nn.Module): def __init__(self): super().__init__() def forward(self, input): return h(input) . a1 = MyActivation() . plt.plot(x, a1(x)) . [&lt;matplotlib.lines.Line2D at 0x2630f1d73a0&gt;] . 히든레이어가 1개의 노드를 가지는 경우 . torch.manual_seed(201715447) fig, ax = plt.subplots(4, 4, figsize = (12, 12)) for i in range(4): for j in range(4): net = torch.nn.Sequential(torch.nn.Linear(1, 1), MyActivation(), torch.nn.Linear(1, 1)) ax[i, j].plot(x, net(x).data, &#39;--&#39;) . 히든레이어가 2개의 노드를 가지는 경우 . torch.manual_seed(201715447) fig, ax = plt.subplots(4, 4, figsize = (12, 12)) for i in range(4): for j in range(4): net = torch.nn.Sequential(torch.nn.Linear(1, 2), MyActivation(), torch.nn.Linear(2, 1)) ax[i, j].plot(x, net(x).data, &#39;--&#39;) . 히든레이어가 3개의 노드를 가지는 경우 . torch.manual_seed(201715447) fig, ax = plt.subplots(4, 4, figsize = (12, 12)) for i in range(4): for j in range(4): net = torch.nn.Sequential(torch.nn.Linear(1, 3), MyActivation(), torch.nn.Linear(3, 1)) ax[i, j].plot(x, net(x).data, &#39;--&#39;) . 히든레이어가 1024개의 노드를 가지는 경우 . torch.manual_seed(201715447) fig, ax = plt.subplots(4, 4, figsize = (12, 12)) for i in range(4): for j in range(4): net = torch.nn.Sequential(torch.nn.Linear(1, 1024), MyActivation(), torch.nn.Linear(1024, 1)) ax[i, j].plot(x, net(x).data, &#39;--&#39;) . &#54616;&#45208;&#51032; &#51008;&#45769;&#52789;&#50640; &#47566;&#51008; &#45432;&#46300;&#49688;&#44032; &#51080;&#45716; &#49888;&#44221;&#47581; . - 아래와 같이 하나의 은닉층을 가지고 있더라도 많은 노드 수만 보장되면 매우 충분한 표현력을 가짐 . $ underset{(n,1)}{ bf X} overset{l_1}{ to} underset{(n,m)}{ boldsymbol u^{(1)}} overset{h}{ to} underset{(n,m)}{ boldsymbol v^{(1)}} overset{l_2}{ to} underset{(n,1)}{ hat{ boldsymbol y}}$ . (예시 1) . torch.manual_seed(201715447) x = torch.linspace(-10, 10, 200).reshape(-1, 1) underlying = torch.sin(2 * x) + torch.sin(0.5 * x) + torch.exp(-0.2 * x) eps = torch.randn(200).reshape(-1, 1) * 0.1 y = underlying + eps plt.plot(x, y, &#39;o&#39;, alpha = 0.5) plt.plot(x, underlying, lw = 3) . [&lt;matplotlib.lines.Line2D at 0x26314bdef10&gt;] . h = lambda x : torch.sigmoid(200 * (x + 0.5)) + torch.sigmoid(-200 * (x - 0.5)) - 1.0 class MyActivation(torch.nn.Module): def __init__(self): super().__init__() def forward(self, input): return h(input) . net = torch.nn.Sequential(torch.nn.Linear(1, 2048), MyActivation(), torch.nn.Linear(2048, 1)) loss_fn = torch.nn.MSELoss() optimizer = torch.optim.Adam(net.parameters()) . for epoch in range(200): ## step 1 yhat = net(x) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;, alpha = 0.2) plt.plot(x, underlying, lw = 3) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x26314c4d580&gt;] . (예시 2) . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex0.csv&#39;) df . x underlying y . 0 -1.000000 | 0.000045 | 0.0 | . 1 -0.998999 | 0.000046 | 0.0 | . 2 -0.997999 | 0.000047 | 0.0 | . 3 -0.996998 | 0.000047 | 0.0 | . 4 -0.995998 | 0.000048 | 0.0 | . ... ... | ... | ... | . 1995 0.995998 | 0.505002 | 0.0 | . 1996 0.996998 | 0.503752 | 0.0 | . 1997 0.997999 | 0.502501 | 0.0 | . 1998 0.998999 | 0.501251 | 1.0 | . 1999 1.000000 | 0.500000 | 1.0 | . 2000 rows × 3 columns . x = torch.tensor(df.x).reshape(-1, 1).float() y = torch.tensor(df.y).reshape(-1, 1).float() plt.plot(x, y, &#39;o&#39;, alpha = 0.1) plt.plot(df.x, df.underlying, lw = 3) . [&lt;matplotlib.lines.Line2D at 0x26314e61bb0&gt;] . h = lambda x : torch.sigmoid(200 * (x + 0.5)) + torch.sigmoid(-200 * (x - 0.5)) - 1.0 class MyActivation(torch.nn.Module): def __init__(self): super().__init__() def forward(self, input): return h(input) . torch.manual_seed(201715447) net = torch.nn.Sequential(torch.nn.Linear(1, 2048), MyActivation(), torch.nn.Linear(2048, 1), torch.nn.Sigmoid()) loss_fn = torch.nn.MSELoss() optimizer = torch.optim.Adam(net.parameters()) . for epoch in range(200): ## step 1 yhat = net(x) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;, alpha = 0.2) plt.plot(df.x, df.underlying, lw = 3) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x26315117be0&gt;] . &#49884;&#44036;&#52769;&#51221; . import time . t1 = time.time() . t2 = time.time() . t2 - t1 . 8.008109092712402 . &#54869;&#47456;&#51201;&#44221;&#49324;&#54616;&#44053;&#48277;, &#48176;&#52824; , &#50640;&#54253; . x = torch.linspace(-10, 10, 100000).reshape(-1, 1) eps = torch.randn(100000).reshape(-1, 1) y = x * 2 + eps . plt.plot(x, y, &#39;o&#39;, alpha = 0.05) plt.plot(x, 2 * x) . [&lt;matplotlib.lines.Line2D at 0x263150d9850&gt;] . plt.plot(x[::100], y[::100], &#39;o&#39;, alpha = 0.05) plt.plot(x, 2 * x) . [&lt;matplotlib.lines.Line2D at 0x2630f4ffd90&gt;] . X, y &#45936;&#51060;&#53552;&#47484; &#44403;&#51060; &#47784;&#46160; GPU&#50640; &#50732;&#47140;&#50556; &#54616;&#45716;&#44032;? . - 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나? . - 아래와 같은 알고리즘을 생각해 볼 수 있다. . 데이터를 반으로 나눈다. . | 짝수 obs의 x, y 그리고 net의 모든 파라미터를 GPU에 올린다. . | yhat, loss, grad, update 수행 . | 짝수 obs의 x, y를 GPU 메모리에서 내린다. 그리고 홀수 obs의 x, y를 GPU 메모리에 올린다. . | yhat, loss, grad, update 수행 . | 홀수 obs의 x, y를 GPU 메모리에서 내린다. 그리고 짝수 obs의 x, y를 GPU 메모리에 올린다. . | 반복 . | &#44221;&#49324;&#54616;&#44053;&#48277;, &#54869;&#47456;&#51201;&#44221;&#49324;&#54616;&#44053;&#48277;, &#48120;&#45768;&#48176;&#52824; &#44221;&#49324;&#54616;&#44053;&#48277; . 10개의 샘플이 있다고 가정. $ {(x_i,y_i) }_{i=1}^{10}$ . - ver 1: 모든 샘플을 이용하여 slope 계산 . (epoch1) $loss= sum_{i=1}^{10}(y_i- beta_0- beta_1x_i)^2 to slope to update$ . (epoch2) $loss= sum_{i=1}^{10}(y_i- beta_0- beta_1x_i)^2 to slope to update$ . ... . - ver 2: 하나의 샘플만을 이용하여 slope 계산 . (epoch1) . $loss=(y_1- beta_0- beta_1x_1)^2 to slope to update$ | $loss=(y_2- beta_0- beta_1x_2)^2 to slope to update$ | ... | $loss=(y_{10}- beta_0- beta_1x_{10})^2 to slope to update$ | . (epoch2) . $loss=(y_1- beta_0- beta_1x_1)^2 to slope to update$ | $loss=(y_2- beta_0- beta_1x_2)^2 to slope to update$ | ... | $loss=(y_{10}- beta_0- beta_1x_{10})^2 to slope to update$ | . ... . - ver 3: $m ( leq n)$ 개의 샘플을 이용하여 slope 계산 . $m=3$일때 . (epoch1) . $loss= sum_{i=1}^{3}(y_i- beta_0- beta_1x_i)^2 to slope to update$ | $loss= sum_{i=4}^{6}(y_i- beta_0- beta_1x_i)^2 to slope to update$ | $loss= sum_{i=7}^{9}(y_i- beta_0- beta_1x_i)^2 to slope to update$ | $loss=(y_{10}- beta_0- beta_1x_{10})^2 to slope to update$ | . (epoch2) . $loss= sum_{i=1}^{3}(y_i- beta_0- beta_1x_i)^2 to slope to update$ | $loss= sum_{i=4}^{6}(y_i- beta_0- beta_1x_i)^2 to slope to update$ | $loss= sum_{i=7}^{9}(y_i- beta_0- beta_1x_i)^2 to slope to update$ | $loss=(y_{10}- beta_0- beta_1x_{10})^2 to slope to update$ | . ... . ds, dl . ds . x = torch.tensor(range(10)).float() y = torch.tensor([1.0] * 5 + [0.0] * 5) . ds = torch.utils.data.TensorDataset(x, y) ds . &lt;torch.utils.data.dataset.TensorDataset at 0x26315038460&gt; . ds.tensors . (tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])) . dl . dl = torch.utils.data.DataLoader(ds, batch_size = 3) . for xx, yy in dl: print(xx, yy) . tensor([0., 1., 2.]) tensor([1., 1., 1.]) tensor([3., 4., 5.]) tensor([1., 1., 0.]) tensor([6., 7., 8.]) tensor([0., 0., 0.]) tensor([9.]) tensor([0.]) . ds, dl&#51012; &#51060;&#50857;&#54620; MNIST &#44396;&#54788; . - 데이터정리 . path = untar_data(URLs.MNIST) . zero_fnames = (path/&#39;training/0&#39;).ls() one_fnames = (path/&#39;training/1&#39;).ls() . X0 = torch.stack([torchvision.io.read_image(str(zf)) for zf in zero_fnames]) X1 = torch.stack([torchvision.io.read_image(str(of)) for of in one_fnames]) X = torch.concat([X0, X1], axis = 0).reshape(-1, 1 * 28 * 28) / 255 y = torch.tensor([0.0] * len(X0) + [1.0] * len(X1)).reshape(-1, 1) . X.shape, y.shape . (torch.Size([12665, 784]), torch.Size([12665, 1])) . - ds --&gt; dl . ds = torch.utils.data.TensorDataset(X, y) dl = torch.utils.data.DataLoader(ds, batch_size = 2048) . 12665 / 2048 . 6.18408203125 . i = 0 for xx, yy in dl: print(i) i += 1 . 0 1 2 3 4 5 6 . - 미니배치를 사용하지 않는 학습 . torch.manual_seed(201715447) net = torch.nn.Sequential(torch.nn.Linear(784, 32), torch.nn.ReLU(), torch.nn.Linear(32, 1), torch.nn.Sigmoid()) loss_fn = torch.nn.BCELoss() optimizer = torch.optim.Adam(net.parameters()) . for epoch in range(70): ## step 1 yhat = net(X) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . torch.sum((yhat &gt; 0.5) == y) / len(y) . tensor(0.9979) . - 미니배치를 사용하는 학습 (GPU 올리고 내리는 과정은 생략) . torch.manual_seed(201715447) net = torch.nn.Sequential(torch.nn.Linear(784, 32), torch.nn.ReLU(), torch.nn.Linear(32, 1), torch.nn.Sigmoid()) loss_fn = torch.nn.BCELoss() optimizer = torch.optim.Adam(net.parameters()) . for epoch in range(70): for xx, yy in dl: ## step 1 # yhat = net(X) ## step 2 loss = loss_fn(net(xx), yy) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . torch.mean(((net(X) &gt; 0.5) == y) * 1.0) . tensor(0.9990) . &#50724;&#48260;&#54588;&#54021; . &#50724;&#48260;&#54588;&#54021; &#50696;&#49884; . - $m$이 매우 클때 아래의 네트워크 거의 무엇이든 맞출 수 있다고 보면 된다. . $ underset{(n,1)}{ bf X} overset{l_1}{ to} underset{(n,m)}{ boldsymbol u^{(1)}} overset{h}{ to} underset{(n,m)}{ boldsymbol v^{(1)}} overset{l_2}{ to} underset{(n,1)}{ hat{ boldsymbol y}}$ | $ underset{(n,1)}{ bf X} overset{l_1}{ to} underset{(n,m)}{ boldsymbol u^{(1)}} overset{sig}{ to} underset{(n,m)}{ boldsymbol v^{(1)}} overset{l_2}{ to} underset{(n,1)}{ hat{ boldsymbol y}}$ | $ underset{(n,1)}{ bf X} overset{l_1}{ to} underset{(n,m)}{ boldsymbol u^{(1)}} overset{relu}{ to} underset{(n,m)}{ boldsymbol v^{(1)}} overset{l_2}{ to} underset{(n,1)}{ hat{ boldsymbol y}}$ | . model: $y_i = (0 times x_i) + epsilon_i$, where $ epsilon_i sim N(0,0.01^2)$ . torch.manual_seed(5) x = torch.linspace(0, 1, 100).reshape(100, 1) y = torch.randn(100).reshape(100, 1) * 0.01 plt.plot(x, y) . [&lt;matplotlib.lines.Line2D at 0x263150f8370&gt;] . torch.manual_seed(1) net = torch.nn.Sequential(torch.nn.Linear(in_features = 1, out_features = 512), torch.nn.ReLU(), torch.nn.Linear(in_features = 512, out_features = 1)) optimizer = torch.optim.Adam(net.parameters()) loss_fn = torch.nn.MSELoss() for epoch in range(1000): yhat = net(x) loss = loss_fn(yhat, y) loss.backward() optimizer.step() net.zero_grad() . plt.plot(x, y) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x26325cce280&gt;] . 우리는 데이터를 랜덤에서 뽑았는데, 데이터의 추세를 따라간다 $ to$ 오버피팅 (underlying이 아니라 오차항을 따라가고 있음) | . &#50724;&#48260;&#54588;&#54021;&#51060;&#46972;&#45716; &#46748;&#47159;&#54620; &#51613;&#44144;! (train / test) . - 데이터를 분리하여 사용 . torch.manual_seed(5) x = torch.linspace(0, 1, 100).reshape(100, 1) y = torch.randn(100).reshape(100, 1) * 0.01 xtrain = x[:80] ytrain = y[:80] xtest = x[80:] ytest = y[80:] plt.plot(xtrain, ytrain) plt.plot(xtest, ytest) plt.title(&#39;train : blue / test : orange&#39;) . Text(0.5, 1.0, &#39;train : blue / test : orange&#39;) . - train만 학습 . torch.manual_seed(1) net = torch.nn.Sequential(torch.nn.Linear(in_features = 1, out_features = 512), torch.nn.ReLU(), torch.nn.Linear(in_features = 512, out_features = 1)) optimizer = torch.optim.Adam(net.parameters()) loss_fn = torch.nn.MSELoss() for epoch in range(1000): yhat = net(x) loss = loss_fn(net(xtrain), ytrain) loss.backward() optimizer.step() optimizer.zero_grad() . plt.plot(x, y, alpha = 0.5) plt.plot(xtrain, net(xtrain).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x26326a64130&gt;] . - training data로 학습한 net을 test data에 적용 . plt.plot(x, y, alpha = 0.5) plt.plot(xtrain, net(xtrain).data, &#39;--&#39;) plt.plot(xtest, net(xtest).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x26326aa9f70&gt;] . train에서는 어느정도 맞지만 test에서는 엉망 --&gt; 오버피팅 | . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/10/11/IABDL.html",
            "relUrl": "/2022/10/11/IABDL.html",
            "date": " • Oct 11, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "IAB딥러닝 10월 6일",
            "content": "Import . import torch import matplotlib.pyplot as plt from fastai.data.all import * import torchvision . import os os.environ[&#39;KMP_DUPLICATE_LIB_OK&#39;] = &#39;True&#39; # plt.plot 오류 발생 시 사용 . &#49884;&#48292;&#53076;&#51221;&#47532; . universal approximation thm : (범용근사정리, 보편근사정리, 시벤코정리), 1989 . 하나의 은닉층을 가지는 &quot;linear -&gt; sigmoid -&gt; linear&quot; 꼴의 네트워크를 이용하여 세상에 존재하는 모든 (다차원) 연속함수를 원하는 정확도로 근사시킬 수 있다. (계수를 잘 추정한다고 가정한다면) . - 이해가 안되는 부분 . 그렇게 잘 맞춘다면 1989년에 모든 문제가 풀렸어야함 . | 최근에는 linear -&gt; relu -&gt; linear 조합을 더 많이 사용함 . | 은닉층이 하나인 네트워크는 잘 사용하지 않음 -&gt; 하드웨어의 발전으로 은닉층이 많은 네트워크 사용이 가능해짐 . | . - 쨋든 universal approximation thm에 따르면 아래와 같은 무기를 가진 꼴이 됨 . 우리의 무기: ${ bf X}: (n,p)$ 꼴의 입력에서 ${ bf y}:(n,1)$ 꼴의 출력으로 향하는 맵핑을 &quot;linear -&gt; relu -&gt; linear&quot;와 같은 네트워크를 이용해서 &quot;근사&quot;시킬 수 있다. | . MNIST with DNN . &#47785;&#54364; . - ${ bf X}:(n,1,28,28)$ 에서 $y:(n,1)$ 로 가는 맵핑을 학습 --&gt; 배운적이 없다면? --&gt; ${ bf X}:(n,784)$ 에서 $y:(n,1)$ 로 가는 맵핑을 학습 . &#50696;&#48708;&#54617;&#49845; 1 : Path . path = untar_data(URLs.MNIST) . . 100.03% [15687680/15683414 00:02&lt;00:00] path . Path(&#39;C:/Users/USER/.fastai/data/mnist_png&#39;) . - path의 정보 . path._str . &#39;C: Users USER .fastai data mnist_png&#39; . - 기능 1 . path.ls() . (#2) [Path(&#39;C:/Users/USER/.fastai/data/mnist_png/testing&#39;),Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training&#39;)] . - 기능 2 . path/&#39;training&#39; . Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training&#39;) . path/&#39;testing&#39; . Path(&#39;C:/Users/USER/.fastai/data/mnist_png/testing&#39;) . - 기능 1과 기능 2 결합 . (path/&#39;training/3&#39;).ls() . (#6131) [Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/10.png&#39;),Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/10000.png&#39;),Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/10011.png&#39;),Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/10031.png&#39;),Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/10034.png&#39;),Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/10042.png&#39;),Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/10052.png&#39;),Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/1007.png&#39;),Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/10074.png&#39;),Path(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/10091.png&#39;)...] . &#50696;&#48708;&#54617;&#49845; 2 : plt.imshow . imgstr = torch.tensor([[1.0, 2], [2.0, 4.0]]) imgstr . tensor([[1., 2.], [2., 4.]]) . plt.imshow(imgstr, cmap = &#39;gray&#39;) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x18eb1cf4e20&gt; . &#50696;&#48708;&#54617;&#49845; 3 : torchvision . imgstr = torchvision.io.read_image(&#39;C:/Users/USER/.fastai/data/mnist_png/training/3/37912.png&#39;) imgstr . tensor([[[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 66, 138, 149, 180, 138, 138, 86, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 22, 162, 161, 228, 252, 252, 253, 252, 252, 252, 252, 74, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 116, 253, 252, 252, 252, 189, 184, 110, 119, 252, 252, 32, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 74, 161, 160, 77, 45, 4, 0, 0, 70, 252, 210, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 205, 252, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 162, 253, 245, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 219, 252, 139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 222, 252, 202, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 43, 253, 252, 89, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 85, 240, 253, 157, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 160, 253, 231, 42, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 142, 252, 252, 42, 30, 78, 161, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 184, 252, 252, 185, 228, 252, 252, 168, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 184, 252, 252, 253, 252, 252, 252, 116, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 179, 252, 253, 252, 252, 210, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 255, 253, 215, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 34, 89, 244, 253, 223, 98, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 116, 123, 142, 234, 252, 252, 184, 67, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 230, 253, 252, 252, 252, 168, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 126, 253, 252, 168, 43, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]], dtype=torch.uint8) . imgstr.shape . torch.Size([1, 28, 28]) . plt.imshow(imgstr.reshape(28, 28), cmap = &#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x18eb63fb8e0&gt; . threes = (path/&#39;training/3&#39;).ls() sevens = (path/&#39;training/7&#39;).ls() len(threes), len(sevens) . (6131, 6265) . X3 = torch.stack([torchvision.io.read_image(str(threes[i])) for i in range(6131)]) X7 = torch.stack([torchvision.io.read_image(str(sevens[i])) for i in range(6265)]) . X3.shape, X7.shape . (torch.Size([6131, 1, 28, 28]), torch.Size([6265, 1, 28, 28])) . X = torch.concat([X3, X7]) X.shape . torch.Size([12396, 1, 28, 28]) . Xnp = X.reshape(-1, 1 * 28 * 28).float() Xnp.shape . torch.Size([12396, 784]) . y = torch.tensor([0.0] * 6131 + [1.0] * 6265).reshape(-1, 1) y.shape . torch.Size([12396, 1]) . plt.plot(y, &#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x18eb6705310&gt;] . &quot;y = 0&quot;은 숫자 3을 의미, &quot;y = 1&quot;은 숫자 7을 의미 | 숫자 3은 6131개, 숫자 7은 6265개 있음 | . HW . - 네트워크 설계 . torch.manual_seed(201715447) net = torch.nn.Sequential(torch.nn.Linear(in_features = 1 * 28 * 28, out_features = 30), torch.nn.ReLU(), torch.nn.Linear(in_features = 30, out_features = 1), torch.nn.Sigmoid()) . $ underset{(n,784)}{ bf X} overset{l_1}{ to} underset{(n,30)}{ boldsymbol u^{(1)}} overset{a_1}{ to} underset{(n,30)}{ boldsymbol v^{(1)}} overset{l_1}{ to} underset{(n,1)}{ boldsymbol u^{(2)}} overset{a_2}{ to} underset{(n,1)}{ boldsymbol v^{(2)}}= underset{(n,1)}{ hat{ boldsymbol y}}$ | . loss_fn = torch.nn.BCELoss() . optimizer = torch.optim.Adam(net.parameters()) . for epoch in range(200): ## step 1 yhat = net(Xnp) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(y, &#39;o&#39;) plt.plot(net(Xnp).data, &#39;.&#39;, alpha = 0.2) . [&lt;matplotlib.lines.Line2D at 0x18eb67e1970&gt;] . (1) . - 숫자 0과 숫자 1을 구분하는 네트워크를 아래와 같은 구조로 설계 . $$ underset{(n,784)}{ bf X} overset{l_1}{ to} underset{(n,64)}{ boldsymbol u^{(1)}} overset{a_1}{ to} underset{(n,64)}{ boldsymbol v^{(1)}} overset{l_1}{ to} underset{(n,1)}{ boldsymbol u^{(2)}} overset{a_2}{ to} underset{(n,1)}{ boldsymbol v^{(2)}}= underset{(n,1)}{ hat{ boldsymbol y}}$$ . &#39;y = 0&#39;은 숫자 0을 의미하도록 하고, &#39;y = 1&#39;은 숫자 1을 의미하도록 설정 | . path = untar_data(URLs.MNIST) . X0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;training/0&#39;).ls()]) X1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/&#39;training/1&#39;).ls()]) X = torch.concat([X0, X1]).reshape(-1, 1 * 28 * 28).float() y = torch.tensor([0.0] * len(X0) + [1.0] * len(X1)).reshape(-1, 1) . torch.manual_seed(201715447) net = torch.nn.Sequential(torch.nn.Linear(in_features = 784, out_features = 64), torch.nn.ReLU(), torch.nn.Linear(in_features = 64, out_features = 1), torch.nn.Sigmoid()) . (2) . - 아래의 지침에 따라 200 epoch 학습을 진행 . 손실함수는 BCELoss를 이용. torch.nn.BCELoss() 이용 | 옵티마이저는 Adam으로 설정. 학습률은 lr = 0.002로 설정 | . loss_fn = torch.nn.BCELoss() optimizer = torch.optim.Adam(net.parameters(), lr = 0.002) . for epoch in range(200): ## step 1 yhat = net(X) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(y) plt.plot(yhat.data, &#39;.&#39;, alpha = 0.5) . [&lt;matplotlib.lines.Line2D at 0x18eb873b6a0&gt;] . (3) . - 아래의 지침에 따라 200 epoch 학습을 진행. 학습이 잘되는가? . 손실함수는 BCELoss를 이용. torch.nn.BCELoss()를 사용하지 않고 수식으로 직접 작성 | 옵티마이저는 Adam으로 설정. 학습률은 lr = 0.002로 설정 | . torch.manual_seed(201715447) net = torch.nn.Sequential(torch.nn.Linear(in_features = 784, out_features = 64), torch.nn.ReLU(), torch.nn.Linear(in_features = 64, out_features = 1), torch.nn.Sigmoid()) . optimizer = torch.optim.Adam(net.parameters(), lr = 0.002) . for epoch in range(200): ## step 1 yhat = net(X) ## step 2 loss = -torch.mean(y * torch.log(yhat) + (1 - y) * torch.log(1 - yhat)) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(y) plt.plot(yhat.data, &#39;.&#39;, alpha = 0.5) . [&lt;matplotlib.lines.Line2D at 0x18eb39c97f0&gt;] . yhat.data . tensor([[nan], [nan], [nan], ..., [nan], [nan], [nan]]) . 학습이 잘 이루어지지 않음! | . (4) . - 아래의 지침에 따라 200 epoch 학습을 진행. 학습이 잘 되는가? . 이미지의 값을 0과 1사이로 규격화. (Xnp = Xnp / 255를 이용) | 손실함수는 BCELoss를 이용. torch.nn.BCELoss()를 사용하지 않고 수식을 직접 입력 | 옵티마이저는 Adam으로 설정. 학습률은 lr = 0.002로 설정 | . X = X / 255 . torch.manual_seed(201715447) net = torch.nn.Sequential(torch.nn.Linear(in_features = 784, out_features = 64), torch.nn.ReLU(), torch.nn.Linear(in_features = 64, out_features = 1), torch.nn.Sigmoid()) . optimizer = torch.optim.Adam(net.parameters(), lr = 0.002) . for epoch in range(200): ## step 1 yhat = net(X) ## step 2 loss = -torch.mean(y * torch.log(yhat) + (1 - y) * torch.log(1 - yhat)) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(y) plt.plot(yhat.data, &#39;.&#39;, alpha = 0.5) . [&lt;matplotlib.lines.Line2D at 0x18eb86fa100&gt;] . 이번에는 학습이 잘 이루어짐! | . (5) . - 아래와 같은 수식을 이용하여 accuracy 계산 . $ text{accuracy}= frac{1}{n} sum_{i=1}^n I( tilde{y}_i=y_i)$ . $ tilde{y}_i = begin{cases} 1 &amp; hat{y}_i &gt; 0.5 0 &amp; hat{y}_i leq 0.5 end{cases}$ | $I( tilde{y}_i=y_i) = begin{cases} 1 &amp; tilde{y}_i=y_i 0 &amp; tilde{y}_i neq y_i end{cases}$ | . 단, $n$은 0과 1을 의미하는 이미지의 수 . (&#54400;&#51060; 1) . ytilde = (yhat &gt; 0.5) * 1 . $ tilde{y}_i = begin{cases} 1 &amp; hat{y}_i &gt; 0.5 0 &amp; hat{y}_i leq 0.5 end{cases}$ 의 구현 | . (ytilde == y) * 1 . tensor([[1], [1], [1], ..., [1], [1], [1]]) . $I( tilde{y}_i=y_i) = begin{cases} 1 &amp; tilde{y}_i=y_i 0 &amp; tilde{y}_i neq y_i end{cases}$ 의 구현 | . torch.sum((ytilde == y) * 1) . tensor(12661) . $ sum_{i=1}^n I( tilde{y}_i=y_i)$의 구현 | . torch.sum((ytilde == y) * 1) / len(y) . tensor(0.9997) . $ text{accuracy}= frac{1}{n} sum_{i=1}^n I( tilde{y}_i=y_i)$ 의 계산 | . (&#54400;&#51060; 2) . ((yhat &gt; 0.5) == y).sum() / len(y) . tensor(0.9997) . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/10/06/IABDL.html",
            "relUrl": "/2022/10/06/IABDL.html",
            "date": " • Oct 6, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "IAB딥러닝 10월 4일",
            "content": "Import . import torch import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns . import os os.environ[&#39;KMP_DUPLICATE_LIB_OK&#39;] = &#39;True&#39; # plt.plot 오류 발생 시 사용 . &#44032;&#51676; &#45936;&#51060;&#53552; . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex0.csv&#39;) df . x underlying y . 0 -1.000000 | 0.000045 | 0.0 | . 1 -0.998999 | 0.000046 | 0.0 | . 2 -0.997999 | 0.000047 | 0.0 | . 3 -0.996998 | 0.000047 | 0.0 | . 4 -0.995998 | 0.000048 | 0.0 | . ... ... | ... | ... | . 1995 0.995998 | 0.505002 | 0.0 | . 1996 0.996998 | 0.503752 | 0.0 | . 1997 0.997999 | 0.502501 | 0.0 | . 1998 0.998999 | 0.501251 | 1.0 | . 1999 1.000000 | 0.500000 | 1.0 | . 2000 rows × 3 columns . plt.plot(df.x, df.y, &#39;o&#39;, alpha = 0.02) plt.plot(df.x, df.underlying, &#39;-b&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767d0b6a30&gt;] . &#47196;&#51648;&#49828;&#54001; &#54924;&#44480;&#47196; &#51201;&#54633; . x = torch.tensor(df.x).float().reshape(-1, 1) y = torch.tensor(df.y).float().reshape(-1, 1) . net = torch.nn.Sequential(torch.nn.Linear(1, 1), torch.nn.Sigmoid()) yhat = net(x) . loss_fn = torch.nn.BCELoss() loss = loss_fn(yhat, y) # loss = -torch.mean((y) * torch.log(yhat) + (1 - y) * torch.log(1 - yhat)) loss . tensor(0.7233, grad_fn=&lt;BinaryCrossEntropyBackward0&gt;) . optimizer = torch.optim.Adam(net.parameters()) . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(df.x, df.underlying, &#39;--b&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767abfe820&gt;] . - 학습 . for epoch in range(6000): yhat = net(x) loss = loss_fn(yhat, y) loss.backward() optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(df.x, df.underlying, &#39;--b&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x2766e5ea610&gt;] . - epoch을 증가시켜도 예측이 어려움 --&gt; 모형의 표현력이 부족 . &#54644;&#44208;&#52293; . - sigmoide를 적용하기 전의 상태가 꺽인 그래프여야 가능함 . sig = torch.nn.Sigmoid() . fig, ax = plt.subplots(4, 2, figsize = (8, 8)) u1 = torch.tensor([-6, -4, -2, 0, 2, 4, 6]) u2 = torch.tensor([6, 4, 2, 0, -2, -4, -6]) u3 = torch.tensor([-6, -2, 2, 6, 2, -2, -6]) u4 = torch.tensor([-6, -2, 2, 6, 4, 2, 0]) ax[0, 0].plot(u1, &#39;--o&#39;, color = &#39;C0&#39;) ax[0, 1].plot(sig(u1), &#39;--o&#39;, color = &#39;C0&#39;) ax[1, 0].plot(u2, &#39;--o&#39;, color = &#39;C1&#39;) ax[1, 1].plot(sig(u2), &#39;--o&#39;, color = &#39;C1&#39;) ax[2, 0].plot(u3, &#39;--o&#39;, color = &#39;C2&#39;) ax[2, 1].plot(sig(u3), &#39;--o&#39;, color = &#39;C2&#39;) ax[3, 0].plot(u4, &#39;--o&#39;, color = &#39;C3&#39;) ax[3, 1].plot(sig(u4), &#39;--o&#39;, color = &#39;C3&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767df6ac70&gt;] . DNN&#51012; &#54876;&#50857;&#54616;&#50668; &#54644;&#44208; . - 목표: 아래와 같은 벡터 ${ boldsymbol u}$를 만들어보자. . ${ boldsymbol u} = [u_1,u_2, dots,u_{2000}], quad u_i = begin{cases} 9x_i +4.5&amp; x_i &lt;0 -4.5x_i + 4.5&amp; x_i &gt;0 end{cases}$ . &#44733;&#51064; &#44536;&#47000;&#54532;&#47484; &#47564;&#46300;&#45716; &#48169;&#48277; 1 . u = [9 * xi + 4.5 if xi &lt;0 else -4.5 * xi + 4.5 for xi in x.reshape(-1).tolist()] plt.plot(u, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767e010dc0&gt;] . &#44733;&#51064; &#44536;&#47000;&#54532;&#47484; &#47564;&#46300;&#45716; &#48169;&#48277; 2 . - 전략 : 선형변환 --&gt; ReLU --&gt; 선형변환 . ReLU 함수란? $ReLU(x) = max(0,x)$ . relu = torch.nn.ReLU() plt.plot(x, &#39;--r&#39;) plt.plot(relu(x), &#39;--b&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767e07e850&gt;] . - 빨간색 : x / 파란색 : relu(x) . &#49440;&#54805;&#48320;&#54872; 1 . plt.plot(x) plt.plot(-x) . [&lt;matplotlib.lines.Line2D at 0x2767e0eecd0&gt;] . ReLU . plt.plot(x, alpha = 0.2) plt.plot(-x, alpha = 0.5) plt.plot(relu(x), &#39;--&#39;, color = &#39;C0&#39;) plt.plot(relu(-x), &#39;--&#39;, color = &#39;C1&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767e1fbfa0&gt;] . &#49440;&#54805;&#48320;&#54872; 2 . plt.plot(x, alpha = 0.2) plt.plot(-x, alpha = 0.2) plt.plot(relu(x), &#39;--&#39;, color = &#39;C0&#39;, alpha = 0.2) plt.plot(relu(-x), &#39;--&#39;, color = &#39;C1&#39;, alpha = 0.2) plt.plot(-4.5 * relu(x) -9.0 * relu(-x) + 4.5, &#39;--&#39;, color = &#39;C2&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767f278580&gt;] . - 초록색 선에 sig를 취하면? . plt.plot(sig(-4.5 * relu(x) -9.0 * relu(-x) + 4.5), &#39;--&#39;, color = &#39;C2&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767f2b3dc0&gt;] . fig = plt.figure(figsize = (8, 4)) spec = fig.add_gridspec(4, 4) ax1 = fig.add_subplot(spec[:2, 0]) ax1.set_title(&#39;x&#39;) ax1.plot(x, &#39;--&#39;, color = &#39;C0&#39;) ax2 = fig.add_subplot(spec[2:, 0]) ax2.set_title(&#39;-x&#39;) ax2.plot(-x, &#39;--&#39;, color = &#39;C1&#39;) ax3 = fig.add_subplot(spec[:2, 1]) ax3.set_title(&#39;relu(x)&#39;) ax3.plot(relu(x), &#39;--&#39;, color = &#39;C0&#39;) ax4 = fig.add_subplot(spec[2:, 1]) ax4.set_title(&#39;relu(-x)&#39;) ax4.plot(relu(-x), &#39;--&#39;, color = &#39;C1&#39;) ax5 = fig.add_subplot(spec[1:3, 2]) ax5.set_title(&#39;u&#39;) ax5.plot(-4.5 * relu(x) -9 * relu(-x) + 4.5, &#39;--&#39;, color = &#39;C2&#39;) ax6 = fig.add_subplot(spec[1:3, 3]) ax6.set_title(&#39;yhat&#39;) ax6.plot(sig(-4.5 * relu(x) -9 * relu(-x) + 4.5), &#39;--&#39;, color = &#39;C2&#39;) fig.tight_layout() . torch.nn.Linear()&#47484; &#51060;&#50857;&#54620; &#44733;&#51064; &#44536;&#47000;&#54532; &#44396;&#54788; . torch.manual_seed(43052) l1 = torch.nn.Linear(in_features = 1, out_features = 2, bias = True) r1 = torch.nn.ReLU() l2 = torch.nn.Linear(in_features = 2, out_features = 1, bias = True) r2 = torch.nn.Sigmoid() . net = torch.nn.Sequential(l1, r1, l2, r2) . l1.weight, l1.bias, l2.weight, l2.bias . (Parameter containing: tensor([[-0.3467], [-0.8470]], requires_grad=True), Parameter containing: tensor([0.3604, 0.9336], requires_grad=True), Parameter containing: tensor([[ 0.2880, -0.6282]], requires_grad=True), Parameter containing: tensor([0.2304], requires_grad=True)) . l1.weight.data = torch.tensor([[1.0], [-1.0]]) l1.bias.data = torch.tensor([0.0, 0.0]) l2.weight.data = torch.tensor([[-4.5, -9.0]]) l2.bias.data = torch.tensor([4.5]) l1.weight, l1.bias, l2.weight, l2.bias . (Parameter containing: tensor([[ 1.], [-1.]], requires_grad=True), Parameter containing: tensor([0., 0.], requires_grad=True), Parameter containing: tensor([[-4.5000, -9.0000]], requires_grad=True), Parameter containing: tensor([4.5000], requires_grad=True)) . plt.plot(l1(x).data) . [&lt;matplotlib.lines.Line2D at 0x2767fa63280&gt;, &lt;matplotlib.lines.Line2D at 0x2767fa632e0&gt;] . plt.plot(r1(l1(x)).data) . [&lt;matplotlib.lines.Line2D at 0x2767fb24b50&gt;, &lt;matplotlib.lines.Line2D at 0x2767fb24bb0&gt;] . plt.plot(l2(r1(l1(x))).data, color = &#39;C2&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767fb5cb20&gt;] . plt.plot(r2(l2(r1(l1(x)))).data, color = &#39;C2&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767fbf27c0&gt;] . - 수식표현 . ${ bf X}= begin{bmatrix} x_1 dots x_n end{bmatrix}$ . | $l_1({ bf X})={ bf X}{ bf W}^{(1)} overset{bc}{+} { boldsymbol b}^{(1)}= begin{bmatrix} x_1 &amp; -x_1 x_2 &amp; -x_2 dots &amp; dots x_n &amp; -x_n end{bmatrix}$ . ${ bf W}^{(1)}= begin{bmatrix} 1 &amp; -1 end{bmatrix}$ | ${ boldsymbol b}^{(1)}= begin{bmatrix} 0 &amp; 0 end{bmatrix}$ | . | $(a_1 circ l_1)({ bf X})= text{relu} big({ bf X}{ bf W}^{(1)} overset{bc}{+}{ boldsymbol b}^{(1)} big)= begin{bmatrix} text{relu}(x_1) &amp; text{relu}(-x_1) text{relu}(x_2) &amp; text{relu}(-x_2) dots &amp; dots text{relu}(x_n) &amp; text{relu}(-x_n) end{bmatrix}$ . | $(l_2 circ a_1 circ l_1)({ bf X})= text{relu} big({ bf X}{ bf W}^{(1)} overset{bc}{+}{ boldsymbol b}^{(1)} big){ bf W}^{(2)} overset{bc}{+}b^{(2)} = begin{bmatrix} -4.5 times text{relu}(x_1) -9.0 times text{relu}(-x_1) +4.5 -4.5 times text{relu}(x_2) -9.0 times text{relu}(-x_2) + 4.5 dots -4.5 times text{relu}(x_n) -9.0 times text{relu}(-x_n)+4.5 end{bmatrix}$ . ${ bf W}^{(2)}= begin{bmatrix} -4.5 -9 end{bmatrix}$ | $b^{(2)}=4.5$ | . | $net({ bf X})=(a_2 circ l_2 circ a_1 circ l_1)({ bf X})= text{sig} Big( text{relu} big({ bf X}{ bf W}^{(1)} overset{bc}{+}{ boldsymbol b}^{(1)} big){ bf W}^{(2)} overset{bc}{+}b^{(2)} Big) = begin{bmatrix} text{sig} Big(-4.5 times text{relu}(x_1) -9.0 times text{relu}(-x_1) +4.5 Big) text{sig} Big(-4.5 times text{relu}(x_2) -9.0 times text{relu}(-x_2) + 4.5 Big) dots text{sig} Big(-4.5 times text{relu}(x_n) -9.0 times text{relu}(-x_n)+4.5 Big) end{bmatrix}$ . | - 차원만 따지면 . $ underset{(n,1)}{ bf X} overset{l_1}{ to} underset{(n,2)}{ boldsymbol u^{(1)}} overset{r_1}{ to} underset{(n,2)}{ boldsymbol v^{(1)}} overset{l_1}{ to} underset{(n,1)}{ boldsymbol u^{(2)}} overset{r_2}{ to} underset{(n,1)}{ boldsymbol v^{(2)}}= underset{(n,1)}{ hat{ boldsymbol y}}$ . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(x, df.underlying, &#39;-b&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767fc41940&gt;] . Step1 ~ Step4 . - 준비 . torch.manual_seed(43052) net = torch.nn.Sequential(torch.nn.Linear(in_features = 1, out_features = 2), torch.nn.ReLU(), torch.nn.Linear(in_features = 2, out_features = 1), torch.nn.Sigmoid()) . loss_fn = torch.nn.BCELoss() . optimizer = torch.optim.Adam(net.parameters()) . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(x, df.underlying, &#39;-b&#39;) plt.plot(x, net(x).data, &#39;--&#39;) plt.title(&#39;before&#39;) . Text(0.5, 1.0, &#39;before&#39;) . - 반복 . for epoch in range(3000): ## step 1 yhat = net(x) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(x, df.underlying, &#39;-b&#39;) plt.plot(x, net(x).data, &#39;--&#39;, color = &#39;C1&#39;) plt.title(&#39;epoch 3000&#39;) . Text(0.5, 1.0, &#39;epoch 3000&#39;) . for epoch in range(3000): ## step 1 yhat = net(x) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(x, df.underlying, &#39;-b&#39;) plt.plot(x, net(x).data, &#39;--&#39;, color = &#39;C1&#39;) plt.title(&#39;epoch 6000&#39;) . Text(0.5, 1.0, &#39;epoch 6000&#39;) . DNN&#51004;&#47196; &#54644;&#44208;&#44032;&#45733;&#54620; &#45796;&#50577;&#54620; &#50696;&#51228; . &#50696;&#51228; 1 . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex1.csv&#39;) df . x underlying y . 0 -1.000000 | 0.999877 | 1.0 | . 1 -0.998999 | 0.999875 | 1.0 | . 2 -0.997999 | 0.999873 | 1.0 | . 3 -0.996998 | 0.999871 | 1.0 | . 4 -0.995998 | 0.999869 | 1.0 | . ... ... | ... | ... | . 1995 0.995998 | 0.000123 | 0.0 | . 1996 0.996998 | 0.000123 | 0.0 | . 1997 0.997999 | 0.000123 | 0.0 | . 1998 0.998999 | 0.000123 | 0.0 | . 1999 1.000000 | 0.000123 | 0.0 | . 2000 rows × 3 columns . x = torch.tensor(df.x).float().reshape(-1, 1) y = torch.tensor(df.y).float().reshape(-1, 1) . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(df.x, df.underlying, &#39;-b&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767f781a30&gt;] . torch.manual_seed(43052) net = torch.nn.Sequential(torch.nn.Linear(in_features = 1, out_features = 16), torch.nn.ReLU(), torch.nn.Linear(in_features = 16, out_features = 1), torch.nn.Sigmoid()) . 위의 Sequential을 수식으로 표현 | $ underset{(n,1)}{ bf X} overset{l_1}{ to} underset{(n,16)}{ boldsymbol u^{(1)}} overset{a_1}{ to} underset{(n,16)}{ boldsymbol v^{(1)}} overset{l_1}{ to} underset{(n,1)}{ boldsymbol u^{(2)}} overset{a_2}{ to} underset{(n,1)}{ boldsymbol v^{(2)}}= underset{(n,1)}{ hat{ boldsymbol y}}$ | . loss_fn = torch.nn.BCELoss() . optimizer = torch.optim.Adam(net.parameters()) . for epoch in range(6000): ## step 1 yhat = net(x) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(df.x, df.underlying, &#39;-b&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767f6f26d0&gt;] . &#50696;&#51228; 2 . - 생각보다 꺽은선 조합으로 많은걸 표현할 수 있다. . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex2.csv&#39;) df . x underlying y . 0 -1.000000 | 14.791438 | 14.486265 | . 1 -0.999000 | 14.756562 | 14.832600 | . 2 -0.997999 | 14.721663 | 15.473211 | . 3 -0.996999 | 14.686739 | 14.757734 | . 4 -0.995998 | 14.651794 | 15.042901 | . ... ... | ... | ... | . 1995 0.995998 | 5.299511 | 5.511416 | . 1996 0.996999 | 5.322140 | 6.022263 | . 1997 0.997999 | 5.344736 | 4.989637 | . 1998 0.999000 | 5.367299 | 5.575369 | . 1999 1.000000 | 5.389829 | 5.466730 | . 2000 rows × 3 columns . x = torch.tensor(df.x).float().reshape(-1, 1) y = torch.tensor(df.y).float().reshape(-1, 1) . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(df.x, df.underlying, &#39;-b&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767f6d2be0&gt;] . (&#54400;&#51060; 1) . torch.manual_seed(201715447) net = torch.nn.Sequential(torch.nn.Linear(in_features = 1, out_features = 32), torch.nn.ReLU(), torch.nn.Linear(in_features = 32, out_features = 1)) . loss_fn = torch.nn.MSELoss() . optimizer = torch.optim.Adam(net.parameters()) . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(df.x, df.underlying, &#39;-b&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767fdabd90&gt;] . for epoch in range(6000): ## step 1 yhat = net(x) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(df.x, df.underlying, &#39;-b&#39;) plt.plot(x, net(x).data, lw = 4) . [&lt;matplotlib.lines.Line2D at 0x2767fe22af0&gt;] . (&#54400;&#51060; 2) . - 풀이1보다 더 잘맞음 --&gt; 초기의 좋은 값이 원인 . torch.manual_seed(5) net = torch.nn.Sequential(torch.nn.Linear(in_features = 1, out_features = 32), torch.nn.ReLU(), torch.nn.Linear(in_features = 32, out_features = 1)) . loss_fn = torch.nn.MSELoss() . optimizer = torch.optim.Adam(net.parameters()) . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(df.x, df.underlying, &#39;-b&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x2767ff107c0&gt;] . for epoch in range(6000): ## step 1 yhat = net(x) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;, alpha = 0.02) plt.plot(df.x, df.underlying, &#39;-b&#39;) plt.plot(x, net(x).data, lw = 4) . [&lt;matplotlib.lines.Line2D at 0x2767ff81640&gt;] . &#50696;&#51228; 3 . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex3.csv&#39;) df . x1 x2 y . 0 -0.874139 | 0.210035 | 0.0 | . 1 -1.143622 | -0.835728 | 1.0 | . 2 -0.383906 | -0.027954 | 0.0 | . 3 2.131652 | 0.748879 | 1.0 | . 4 2.411805 | 0.925588 | 1.0 | . ... ... | ... | ... | . 1995 -0.002797 | -0.040410 | 0.0 | . 1996 -1.003506 | 1.182736 | 0.0 | . 1997 1.388121 | 0.079317 | 0.0 | . 1998 0.080463 | 0.816024 | 1.0 | . 1999 -0.416859 | 0.067907 | 0.0 | . 2000 rows × 3 columns . sns.scatterplot(data = df, x = &#39;x1&#39;, y = &#39;x2&#39;, hue = &#39;y&#39;, alpha = 0.5, palette = {0 : (0.5, 0.0, 1.0), 1 : (1.0, 0.0, 0.0)}) . &lt;AxesSubplot:xlabel=&#39;x1&#39;, ylabel=&#39;x2&#39;&gt; . x1 = torch.tensor(df.x1).float().reshape(-1, 1) x2 = torch.tensor(df.x2).float().reshape(-1, 1) X = torch.concat([x1, x2], axis = 1) y = torch.tensor(df.y).float().reshape(-1, 1) . X.shape . torch.Size([2000, 2]) . torch.manual_seed(201715447) net = torch.nn.Sequential(torch.nn.Linear(in_features = 2, out_features = 32), torch.nn.ReLU(), torch.nn.Linear(in_features = 32, out_features = 1), torch.nn.Sigmoid()) . $ underset{(n,2)}{ bf X} overset{l_1}{ to} underset{(n,32)}{ boldsymbol u^{(1)}} overset{a_1}{ to} underset{(n,32)}{ boldsymbol v^{(1)}} overset{l_1}{ to} underset{(n,1)}{ boldsymbol u^{(2)}} overset{a_2}{ to} underset{(n,1)}{ boldsymbol v^{(2)}}= underset{(n,1)}{ hat{ boldsymbol y}}$ | . loss_fn = torch.nn.BCELoss() . optimizer = torch.optim.Adam(net.parameters()) . for epoch in range(3000): ## step 1 yhat = net(X) ## step 2 loss = loss_fn(yhat, y) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . df2 = df.assign(yhat = yhat.reshape(-1).detach().tolist()) df2 . x1 x2 y yhat . 0 -0.874139 | 0.210035 | 0.0 | 0.335968 | . 1 -1.143622 | -0.835728 | 1.0 | 0.642391 | . 2 -0.383906 | -0.027954 | 0.0 | 0.115918 | . 3 2.131652 | 0.748879 | 1.0 | 0.869468 | . 4 2.411805 | 0.925588 | 1.0 | 0.835479 | . ... ... | ... | ... | ... | . 1995 -0.002797 | -0.040410 | 0.0 | 0.245880 | . 1996 -1.003506 | 1.182736 | 0.0 | 0.413939 | . 1997 1.388121 | 0.079317 | 0.0 | 0.434655 | . 1998 0.080463 | 0.816024 | 1.0 | 0.362519 | . 1999 -0.416859 | 0.067907 | 0.0 | 0.121243 | . 2000 rows × 4 columns . sns.scatterplot(data = df2, x = &#39;x1&#39;, y = &#39;x2&#39;, hue = &#39;yhat&#39;, alpha = 0.5, palette = &#39;rainbow&#39;) . &lt;AxesSubplot:xlabel=&#39;x1&#39;, ylabel=&#39;x2&#39;&gt; . - 결과시각화 . fig, ax = plt.subplots(1, 2, figsize = (8, 4)) sns.scatterplot(data = df, x = &#39;x1&#39;, y = &#39;x2&#39;, hue = &#39;y&#39;, alpha = 0.5, palette = {0 : (0.5, 0.0, 1.0), 1 : (1.0, 0.0, 0.0)}, ax = ax[0]) sns.scatterplot(data = df2, x = &#39;x1&#39;, y = &#39;x2&#39;, hue = &#39;yhat&#39;, alpha = 0.5, palette = &#39;rainbow&#39;, ax = ax[1]) . &lt;AxesSubplot:xlabel=&#39;x1&#39;, ylabel=&#39;x2&#39;&gt; . Appedix : &#45936;&#51060;&#53552; &#49373;&#49457;&#53076;&#46300; . motivating example . np.random.seed(201715447) x = np.linspace(-1, 1, 2000).tolist() transform = lambda x : x * 15 + 5 if x&lt;0 else x * -5 + 5 u = list(map(transform, x)) v = torch.nn.Sigmoid()(torch.tensor(u)) y = torch.bernoulli(v) pd.DataFrame({&#39;x&#39; : x, &#39;underlying&#39; : v, &#39;y&#39; : y}).to_csv(&#39;2022-10-04-dnnex0.csv&#39;, index = False) . &#50696;&#51228; 1 . np.random.seed(201715447) x = np.linspace(-1, 1, 2000).tolist() def transform(x): if x &lt; -0.2: return -15 * x - 6 elif x &lt; 0.6: return 9 else: return -9 u = list(map(transform, x)) v = torch.nn.Sigmoid()(torch.tensor(u)) y = torch.bernoulli(v) pd.DataFrame({&#39;x&#39; : x, &#39;underlying&#39; : v, &#39;y&#39; : y}).to_csv(&#39;2022-10-04-dnnex1.csv&#39;, index = False) . &#50696;&#51228; 2 . torch.manual_seed(201715447) x = torch.linspace(-1, 1, 2000) eps = torch.randn(2000) * 0.5 fx = 2.5 + 4 * torch.exp(-x) + 5 * torch.cos(5 * x) y = fx + eps pd.DataFrame({&#39;x&#39; : x, &#39;underlying&#39; : fx, &#39;y&#39; : y}).to_csv(&#39;2022-10-04-dnnex2.csv&#39;, index = False) . &#50696;&#51228; 3 . x1, x2 = np.random.multivariate_normal([0, 0], [[1, 0.5], [0.5, 1]], 2000).T . np.random.seed(201715447) idx = np.linspace(-1, 1, 2000).tolist() def transform1(x1, x2): if x1 &lt; 0: return -3 * x1 - 3 elif x1 &lt; 0.6: return 0 elif x2 &gt; 1.5: return -0.5 * (x1)**2 - 10 * x2 + 5 else: return x1 + 2 * x2 - 2 u = torch.tensor(list(map(transform1, x1, x2))) v = torch.nn.Sigmoid()(u) y = torch.bernoulli(v) pd.DataFrame({&#39;x1&#39; : x1, &#39;x2&#39; : x2, &#39;y&#39; : y}).to_csv(&#39;2022-10-04-dnnex3.csv&#39;, index = False) . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/10/04/IABDL.html",
            "relUrl": "/2022/10/04/IABDL.html",
            "date": " • Oct 4, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "IAB딥러닝 9월 27일",
            "content": "Import . import torch import pandas as pd import numpy as np import matplotlib.pyplot as plt . import os os.environ[&#39;KMP_DUPLICATE_LIB_OK&#39;] = &#39;True&#39; # plt.plot 오류 발생 시 사용 . Logistic regression intro . motive . - 현실에 이러한 경우가 많음 . $x$가 커질수록 (혹은 작아질수록) 성공확률이 증가함 | . - (X, y)는 어떤 모양일까? . _df = pd.DataFrame({&#39;x&#39;:range(-6,7), &#39;y&#39;:[0,0,0,0,0,0,1,0,1,1,1,1,1]}) _df . x y . 0 -6 | 0 | . 1 -5 | 0 | . 2 -4 | 0 | . 3 -3 | 0 | . 4 -2 | 0 | . 5 -1 | 0 | . 6 0 | 1 | . 7 1 | 0 | . 8 2 | 1 | . 9 3 | 1 | . 10 4 | 1 | . 11 5 | 1 | . 12 6 | 1 | . plt.plot(_df.x, _df.y, &#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x2050dc2a400&gt;] . - 시그모이드(Sigmoid)라는 함수가 있음 . _x = torch.linspace(-6, 6, 100) def f(x): return torch.exp(x) / (1 + torch.exp(x)) . plt.plot(_df.x, _df.y, &#39;o&#39;) plt.plot(_x, f(_x)) . [&lt;matplotlib.lines.Line2D at 0x2050dfdfee0&gt;] . model . - $x$가 커질수록 $y=1$이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt; 암기!!! . $y_i sim Ber( pi_i), quad $ where $ pi_i = frac{ exp(w_0+w_1x_i)}{1+ exp(w_0+w_1x_i)}$ . | $ hat{y}_i= frac{ exp( hat{w}_0+ hat{w}_1x_i)}{1+ exp( hat{w}_0+ hat{w}_1x_i)}= frac{1}{1+ exp(- hat{w}_0- hat{w}_1x_i)}$ . | $loss= - sum_{i=1}^{n} big(y_i log( hat{y}_i)+(1-y_i) log(1- hat{y}_i) big)$ &lt; 암기!! . | . toy example . x = torch.linspace(-1, 1, 2000).reshape(2000, 1) w0 = -1 w1 = 5 u = w0 + x * w1 v = torch.exp(u) / (1 + torch.exp(u)) y = torch.bernoulli(v) . plt.scatter(x, y, alpha = 0.05) plt.plot(x, v, &#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x2050e059a00&gt;] . 우리의 목적: $x$가 들어가면 빨간선 $ hat{y}$의 값을 만들어주는 mapping을 학습 | . net &#49444;&#44228; . plt.scatter(x, y, alpha = 0.05) plt.plot(x, v, &#39;--r&#39;) w0hat = -0.8470 w1hat = -0.3467 plt.plot(x, f(x * w1hat + w0hat), &#39;--b&#39;) . [&lt;matplotlib.lines.Line2D at 0x2050f0eb730&gt;] . - f대신에 torch.nn.Sigmoid()를 사용해도 무방 . s1 = torch.nn.Sigmoid() . plt.scatter(x, y, alpha = 0.05) plt.plot(x, v, &#39;--r&#39;) w0hat = -0.8470 w1hat = -0.3467 plt.plot(x, s1(x * w1hat + w0hat), &#39;--b&#39;) . [&lt;matplotlib.lines.Line2D at 0x2050f163220&gt;] . - x * w1hat + w0hat 대신에 torch.nn.Linear()를 사용해도 무방 . torch.manual_seed(43052) l1 = torch.nn.Linear(in_features = 1, out_features = 1, bias = True) . l1.weight . Parameter containing: tensor([[-0.3467]], requires_grad=True) . l1.bias . Parameter containing: tensor([-0.8470], requires_grad=True) . plt.scatter(x, y, alpha = 0.05) plt.plot(x, v, &#39;--r&#39;) plt.plot(x, s1(l1(x)).data, &#39;--b&#39;) . [&lt;matplotlib.lines.Line2D at 0x2050f1d5250&gt;] . - 지금 $x overset{l1}{ to} u overset{s1}{ to} v = hat{y}$ 구조 . - l1,a1 을 sequential 하게 (직렬로) 엮어서 $ x overset{net}{ to} hat{y}$ 로 만들수 없을까? . net = torch.nn.Sequential(l1, s1) . plt.scatter(x, y, alpha = 0.05) plt.plot(x, v, &#39;--r&#39;) plt.plot(x, net(x).data, &#39;--b&#39;) . [&lt;matplotlib.lines.Line2D at 0x2050f220b80&gt;] . &#54617;&#49845; . - 옵티마이저를 설계하고 학습 . optimizer = torch.optim.SGD(net.parameters(), lr = 0.05) . - step 1 ~ 4 . for epoch in range(1000): ## step 1 yhat = net(x) ## step 2 loss = torch.mean((y - yhat) ** 2) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.scatter(x, y, alpha = 0.05) plt.plot(x, v, &#39;--r&#39;) plt.plot(x, net(x).data, &#39;--b&#39;) . [&lt;matplotlib.lines.Line2D at 0x205154a7d30&gt;] . - 5000번 추가 학습 . for epoch in range(5000): ## step 1 yhat = net(x) ## step 2 loss = torch.mean((y - yhat) ** 2) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.scatter(x, y, alpha = 0.05) plt.plot(x, v, &#39;--r&#39;) plt.plot(x, net(x).data, &#39;--b&#39;) . [&lt;matplotlib.lines.Line2D at 0x20515513310&gt;] . BCE loss . MSE loss VS BCE loss . - loss_fn1(MSE loss) / loss_fn2(BCE loss) . def loss_fn1(y, yhat): return torch.mean((y - yhat) ** 2) . def loss_fn2(y, yhat): return -torch.mean(y * torch.log(yhat) + (1 - y) * torch.log(1 - yhat)) . - loss_fn1, SGD, lr = 0.05 . torch.manual_seed(43052) net = torch.nn.Sequential(torch.nn.Linear(1, 1), torch.nn.Sigmoid()) optimizer = torch.optim.SGD(net.parameters(), lr = 0.05) for epoch in range(1000): ## step 1 yhat = net(x) ## step 2 loss = loss_fn1(y, yhat) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;, alpha = 0.05) plt.plot(x, v, &#39;--&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x20516e59c70&gt;] . - loss_fn2, SGD, lr = 0.05 . torch.manual_seed(43052) net = torch.nn.Sequential(torch.nn.Linear(1, 1), torch.nn.Sigmoid()) optimizer = torch.optim.SGD(net.parameters(), lr = 0.05) for epoch in range(1000): ## step 1 yhat = net(x) ## step 2 loss = loss_fn2(y, yhat) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;, alpha = 0.05) plt.plot(x, v, &#39;--&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x20516fa5220&gt;] . - loss_fn1 과 loss_fn2가 차이가 나는 이유 . - 손실함수의 모양이 다르기 때문! . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1, projection = &#39;3d&#39;) ax2 = fig.add_subplot(1, 2, 2, projection = &#39;3d&#39;) ax1.elev = 15 ax2.elev = 15 ax1.azim = 75 ax2.azim = 75 fig.set_figheight(8) fig.set_figwidth(8) . def plot_loss(loss_fn, ax): w0hat, w1hat = torch.meshgrid(torch.arange(-10, 3, 0.15), torch.arange(-1, 10, 0.15), indexing = &#39;ij&#39;) w0hat = w0hat.reshape(-1) w1hat = w1hat.reshape(-1) def l(w0hat, w1hat): yhat = torch.exp(w0hat + w1hat * x) / (1 + torch.exp(w0hat + w1hat * x)) return loss_fn(y, yhat) loss = list(map(l, w0hat, w1hat)) ax.scatter(w0hat, w1hat, loss, s = 0.1, alpha = 0.2) ax.scatter(-1, 5, l(-1, 5), s = 200, marker = &#39;*&#39;) . plot_loss(loss_fn1, ax1) plot_loss(loss_fn2, ax2) ax1.set_title(&#39;MSE loss&#39;) ax2.set_title(&#39;BCE loss&#39;) fig . 왼쪽 그림의 손실함수는 convex 하지 않다 | 오른쪽 그림의 손실함수는 convex 하다 | . def learn_and_record(net, loss_fn, optimizer): yhat_history = [] loss_history = [] what_history = [] for epoch in range(1000): ## step 1 yhat = net(x) ## step 2 loss = loss_fn(y, yhat) ## step 3 loss.backward() ## step 4 optimizer.step() optimizer.zero_grad() ## record if epoch % 20 == 0: yhat_history.append(yhat.reshape(-1).data.tolist()) loss_history.append(loss.item()) what_history.append([net[0].bias.data.item(), net[0].weight.data.item()]) return yhat_history, loss_history, what_history . - 애니메이션을 만들어주는 함수 제작 . from matplotlib import animation plt.rcParams[&#39;animation.html&#39;] = &#39;jshtml&#39; . def show_lrpr2(net, loss_fn, optimizer, suptitle = &#39;&#39;): yhat_history, loss_history, what_history = learn_and_record(net, loss_fn, optimizer) fig = plt.figure(figsize = (7, 2.5)) ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection = &#39;3d&#39;) ax1.set_xticks([]) ax1.set_yticks([]) ax2.set_xticks([]) ax2.set_yticks([]) ax2.set_zticks([]) ax2.elev = 15 ax2.azim = 75 ax1.plot(x, v, &#39;--&#39;) ax1.scatter(x, y, alpha = 0.05) line, = ax1.plot(x, yhat_history[0], &#39;--&#39;) plot_loss(loss_fn, ax2) fig.suptitle(suptitle) fig.tight_layout() def animate(epoch): line.set_ydata(yhat_history[epoch]) ax2.scatter(np.array(what_history)[epoch, 0], np.array(what_history)[epoch, 1], loss_history[epoch], color = &#39;grey&#39;) return line ani = animation.FuncAnimation(fig, animate, frames = 30) plt.close() return ani . &#49884;&#44033;&#54868; 1 : MSE loss, SGD, &#51339;&#51008;&#52488;&#44592;&#44050; . l1 = torch.nn.Linear(1, 1) s1 = torch.nn.Sigmoid() net = torch.nn.Sequential(l1, s1) optimizer = torch.optim.SGD(net.parameters(), lr = 0.05) . l1.bias.data = torch.tensor([-3.0]) l1.weight.data = torch.tensor([[-1.0]]) . show_lrpr2(net, loss_fn1, optimizer, &#39;MSE loss, SGD, good_init&#39;) . &lt;/input&gt; Once Loop Reflect &#49884;&#44033;&#54868; 2 : BCE loss, SGD, &#51339;&#51008;&#52488;&#44592;&#44050; . l1 = torch.nn.Linear(1, 1) s1 = torch.nn.Sigmoid() net = torch.nn.Sequential(l1, s1) optimizer = torch.optim.SGD(net.parameters(), lr = 0.05) . l1.bias.data = torch.tensor([-3.0]) l1.weight.data = torch.tensor([[-1.0]]) . show_lrpr2(net, loss_fn2, optimizer, &#39;BCE loss, SGD, good_init&#39;) . &lt;/input&gt; Once Loop Reflect &#49884;&#44033;&#54868; 3 : MSE loss, SGD, &#45208;&#49244;&#52488;&#44592;&#44050; . l1 = torch.nn.Linear(1, 1) s1 = torch.nn.Sigmoid() net = torch.nn.Sequential(l1, s1) optimizer = torch.optim.SGD(net.parameters(), lr = 0.05) . l1.bias.data = torch.tensor([-10.0]) l1.weight.data = torch.tensor([[-1.0]]) . show_lrpr2(net, loss_fn1, optimizer, &#39;MSE loss, SGD, good_init&#39;) . &lt;/input&gt; Once Loop Reflect &#49884;&#44033;&#54868; 4 : BCE loss, SGD, &#45208;&#49244;&#52488;&#44592;&#44050; . l1 = torch.nn.Linear(1, 1) s1 = torch.nn.Sigmoid() net = torch.nn.Sequential(l1, s1) optimizer = torch.optim.SGD(net.parameters(), lr = 0.05) . l1.bias.data = torch.tensor([-10.0]) l1.weight.data = torch.tensor([[-1.0]]) . show_lrpr2(net, loss_fn2, optimizer, &#39;MSE loss, SGD, good_init&#39;) . &lt;/input&gt; Once Loop Reflect HW . - 시각화 1 ~ 4에서 optimizer를 Adam으로 수정하여 진행 . &#49884;&#44033;&#54868; 1 : MSE loss, Adam, &#51339;&#51008;&#52488;&#44592;&#44050; . l1 = torch.nn.Linear(1, 1) s1 = torch.nn.Sigmoid() net = torch.nn.Sequential(l1, s1) optimizer = torch.optim.Adam(net.parameters(), lr = 0.05) . l1.bias.data = torch.tensor([-3.0]) l1.weight.data = torch.tensor([[-1.0]]) . show_lrpr2(net, loss_fn1, optimizer, &#39;MSE loss, Adam, good_init&#39;) . &lt;/input&gt; Once Loop Reflect &#49884;&#44033;&#54868; 2 : BCE loss, Adam, &#51339;&#51008;&#52488;&#44592;&#44050; . l1 = torch.nn.Linear(1, 1) s1 = torch.nn.Sigmoid() net = torch.nn.Sequential(l1, s1) optimizer = torch.optim.Adam(net.parameters(), lr = 0.05) . l1.bias.data = torch.tensor([-3.0]) l1.weight.data = torch.tensor([[-1.0]]) . show_lrpr2(net, loss_fn2, optimizer, &#39;BCE loss, Adam, good_init&#39;) . &lt;/input&gt; Once Loop Reflect &#49884;&#44033;&#54868; 3 : MSE loss, Adam, &#45208;&#49244;&#52488;&#44592;&#44050; . l1 = torch.nn.Linear(1, 1) s1 = torch.nn.Sigmoid() net = torch.nn.Sequential(l1, s1) optimizer = torch.optim.Adam(net.parameters(), lr = 0.05) . l1.bias.data = torch.tensor([-10.0]) l1.weight.data = torch.tensor([[-1.0]]) . show_lrpr2(net, loss_fn1, optimizer, &#39;MSE loss, Adam, good_init&#39;) . &lt;/input&gt; Once Loop Reflect &#49884;&#44033;&#54868; 4 : BCE loss, Adam, &#45208;&#49244;&#52488;&#44592;&#44050; . l1 = torch.nn.Linear(1, 1) s1 = torch.nn.Sigmoid() net = torch.nn.Sequential(l1, s1) optimizer = torch.optim.Adam(net.parameters(), lr = 0.05) . l1.bias.data = torch.tensor([-10.0]) l1.weight.data = torch.tensor([[-1.0]]) . show_lrpr2(net, loss_fn2, optimizer, &#39;MSE loss, Adam, good_init&#39;) . &lt;/input&gt; Once Loop Reflect - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/29/IABDL.html",
            "relUrl": "/2022/09/29/IABDL.html",
            "date": " • Sep 29, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "IAB딥러닝 9월 27일",
            "content": "Import . import torch import pandas as pd import numpy as np import matplotlib.pyplot as plt . import os os.environ[&#39;KMP_DUPLICATE_LIB_OK&#39;] = &#39;True&#39; # plt.plot 오류 발생 시 사용 . numpy&#50752; torch&#45716; &#48708;&#49847;&#54616;&#45796; . - torch.tensor() = np.array()처럼 생각해도 무방 . np.array([1, 2, 3]), torch.tensor([1, 2, 3]) . (array([1, 2, 3]), tensor([1, 2, 3])) . - 소수점 정밀도 차이가 조금 있음 . np.array([3.123456789]), torch.tensor([3.123456789]) . (array([3.12345679]), tensor([3.1235])) . - 기본적인 문법은 numpy 대신 torch를 사용해도 괜찮음 // 완전 같지는 않다 . np.arange(10), torch.arange(10) . (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])) . np.linspace(0, 1, 10), torch.linspace(0, 1, 10) . (array([0. , 0.11111111, 0.22222222, 0.33333333, 0.44444444, 0.55555556, 0.66666667, 0.77777778, 0.88888889, 1. ]), tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889, 1.0000])) . np.random.randn(10), torch.randn(10) . (array([-0.0394819 , -1.28231185, 0.52968028, -0.46039897, 0.86816715, 0.34182877, -0.79434121, -0.45743091, -0.64380063, 0.31566267]), tensor([ 1.5308, 0.3064, 2.1564, -0.6753, -0.5874, -0.1225, -0.7329, -0.8632, 0.7037, 0.7644])) . length $n$ vector, $n times 1$ col-vector, $1 times n$ row-vector . - 길이가 3인 벡터 선언방법 . a = torch.tensor([1, 2, 3]) a.shape . torch.Size([3]) . - 3x1 col-vec 선언방법 . (방법1) . a = torch.tensor([[1], [2], [3]]) a.shape . torch.Size([3, 1]) . (방법2) . a = torch.tensor([1, 2, 3]).reshape(3, 1) a.shape . torch.Size([3, 1]) . - 1x3 row-vec 선언방법 . (방법1) . a = torch.tensor([[1, 2, 3]]) a.shape . torch.Size([1, 3]) . (방법2) . a = torch.tensor([1, 2, 3]).reshape(1, 3) a.shape . torch.Size([1, 3]) . torch&#51032; dtype . - 기본적으로 torch는 소수점으로 저장되면 dtype = torch.float32로 설정 . tsr = torch.tensor([1.23, 2.34]) tsr . tensor([1.2300, 2.3400]) . tsr.dtype . torch.float32 . - 정수로 선언하더라고 dtype을 torch.float32로 설정하는게 유리함 . tsr = torch.tensor([1, 2]) tsr . tensor([1, 2]) . tsr.dtype . torch.int64 . (좋은예시 1) . tsr = torch.tensor([1, 2], dtype = torch.float32) tsr . tensor([1., 2.]) . tsr.dtype . torch.float32 . (좋은예시 2) . tsr = torch.tensor([1, 2.0]) tsr . tensor([1., 2.]) . tsr.dtype . torch.float32 . (int로 선언 후 float으로 변경 가능) . tsr = torch.tensor([1, 2]).float() tsr . tensor([1., 2.]) . tsr.dtype . torch.float32 . Shape of Vector . - 행렬곱셈에 대한 shape 조심 . A = torch.tensor([[2.00, 0.00], [0.00, 3.00]]) b1 = torch.tensor([[-1.0, -5.0]]) b2 = torch.tensor([[-1.0], [-5.0]]) b3 = torch.tensor([-1.0, -5.0]) . A.shape, b1.shape, b2.shape, b3.shape . (torch.Size([2, 2]), torch.Size([1, 2]), torch.Size([2, 1]), torch.Size([2])) . - A @ b1은 계산 불가능 / b1 @ A는 계산 가능 . A @ b1 . RuntimeError Traceback (most recent call last) Input In [27], in &lt;cell line: 1&gt;() -&gt; 1 A @ b1 RuntimeError: mat1 and mat2 shapes cannot be multiplied (2x2 and 1x2) . b1 @ A . tensor([[ -2., -15.]]) . - A @ b2는 계산 가능 / b2 @ A는 계산 불가능 . A @ b2 . tensor([[ -2.], [-15.]]) . b2 @ A . RuntimeError Traceback (most recent call last) Input In [30], in &lt;cell line: 1&gt;() -&gt; 1 b2 @ A RuntimeError: mat1 and mat2 shapes cannot be multiplied (2x1 and 2x2) . - A @ b3는 계산 가능 / b3 @ A는 계산 가능 . A @ b3 . tensor([ -2., -15.]) . (A @ b3).shape . torch.Size([2]) . b3 @ A . tensor([ -2., -15.]) . (b3 @ A).shape . torch.Size([2]) . - 브로드캐스팅 . a = torch.tensor([1, 2, 3]) a - 1 . tensor([0, 1, 2]) . b = torch.tensor([[1], [2], [3]]) b - 1 . tensor([[0], [1], [2]]) . a - b . tensor([[ 0, 1, 2], [-1, 0, 1], [-2, -1, 0]]) . Step 1&#51032; &#45796;&#47480;&#48260;&#51204; (&#48373;&#49845; + $ alpha$) . read data . df = pd.read_csv(&quot;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-22-regression.csv&quot;) df . x y . 0 -2.482113 | -8.542024 | . 1 -2.362146 | -6.576713 | . 2 -1.997295 | -5.949576 | . 3 -1.623936 | -4.479364 | . 4 -1.479192 | -4.251570 | . ... ... | ... | . 95 2.244400 | 10.325987 | . 96 2.393501 | 12.266493 | . 97 2.605604 | 13.098280 | . 98 2.605658 | 12.546793 | . 99 2.663240 | 13.834002 | . 100 rows × 2 columns . x = torch.tensor(df.x).float().reshape(100, 1) y = torch.tensor(df.y).float().reshape(100, 1) _1 = torch.ones([100, 1]) X = torch.concat([_1, x], axis = 1) . plt.plot(x, y, &#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x223f4ca3460&gt;] . ver1 : net = torch.nn.Linear(1, 1, bias = True) . - 준비 . net = torch.nn.Linear(1, 1, bias = True) net.weight.data = torch.tensor([[10.0]]) net.bias.data = torch.tensor([-5.0]) net.weight, net.bias . (Parameter containing: tensor([[10.]], requires_grad=True), Parameter containing: tensor([-5.], requires_grad=True)) . - step 1 . yhat = net(x) . plt.plot(x, y, &#39;o&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x223f7afb430&gt;] . - step 2 . loss = torch.mean((y - yhat) ** 2) . - step 3 . (미분 전) . net.bias, net.weight . (Parameter containing: tensor([-5.], requires_grad=True), Parameter containing: tensor([[10.]], requires_grad=True)) . net.bias.grad, net.weight.grad . (None, None) . (미분) . loss.backward() . (미분 후) . net.bias, net.weight . (Parameter containing: tensor([-5.], requires_grad=True), Parameter containing: tensor([[10.]], requires_grad=True)) . net.bias.grad, net.weight.grad . (tensor([-13.4225]), tensor([[11.8893]])) . - step 4 . (업데이터 전) . net.bias, net.weight . (Parameter containing: tensor([-5.], requires_grad=True), Parameter containing: tensor([[10.]], requires_grad=True)) . net.bias.grad, net.weight.grad . (tensor([-13.4225]), tensor([[11.8893]])) . (업데이트) . net.bias.data = net.bias.data - 0.1 * net.bias.grad net.weight.data = net.weight.data - 0.1 * net.weight.grad . net.bias.grad = None net.weight.grad = None . (업데이트 후) . net.bias, net.weight . (Parameter containing: tensor([-3.6577], requires_grad=True), Parameter containing: tensor([[8.8111]], requires_grad=True)) . net.bias.grad, net.weight.grad . (None, None) . - 반복 . for epoch in range(30): yhat = net(x) loss = torch.mean((y - yhat) ** 2) loss.backward() net.weight.data = net.weight.data - 0.1 * net.weight.grad net.bias.data = net.bias.data - 0.1 * net.bias.grad net.weight.grad = None net.bias.grad = None . plt.plot(x, y, &#39;o&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x223f7bb8100&gt;] . ver2 : net = torch.nn.Linear(2, 1, bias = False) . - 준비 . net = torch.nn.Linear(2, 1, bias = False) net.weight.data = torch.tensor([[-5.0, 10.0]]) . - step 1 . yhat = net(X) . - step 2 . loss = torch.mean((y - yhat) ** 2) . - step 3 . (미분 전) . net.weight . Parameter containing: tensor([[-5., 10.]], requires_grad=True) . net.weight.grad . (미분) . loss.backward() . (미분 후) . net.weight . Parameter containing: tensor([[-5., 10.]], requires_grad=True) . net.weight.grad . tensor([[-13.4225, 11.8893]]) . - step 4 . (업데이트 전) . net.weight . Parameter containing: tensor([[-5., 10.]], requires_grad=True) . net.weight.grad . tensor([[-13.4225, 11.8893]]) . (업데이트) . net.weight.data = net.weight.data - 0.1 * net.weight.grad . net.weight.grad = None . (업데이트 후) . net.weight . Parameter containing: tensor([[-3.6577, 8.8111]], requires_grad=True) . net.weight.grad . - 반복 . net = torch.nn.Linear(2, 1, bias = False) net.weight.data = torch.tensor([[-5.0, 10.0]]) . plt.plot(x, y, &#39;o&#39;) plt.plot(x, net(X).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x223fe24b6d0&gt;] . for epoch in range(30): yhat = net(X) loss = torch.mean((y - yhat) ** 2) loss.backward() net.weight.data = net.weight.data - 0.1 * net.weight.grad net.weight.grad = None . plt.plot(x, y, &#39;o&#39;) plt.plot(x, net(X).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x223fe295fa0&gt;] . step 4&#51032; &#45796;&#47480;&#48260;&#51204; : &#50741;&#54000;&#47560;&#51060;&#51200; . ver 1 : net = torch.nn.Linear(1, 1, bias = True) . - 준비 . net = torch.nn.Linear(1, 1) net.weight.data = torch.tensor([[10.0]]) net.bias.data = torch.tensor([[-5.0]]) . optimizer = torch.optim.SGD(net.parameters(), lr = 1 / 10) . - step 1 ~ 3 . yhat = net(x) . loss = torch.mean((y - yhat) ** 2) . loss.backward() . - step 4 . (업데이트 전) . net.weight.data, net.bias.data . (tensor([[10.]]), tensor([[-5.]])) . net.weight.grad, net.bias.grad . (tensor([[11.8893]]), tensor([[-13.4225]])) . (업데이트) . optimizer.step() optimizer.zero_grad() . (업데이트 후) . net.weight.data, net.bias.data . (tensor([[8.8111]]), tensor([[-3.6577]])) . net.weight.grad, net.bias.grad . (tensor([[0.]]), tensor([[0.]])) . - 반복 . net = torch.nn.Linear(1, 1) net.weight.data = torch.tensor([[10.0]]) net.bias.data = torch.tensor([-5.0]) optimizer = torch.optim.SGD(net.parameters(), lr = 1 / 10) . for epoch in range(30): yhat = net(x) loss = torch.mean((y - yhat) ** 2) loss.backward() optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x223fe2f7bb0&gt;] . ver2 : torch.nn.Linear(2, 1, bias = False) . net = torch.nn.Linear(2, 1, bias = False) net.weight.data = torch.tensor([[-5.0, 10.0]]) optimizer = torch.optim.SGD(net.parameters(), lr = 1 / 10) . for epoch in range(30): yhat = net(X) loss = torch.mean((y - yhat) ** 2) loss.backward() optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;) plt.plot(x, net(X).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x223fe354a30&gt;] . Appendix : net.parameters()&#51032; &#51032;&#48120; . - iterator, generator의 개념 필요 . - 네트워크 생성 . net = torch.nn.Linear(in_features = 1, out_features = 1) net.weight . Parameter containing: tensor([[-0.1294]], requires_grad=True) . net.bias . Parameter containing: tensor([0.6951], requires_grad=True) . set(dir(net.parameters)) &amp; {&#39;__iter__&#39;} . set() . set(dir(net.parameters())) &amp; {&#39;__iter__&#39;} . {&#39;__iter__&#39;} . - 무슨 의미일까? . _generator = net.parameters() . _generator.__next__() . Parameter containing: tensor([[-0.1294]], requires_grad=True) . _generator.__next__() . Parameter containing: tensor([0.6951], requires_grad=True) . _generator.__next__() . StopIteration Traceback (most recent call last) Input In [101], in &lt;cell line: 1&gt;() -&gt; 1 _generator.__next__() StopIteration: . - 이건 이런느낌? . _generator2 = iter([net.weight, net.bias]) . _generator2 . &lt;list_iterator at 0x223fe305a30&gt; . _generator2.__next__() . Parameter containing: tensor([[-0.1294]], requires_grad=True) . _generator2.__next__() . Parameter containing: tensor([0.6951], requires_grad=True) . _generator2.__next__() . StopIteration Traceback (most recent call last) Input In [106], in &lt;cell line: 1&gt;() -&gt; 1 _generator2.__next__() StopIteration: . - 즉, 아래의 코드는 같다 . _generator = net.parameters() torch.optim.SGD(_generator, lr = 1 / 10) ### 코드 2 _generator = iter([net.weight, net.bias]) torch.optim.SGD(_generator, lr = 1 / 10) ### 코드 3 _iterator = [net.weight, net.bias] torch.optim.SGD(_iterator, lr = 1 / 10) . SGD ( Parameter Group 0 dampening: 0 lr: 0.1 maximize: False momentum: 0 nesterov: False weight_decay: 0 ) . 결론 : net.parameters()는 net오브젝트에서 학습할 파라미터를 모두 모아 리스트(iterable object)로 만드는 함수 . - 응용예제 1 . What = torch.tensor([[-5.0], [10.0]], requires_grad = True) optimizer = torch.optim.SGD([What], lr = 1 / 10) . plt.plot(x, y, &#39;o&#39;) plt.plot(x, (X @ What).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x223fe409700&gt;] . for epoch in range(30): yhat = X @ What loss = torch.mean((y - yhat) ** 2) loss.backward() optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;) plt.plot(x, (X @ What).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x223fe38ad60&gt;] . - 응용예제 2 . b = torch.tensor(-5.0, requires_grad = True) w = torch.tensor(10.0, requires_grad = True) optimizer = torch.optim.SGD([b, w], lr = 1 / 10) . plt.plot(x, y, &#39;o&#39;) plt.plot(x, (w * x + b).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x223f72d03a0&gt;] . for epoch in range(30): yhat = b + w * x loss = torch.mean((y - yhat) ** 2) loss.backward() optimizer.step() optimizer.zero_grad() . plt.plot(x, y, &#39;o&#39;) plt.plot(x, (w * x + b).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x223ff466460&gt;] . Logistic regression . motive . - 현실에 이런 경우가 많음 . x가 커질수록 (혹은 작아질수록) 성공확률이 증가 | . - (X, y)는 어떤 모양? . _df = pd.DataFrame({&#39;x&#39;:range(-6,7),&#39;y&#39;:[0,0,0,0,0,0,1,0,1,1,1,1,1]}) _df . x y . 0 -6 | 0 | . 1 -5 | 0 | . 2 -4 | 0 | . 3 -3 | 0 | . 4 -2 | 0 | . 5 -1 | 0 | . 6 0 | 1 | . 7 1 | 0 | . 8 2 | 1 | . 9 3 | 1 | . 10 4 | 1 | . 11 5 | 1 | . 12 6 | 1 | . plt.plot(_df.x, _df.y, &#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x223ff4b86d0&gt;] . - 시그모이드 함수 구현 . xx = torch.linspace(-6, 6, 100) def f(x): return torch.exp(x) / (1 + torch.exp(x)) . plt.plot(_df.x, _df.y, &#39;o&#39;) plt.plot(xx, f(xx)) . [&lt;matplotlib.lines.Line2D at 0x223ff7e20d0&gt;] . model . - $x$가 커질수록 $y=1$이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt; 외우세요!!! . $y_i sim Ber( pi_i), quad $ where $ pi_i = frac{ exp(w_0+w_1x_i)}{1+ exp(w_0+w_1x_i)}$ . | $ hat{y}_i= frac{ exp( hat{w}_0+ hat{w}_1x_i)}{1+ exp( hat{w}_0+ hat{w}_1x_i)}= frac{1}{1+ exp(- hat{w}_0- hat{w}_1x_i)}$ . | $loss= - sum_{i=1}^{n} big(y_i log( hat{y}_i)+(1-y_i) log(1- hat{y}_i) big)$ &lt; 외우세요!! . | . toy example . - 예제시작 . x = torch.linspace(-1, 1, 2000).reshape(2000, 1) w0 = -1 w1 = 5 u = w0 + x * w1 v = torch.exp(u) / (1 + torch.exp(u)) y = torch.bernoulli(v) . plt.scatter(x, y, alpha = 0.05) plt.plot(x, v, &#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x223ff8d4100&gt;] . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/27/IABDL.html",
            "relUrl": "/2022/09/27/IABDL.html",
            "date": " • Sep 27, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "IAB딥러닝 9월 22일",
            "content": "Review . import torch import pandas as pd import numpy as np import matplotlib.pyplot as plt . import os os.environ[&#39;KMP_DUPLICATE_LIB_OK&#39;] = &#39;True&#39; # plt.plot 오류 발생 시 사용 . df = pd.read_csv(&quot;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-22-regression.csv&quot;) df . x y . 0 -2.482113 | -8.542024 | . 1 -2.362146 | -6.576713 | . 2 -1.997295 | -5.949576 | . 3 -1.623936 | -4.479364 | . 4 -1.479192 | -4.251570 | . ... ... | ... | . 95 2.244400 | 10.325987 | . 96 2.393501 | 12.266493 | . 97 2.605604 | 13.098280 | . 98 2.605658 | 12.546793 | . 99 2.663240 | 13.834002 | . 100 rows × 2 columns . x = torch.tensor(df.x, dtype=torch.float32).reshape(100, 1) y = torch.tensor(df.y, dtype=torch.float32).reshape(100, 1) X = torch.tensor([[1]*100, x]).T . What = torch.tensor([[-5.0], [10.0]], requires_grad = True) What . tensor([[-5.], [10.]], requires_grad=True) . plt.plot(x, y, &#39;o&#39;) plt.plot(x, X @ What.data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x270dd08bbb0&gt;] . ver1 : loss = sum of squares error . alpha = 1 / 1000 What = torch.tensor([[-5.0], [10.0]], requires_grad = True) for epoch in range(30): # step 1 : yhat yhat = X @ What # step 2 : loss loss = torch.sum((y - yhat) ** 2) # step 3 : 미분 loss.backward() # step 4 : update What.data = What.data - alpha * What.grad What.grad = None . What . tensor([[2.4290], [4.0144]], requires_grad=True) . plt.plot(x, y, &#39;o&#39;) plt.plot(x, X @ What.data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x270dd82e520&gt;] . ver2 : loss = mean squared error = MSE . alpha = 1/10 What = torch.tensor([[-5.0], [10.0]], requires_grad = True) for epoch in range(30): # step 1 : yhat yhat = X @ What # step 2 : loss loss = torch.mean((y - yhat) ** 2) # step 3 : 미분 loss.backward() # step 4 : update What.data = What.data - alpha * What.grad What.grad = None . What . tensor([[2.4290], [4.0144]], requires_grad=True) . step 1 &#45796;&#47480; ver . - ver1 : bias = True . torch.manual_seed(43052) net = torch.nn.Linear(in_features = 1, out_features = 1, bias = True) . plt.plot(x, y, &#39;o&#39;) plt.plot(x, net(x).data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x270e48c3bb0&gt;] . net.weight . Parameter containing: tensor([[-0.3467]], requires_grad=True) . net.bias . Parameter containing: tensor([-0.8470], requires_grad=True) . _yhat = -0.3467 * x - 0.8470 . plt.plot(x, y, &#39;o&#39;) plt.plot(x, _yhat, &#39;--&#39;) plt.plot(x, net(x).data, &#39;-.&#39;) . [&lt;matplotlib.lines.Line2D at 0x270e4933310&gt;] . - ver2 : 입력 x를 X로 입력 (X는 bias가 고려된 상황) . torch.manual_seed(43052) net = torch.nn.Linear(in_features = 2, out_features = 1, bias = False) . net.weight . Parameter containing: tensor([[-0.2451, -0.5989]], requires_grad=True) . plt.plot(x, y, &#39;o&#39;) plt.plot(x, net(X).data, &#39;--&#39;) plt.plot(x, X @ torch.tensor([[-0.2451], [-0.5989]]), &#39;-.&#39;) . [&lt;matplotlib.lines.Line2D at 0x270e76f6b80&gt;] . - 수식표현: $ hat{ bf y} = { bf X} { bf hat W} = begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots &amp; dots 1 &amp; x_{100} end{bmatrix} begin{bmatrix} -0.2451 -0.5989 end{bmatrix}$ . (1) &#51088;&#49888;&#51032; &#54617;&#48264;&#51004;&#47196; seed&#47484; &#49444;&#51221;&#54616;&#44256; &#54364;&#51456;&#51221;&#44508;&#48516;&#54252;&#50640;&#49436; 5&#44060;&#51032; &#45212;&#49688;&#47484; &#49373;&#49457; &#54980; &#49692;&#49436;&#45824;&#47196; &#51221;&#47148;&#54620; &#46244;&#50640; x&#50640; &#51200;&#51109; . torch.manual_seed(201715447) x,_ = torch.randn(5).sort() . (2) torch.nn.Linear()&#47484; &#51060;&#50857;&#54616;&#50668; &#51201;&#45817;&#54620; &#45348;&#53944;&#50892;&#53356; &#49373;&#49457; &#54980; net.weight &#54841;&#51008; net.bias&#51032; &#44050;&#51012; &#49688;&#51221; . x = x.reshape(-1, 1) X = torch.concat([torch.ones(5).reshape(-1, 1), x], axis = 1) . x, X . (tensor([[-1.2745], [-0.3031], [-0.1233], [ 0.2399], [ 1.4699]]), tensor([[ 1.0000, -1.2745], [ 1.0000, -0.3031], [ 1.0000, -0.1233], [ 1.0000, 0.2399], [ 1.0000, 1.4699]])) . ver1 : bias = True . net1 = torch.nn.Linear(in_features = 1, out_features = 1, bias = True) net1.weight.data, net1.bias.data . (tensor([[0.6365]]), tensor([-0.9915])) . net1.weight.data = torch.tensor([[2.5]]) net1.bias.data = torch.tensor([-7.0]) net1.weight.data, net1.bias.data . (tensor([[2.5000]]), tensor([-7.])) . net1(x), 2.5 * x - 7 . (tensor([[-10.1863], [ -7.7579], [ -7.3082], [ -6.4002], [ -3.3253]], grad_fn=&lt;AddmmBackward0&gt;), tensor([[-10.1863], [ -7.7579], [ -7.3082], [ -6.4002], [ -3.3253]])) . ver2 : bias = False . net2 = torch.nn.Linear(in_features = 2, out_features = 1, bias = False) net2.weight.data, net2.bias . (tensor([[-0.5855, 0.0121]]), None) . net2.weight.data = torch.tensor([[-7.0, 2.5]]) net2.weight.data . tensor([[-7.0000, 2.5000]]) . net2(X), 2.5 * x - 7 . (tensor([[-10.1863], [ -7.7579], [ -7.3082], [ -6.4002], [ -3.3253]], grad_fn=&lt;MmBackward0&gt;), tensor([[-10.1863], [ -7.7579], [ -7.3082], [ -6.4002], [ -3.3253]])) . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/22/IABDL.html",
            "relUrl": "/2022/09/22/IABDL.html",
            "date": " • Sep 22, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "IAB딥러닝 9월 20일",
            "content": "Import . import torch import numpy as np import matplotlib.pyplot as plt . import os os.environ[&#39;KMP_DUPLICATE_LIB_OK&#39;] = &#39;True&#39; # plt.plot 오류 발생 시 사용 . - numpy&#47928;&#48277; &#52280;&#44256;&#51088;&#47308; . (1) reshape : 2단계 참고 . https://guebin.github.io/IP2022/2022/04/06/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%946%EC%9D%BC.html . (2) concatenate, stack : 4단계 참고 . https://guebin.github.io/IP2022/2022/04/11/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%9411%EC%9D%BC.html . &#54924;&#44480;&#47784;&#54805; . - model: $y_i= w_0+w_1 x_i + epsilon_i = 2.5 + 4x_i + epsilon_i, quad i=1,2, dots,n$ . - model: ${ bf y}={ bf X}{ bf W} + boldsymbol{ epsilon}$ . ${ bf y}= begin{bmatrix} y_1 y_2 dots y_n end{bmatrix}, quad { bf X}= begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 dots 1 &amp; x_n end{bmatrix}, quad { bf W}= begin{bmatrix} 2.5 4 end{bmatrix}, quad boldsymbol{ epsilon}= begin{bmatrix} epsilon_1 dots epsilon_n end{bmatrix}$ | . &#54924;&#44480;&#47784;&#54805;&#50640;&#49436; &#45936;&#51060;&#53552; &#49373;&#49457; . torch.manual_seed(43052) ones= torch.ones(100) x,_ = torch.randn(100).sort() X = torch.stack([ones, x]).T # torch.stack([ones,x],axis=1) W = torch.tensor([2.5, 4]) ϵ = torch.randn(100) * 0.5 y = X @ W + ϵ . plt.plot(x, y, &#39;o&#39;) plt.plot(x, 2.5 + 4 * x, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x24e99b92a30&gt;] . &#54924;&#44480;&#47784;&#54805;&#50640;&#49436; &#54617;&#49845;&#51060;&#46976;? . - 파란점만 주어졌을때, 주황색 점선을 추정하는 것. 좀 더 정확하게 말하면 given data로 $ begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}$를 최대한 $ begin{bmatrix} 2.5 4 end{bmatrix}$와 비슷하게 찾는것. . given data : $ big {(x_i,y_i) big }_{i=1}^{n}$ . | parameter: ${ bf W}= begin{bmatrix} w_0 w_1 end{bmatrix}$ . | estimated parameter: ${ bf hat{W}}= begin{bmatrix} hat{w}_0 hat{w}_1 end{bmatrix}$ . | . plt.plot(x, y, &#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x24e9a331340&gt;] . - 시도: $( hat{w}_0, hat{w}_1)=(-5,10)$을 선택하여 선을 그려보고 적당한지 판단. . plt.plot(x, y, &#39;o&#39;) plt.plot(x, -5 + 10 * x, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x24836ad4f70&gt;] . - 벡터표현으로 주황색 점선을 계산 . What = torch.tensor([-5.0, 10.0]) . X.shape . torch.Size([100, 2]) . plt.plot(x, y, &#39;o&#39;) plt.plot(x, X @ What, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x24e9a38ecd0&gt;] . &#54028;&#46972;&#48120;&#53552;&#47484; &#54617;&#49845;&#54616;&#45716; &#48169;&#48277; . - 컴퓨터의 반복계산을 이용하여 추론 (손실함수 + 경사하강법) . - 전략 : 3단계 전략 . stage 1 : 아무 점선이나 그어본다. . | stage 2 : stage 1에서 그은 점선보다 더 좋은 점선으로 바꾼다. . | stage 3 : stage 1 - 2를 반복한다. . | . Stage 1 : &#51076;&#51032;&#51032; &#49440;&#51012; &#44536;&#50612;&#48376;&#45796;. . What = torch.tensor([-5.0, 10.0], requires_grad = True) What . tensor([-5., 10.], requires_grad=True) . yhat = X @ What . plt.plot(x, y, &#39;o&#39;) plt.plot(x, yhat.data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x24e9a3eed30&gt;] . Stage 2 : &#52395;&#48264;&#51704; &#49688;&#51221;. &#52572;&#52488;&#51032; &#51216;&#49440;&#50640; &#45824;&#54620; &#51201;&#45817;&#54620; &#51221;&#46020;&#47484; &#54032;&#45800;&#54616;&#44256; &#45908; &#51201;&#45817;&#54620; &#51216;&#49440;&#51004;&#47196; &#50629;&#45936;&#51060;&#53944;&#47484; &#54620;&#45796;. . - &#39;적당한 정도&#39;를 판단하기 위한 장치: loss function 도입! . $loss= sum_{i=1}^{n}(y_i- hat{y}_i)^2= sum_{i=1}^{n}(y_i-( hat{w}_0+ hat{w}_1x_i))^2$ . $=({ bf y}-{ bf hat{y}})^ top({ bf y}-{ bf hat{y}})=({ bf y}-{ bf X}{ bf hat{W}})^ top({ bf y}-{ bf X}{ bf hat{W}})$ . - loss 함수의 특징 . $y_i approx hat{y}_i$ 일수록 loss값이 작다. | $y_i approx hat{y}_i$ 이 되도록 $( hat{w}_0, hat{w}_1)$을 잘 찍으면 loss값이 작다. | (중요) 주황색 점선이 &#39;적당할 수록&#39; loss값이 작다. | . loss = torch.sum((y - yhat) ** 2) loss . tensor(8587.6875, grad_fn=&lt;SumBackward0&gt;) . - 목표 : loss값을 줄이는 것. . - 경사하강법 / 벡터미분 . - 경사하강법으로 loss를 줄이기 위해서는 $ frac{ partial}{ partial { bf W}}loss(w_0,w_1)$의 계산이 필요한데, 이를 위해서 벡터미분이 필요하다. (loss.backward()로 하면된다) . loss.backward() . What, What.grad . (tensor([-5., 10.], requires_grad=True), tensor([-1342.2522, 1188.9305])) . $loss(w_0,w_1)=({ bf y}- hat{ bf y})^ top ({ bf y}- hat{ bf y})=({ bf y}-{ bf XW})^ top ({ bf y}-{ bf XW})$ . | $ frac{ partial}{ partial { bf W} }loss(w_0,w_1)=-2{ bf X}^ top { bf y}+2{ bf X}^ top { bf X W}$ . | . -2 * X.T @ y + 2 * X.T @ X @ What . tensor([-1342.2522, 1188.9308], grad_fn=&lt;AddBackward0&gt;) . $ frac{ partial}{ partial { bf W} } loss(w_0,w_1)= begin{bmatrix} frac{ partial}{ partial w_0} frac{ partial}{ partial w_1} end{bmatrix}loss(w_0,w_1) = begin{bmatrix} frac{ partial}{ partial w_0}loss(w_0,w_1) frac{ partial}{ partial w_1}loss(w_0,w_1) end{bmatrix}$ . | $ frac{ partial}{ partial w_0}loss(w_0,w_1) approx frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}$ . | $ frac{ partial}{ partial w_1}loss(w_0,w_1) approx frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}$ . | . _lossfn = lambda w0, w1 : torch.sum((y - w0 - w1 * x) ** 2) _lossfn(-5, 10) . tensor(8587.6875) . h = 0.001 (_lossfn(-5 + h, 10) - _lossfn(-5, 10)) / h, (_lossfn(-5, 10 + h) - _lossfn(-5, 10)) / h . (tensor(-1341.7968), tensor(1190.4297)) . - 수정 전, 수정하는폭, 수정 후의 값 . alpha=0.001 print(&#39;수정전 : &#39; + str(What.data)) # What 에서 미분꼬리표를 떼고 싶다면? What.data or What.detach() print(&#39;수정하는폭 : &#39; + str(-alpha * What.grad)) print(&#39;수정후 : &#39; + str(What.data - alpha * What.grad)) print(&#39;*참값 : (2.5, 4)&#39; ) . 수정전 : tensor([-5., 10.]) 수정하는폭 : tensor([ 1.3423, -1.1889]) 수정후 : tensor([-3.6577, 8.8111]) *참값 : (2.5, 4) . - Wbefore, Wafter 계산 . Wbefore = What.data Wafter = What.data - alpha * What.grad Wbefore, Wafter . (tensor([-5., 10.]), tensor([-3.6577, 8.8111])) . - Wbefore, Wafter 시각화 . plt.plot(x, y, &#39;o&#39;) plt.plot(x, X @ Wbefore, &#39;--b&#39;) # 파란색 점선 plt.plot(x, X @ Wafter, &#39;--&#39;) # 주황색 점선 . [&lt;matplotlib.lines.Line2D at 0x24ea04d41c0&gt;] . Stage3: Learn (=estimate $ bf hat{W})$ . - 이 과정은 Stage 1, 2를 반복 . What = torch.tensor([-5.0, 10.0], requires_grad = True) . alpha = 0.001 for epoch in range(30): yhat = X @ What loss = torch.sum((y - yhat) ** 2) loss.backward() What.data = What.data - alpha * What.grad What.grad = None . - 반복결과 . What.data . tensor([2.4290, 4.0144]) . - 반복결과 시각화 . plt.plot(x, y, &#39;o&#39;) plt.plot(x, X @ What.data, &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x24ea6bfba60&gt;] . &#54617;&#49845;&#44284;&#51221; &#44592;&#47197; . loss_history = [] yhat_history = [] What_history = [] . What = torch.tensor([-5.0, 10.0], requires_grad = True) alpha = 0.001 for epoch in range(30): yhat = X @ What yhat_history.append(yhat.data.tolist()) loss = torch.sum((y - yhat) ** 2) loss_history.append(loss.item()) loss.backward() What.data = What.data - alpha * What.grad What_history.append(What.data.tolist()) What.grad = None . - epoch = 3 관찰 . plt.plot(x, y, &#39;o&#39;) plt.plot(x, yhat_history[2], &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x24ea6c98ac0&gt;] . - epoch = 10 관찰 . plt.plot(x, y, &#39;o&#39;) plt.plot(x, yhat_history[9], &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x24ea6ce3b80&gt;] . - epoch = 30 관찰 . plt.plot(x, y, &#39;o&#39;) plt.plot(x, yhat_history[29], &#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x24ea6d40eb0&gt;] . - $ hat{ bf W}$ 관찰 . What_history . [[-3.657747745513916, 8.81106948852539], [-2.554811477661133, 7.861191749572754], [-1.649186134338379, 7.101552963256836], [-0.9060712456703186, 6.49347448348999], [-0.2966785430908203, 6.006272315979004], [0.20277434587478638, 5.615575313568115], [0.6119105219841003, 5.302003383636475], [0.9469034671783447, 5.050129413604736], [1.2210699319839478, 4.847657680511475], [1.4453645944595337, 4.684779167175293], [1.6287915706634521, 4.553659439086914], [1.778746247291565, 4.448036193847656], [1.90129816532135, 4.3628973960876465], [2.0014259815216064, 4.294229507446289], [2.0832109451293945, 4.238814353942871], [2.149996757507324, 4.194070339202881], [2.204521894454956, 4.157923698425293], [2.249027729034424, 4.128708839416504], [2.285348415374756, 4.105085849761963], [2.31498384475708, 4.0859761238098145], [2.339160442352295, 4.070511341094971], [2.3588807582855225, 4.057991027832031], [2.3749637603759766, 4.0478515625], [2.3880786895751953, 4.039637088775635], [2.3987717628479004, 4.032979965209961], [2.40748929977417, 4.027583599090576], [2.414595603942871, 4.023208141326904], [2.4203879833221436, 4.019659042358398], [2.4251089096069336, 4.016779899597168], [2.4289560317993164, 4.014443874359131]] . - loss 관찰 . plt.plot(loss_history) . [&lt;matplotlib.lines.Line2D at 0x24ea6d9dc40&gt;] . &#54617;&#49845;&#44284;&#51221;&#51012; animation&#51012; &#51060;&#50857;&#54644; &#49884;&#44033;&#54868; . from matplotlib import animation . plt.rcParams[&#39;figure.figsize&#39;] = (7.5, 2.5) plt.rcParams[&#39;animation.html&#39;] = &#39;jshtml&#39; . fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection = &#39;3d&#39;) . - 왼쪽 plot . ax1.plot(x, y, &#39;o&#39;) line, = ax1.plot(x, yhat_history[0]) . fig . - 오른쪽 plot . _w0 = np.arange(-6, 11, 0.5) _w1 = np.arange(-6, 11, 0.5) w1, w0 = np.meshgrid(_w1, _w0) lss = w0 * 0 for i in range(len(_w0)): for j in range(len(_w1)): lss[i, j] = torch.sum((y - _w0[i] - _w1[j] * x) ** 2) ax2.plot_surface(w0, w1, lss, rstride = 1, cstride = 1, color = &#39;b&#39;, alpha = 0.35) ax2.azim = 40 ax2.dist = 8 ax2.elev = 5 . fig . ax2.scatter(2.5, 4, torch.sum((y - 2.5 - 4 * x) ** 2), s = 200, color = &#39;red&#39;, marker = &#39;*&#39;) . &lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x24ea6ed6dc0&gt; . fig . - 오른쪽 plot : $(w_0,w_1)=(-3.66, 8.81)$ 와 $loss(-3.66,8.81)$ 값 . What_history[0] . [-3.657747745513916, 8.81106948852539] . ax2.scatter(What_history[0][0], What_history[0][1], loss_history[0], color = &#39;blue&#39;) . &lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x24ea6f13820&gt; . fig . - 애니메이션 . def animate(epoch): line.set_ydata(yhat_history[epoch]) ax2.scatter(What_history[epoch][0], What_history[epoch][1], loss_history[epoch], color = &#39;blue&#39;) return line ani = animation.FuncAnimation(fig, animate, frames = 30) plt.close() ani . &lt;/input&gt; Once Loop Reflect - 위의 내용을 함수로 합침 . def show_lrpr(data, history): x, y = data loss_history, yhat_history, What_history = history fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(1, 2, 2, projection = &#39;3d&#39;) # ax1 --&gt; 왼쪽 plot ax1.plot(x, y, &#39;o&#39;) line, = ax1.plot(x, yhat_history[0]) # ax2 --&gt; 오른쪽 plot _w0 = np.arange(-6, 11, 0.5) _w1 = np.arange(-6, 11, 0.5) w1, w0 = np.meshgrid(_w1, _w0) lss = w0 * 0 for i in range(len(_w0)): for j in range(len(_w1)): lss[i, j] = torch.sum((y - _w0[i] - _w1[j] * x) ** 2) ax2.plot_surface(w0, w1, lss, rstride = 1, cstride = 1, color = &#39;b&#39;, alpha = 0.35) # 3d 곡면 생성 ax2.scatter(2.5, 4, torch.sum((y - 2.5 - 4 * x) ** 2), s = 200, color = &#39;red&#39;, marker = &#39;*&#39;) # 최소점 표시 ax2.scatter(What_history[0][0], What_history[0][1], loss_history[0], color = &#39;b&#39;) ax2.azim = 40 ax2.dist = 8 ax2.elev = 5 def animate(epoch): line.set_ydata(yhat_history[epoch]) ax2.scatter(np.array(What_history)[epoch, 0], np.array(What_history)[epoch, 1], loss_history[epoch], color = &#39;gray&#39;) return line ani = animation.FuncAnimation(fig, animate, frames = 30) plt.close() return ani . show_lrpr([x, y], [loss_history, yhat_history, What_history]) . &lt;/input&gt; Once Loop Reflect $ alpha$&#50640; &#45824;&#54616;&#50668; ($ alpha$&#45716; &#54617;&#49845;&#47456;) . (1) $ alpha$ = 0.0001 : $ alpha$&#44032; &#45320;&#47924; &#51089;&#51004;&#47732; --&gt; &#48708;&#54952;&#50984;&#51201; . loss_history = [] yhat_history = [] What_history = [] . What = torch.tensor([-5.0, 10.0], requires_grad = True) alpha = 0.0001 for epoch in range(30): yhat = X @ What yhat_history.append(yhat.data.tolist()) loss = torch.sum((y - yhat) ** 2) loss_history.append(loss.item()) loss.backward() What.data = What.data - alpha * What.grad What_history.append(What.data.tolist()) What.grad = None . show_lrpr([x, y], [loss_history, yhat_history, What_history]) . &lt;/input&gt; Once Loop Reflect (2) $ alpha$ = 0.0083 : $ alpha$&#44032; &#45320;&#47924; &#53356;&#45796;&#47732; --&gt; &#45796;&#47480; &#51032;&#48120;&#50640;&#49436; &#48708;&#54952;&#50984;&#51201; + &#50948;&#54744; . loss_history = [] yhat_history = [] What_history = [] . What = torch.tensor([-5.0, 10.0], requires_grad = True) alpha = 0.0083 for epoch in range(30): yhat = X @ What yhat_history.append(yhat.data.tolist()) loss = torch.sum((y - yhat) ** 2) loss_history.append(loss.item()) loss.backward() What.data = What.data - alpha * What.grad What_history.append(What.data.tolist()) What.grad = None . show_lrpr([x, y], [loss_history, yhat_history, What_history]) . &lt;/input&gt; Once Loop Reflect (3) $ alpha$ = 0.0085 . loss_history = [] yhat_history = [] What_history = [] . What = torch.tensor([-5.0, 10.0], requires_grad = True) alpha = 0.0085 for epoch in range(30): yhat = X @ What yhat_history.append(yhat.data.tolist()) loss = torch.sum((y - yhat) ** 2) loss_history.append(loss.item()) loss.backward() What.data = What.data - alpha * What.grad What_history.append(What.data.tolist()) What.grad = None . show_lrpr([x, y], [loss_history, yhat_history, What_history]) . &lt;/input&gt; Once Loop Reflect (3) $ alpha$ = 0.01 . loss_history = [] yhat_history = [] What_history = [] . What = torch.tensor([-5.0, 10.0], requires_grad = True) alpha = 0.01 for epoch in range(30): yhat = X @ What yhat_history.append(yhat.data.tolist()) loss = torch.sum((y - yhat) ** 2) loss_history.append(loss.item()) loss.backward() What.data = What.data - alpha * What.grad What_history.append(What.data.tolist()) What.grad = None . show_lrpr([x, y], [loss_history, yhat_history, What_history]) . &lt;/input&gt; Once Loop Reflect - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/20/IABDL.html",
            "relUrl": "/2022/09/20/IABDL.html",
            "date": " • Sep 20, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "IAB딥러닝 9월 19일",
            "content": "from fastai.vision.all import * from fastai.collab import * from fastai.text.all import * . 1. &#51060;&#48120;&#51648;&#51088;&#47308;&#48516;&#49437; . path = untar_data(URLs.MNIST_SAMPLE) . dls = ImageDataLoaders.from_folder(path, suffle = False) . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `number_workers` is changed to 0 to avoid getting stuck . dls.show_batch() . - cnn_learner를 이용하여 lrnr 오브젝트 생성 . arch = resnet34 | metrics = error_rate | . lrnr = vision_learner(dls, arch = resnet34, metrics = error_rate) . lrnr.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.290875 | 0.139522 | 0.046614 | 00:23 | . epoch train_loss valid_loss error_rate time . 0 | 0.053940 | 0.020497 | 0.006869 | 00:13 | . X, y = dls.one_batch() . X.shape # 64개의 이미지, 3채널, (28, 28)크기 . torch.Size([64, 3, 28, 28]) . show_image(X[0]) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . &lt;AxesSubplot:&gt; . lrnr.model(X[0].reshape(1, 3, 28, 28)) . TensorBase([[-4.9088, 5.3898]], device=&#39;cuda:0&#39;, grad_fn=&lt;AliasBackward0&gt;) . import numpy as np a = np.exp(-4.9088) b = np.exp(5.3898) print(&#39;3일 확률 : &#39;, a / (a + b)) print(&#39;7일 확률 : &#39;, b / (a + b)) . 3일 확률 : 3.3679080176154866e-05 7일 확률 : 0.9999663209198238 . lrnr.predict(X[0].to(&quot;cpu&quot;)) . (&#39;3&#39;, TensorBase(0), TensorBase([0.9966, 0.0034])) . 2. &#52628;&#52380;&#49884;&#49828;&#53596; . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv&#39;) df . user item rating item_name . 0 1 | 15 | 1.084308 | 홍차5 | . 1 1 | 1 | 4.149209 | 커피1 | . 2 1 | 11 | 1.142659 | 홍차1 | . 3 1 | 5 | 4.033415 | 커피5 | . 4 1 | 4 | 4.078139 | 커피4 | . ... ... | ... | ... | ... | . 995 100 | 18 | 4.104276 | 홍차8 | . 996 100 | 17 | 4.164773 | 홍차7 | . 997 100 | 14 | 4.026915 | 홍차4 | . 998 100 | 4 | 0.838720 | 커피4 | . 999 100 | 7 | 1.094826 | 커피7 | . 1000 rows × 4 columns . (1) 73&#48264; &#50976;&#51200;&#44032; &#47673;&#51008; &#50500;&#51060;&#53596; &#48143; &#54217;&#51216;&#51012; &#52636;&#47141;&#54616;&#45716; &#53076;&#46300;&#47484; &#51089;&#49457;. . df.query(&#39;user == 73&#39;) . user item rating item_name . 720 73 | 20 | 3.733853 | 홍차10 | . 721 73 | 18 | 3.975004 | 홍차8 | . 722 73 | 9 | 1.119541 | 커피9 | . 723 73 | 13 | 3.840801 | 홍차3 | . 724 73 | 2 | 0.943742 | 커피2 | . 725 73 | 4 | 1.152405 | 커피4 | . 726 73 | 1 | 0.887292 | 커피1 | . 727 73 | 7 | 0.947641 | 커피7 | . 728 73 | 6 | 0.868370 | 커피6 | . 729 73 | 17 | 3.873590 | 홍차7 | . (2) dls&#50752; lrnr &#50724;&#48652;&#51229;&#53944;&#47484; &#49373;&#49457;&#54616;&#44256; lrnr &#50724;&#48652;&#51229;&#53944;&#47484; &#54617;&#49845;. . dls = CollabDataLoaders.from_df(df) lrnr = collab_learner(dls, y_range = (0, 5)) . lrnr.fit(50) . epoch train_loss valid_loss time . 0 | 2.308994 | 2.355548 | 00:00 | . 1 | 2.306565 | 2.353840 | 00:00 | . 2 | 2.299696 | 2.340409 | 00:00 | . 3 | 2.280939 | 2.298518 | 00:00 | . 4 | 2.246671 | 2.214348 | 00:00 | . 5 | 2.189545 | 2.079250 | 00:00 | . 6 | 2.106238 | 1.893685 | 00:00 | . 7 | 1.993163 | 1.668546 | 00:00 | . 8 | 1.851504 | 1.418325 | 00:00 | . 9 | 1.686607 | 1.162084 | 00:00 | . 10 | 1.503044 | 0.919690 | 00:00 | . 11 | 1.314056 | 0.702645 | 00:00 | . 12 | 1.128208 | 0.522699 | 00:00 | . 13 | 0.952406 | 0.380159 | 00:00 | . 14 | 0.792922 | 0.274280 | 00:00 | . 15 | 0.653734 | 0.198446 | 00:00 | . 16 | 0.534922 | 0.146163 | 00:00 | . 17 | 0.435490 | 0.111528 | 00:00 | . 18 | 0.353936 | 0.088991 | 00:00 | . 19 | 0.287826 | 0.074637 | 00:00 | . 20 | 0.234859 | 0.064953 | 00:00 | . 21 | 0.192636 | 0.058722 | 00:00 | . 22 | 0.159204 | 0.054913 | 00:00 | . 23 | 0.132806 | 0.051880 | 00:00 | . 24 | 0.111807 | 0.050033 | 00:00 | . 25 | 0.095299 | 0.048970 | 00:00 | . 26 | 0.082377 | 0.047987 | 00:00 | . 27 | 0.071978 | 0.047371 | 00:00 | . 28 | 0.063799 | 0.047291 | 00:00 | . 29 | 0.057256 | 0.047057 | 00:00 | . 30 | 0.052145 | 0.046960 | 00:00 | . 31 | 0.048205 | 0.047008 | 00:00 | . 32 | 0.044957 | 0.046687 | 00:00 | . 33 | 0.042382 | 0.046597 | 00:00 | . 34 | 0.040269 | 0.046746 | 00:00 | . 35 | 0.038481 | 0.046838 | 00:00 | . 36 | 0.037097 | 0.047285 | 00:00 | . 37 | 0.036044 | 0.047355 | 00:00 | . 38 | 0.035167 | 0.047152 | 00:00 | . 39 | 0.034341 | 0.047297 | 00:00 | . 40 | 0.033596 | 0.047628 | 00:00 | . 41 | 0.032875 | 0.047863 | 00:00 | . 42 | 0.032257 | 0.047251 | 00:00 | . 43 | 0.031906 | 0.047225 | 00:00 | . 44 | 0.031499 | 0.047751 | 00:00 | . 45 | 0.030912 | 0.047885 | 00:00 | . 46 | 0.030393 | 0.048134 | 00:00 | . 47 | 0.030251 | 0.048073 | 00:00 | . 48 | 0.029833 | 0.047878 | 00:00 | . 49 | 0.029378 | 0.047627 | 00:00 | . (3) &#45936;&#51060;&#53552;&#54532;&#47112;&#51076; &#49373;&#49457; . df_new = pd.DataFrame({&#39;user&#39;:[73] * 20, &#39;item&#39;:range(1,21)}) df_new . user item . 0 73 | 1 | . 1 73 | 2 | . 2 73 | 3 | . 3 73 | 4 | . 4 73 | 5 | . 5 73 | 6 | . 6 73 | 7 | . 7 73 | 8 | . 8 73 | 9 | . 9 73 | 10 | . 10 73 | 11 | . 11 73 | 12 | . 12 73 | 13 | . 13 73 | 14 | . 14 73 | 15 | . 15 73 | 16 | . 16 73 | 17 | . 17 73 | 18 | . 18 73 | 19 | . 19 73 | 20 | . (4) 73&#48264; &#50976;&#51200;&#51032; &#52712;&#54693; &#54028;&#50501; . _dl = dls.test_dl(df_new) lrnr.get_preds(dl = _dl) . (tensor([0.9909, 1.0178, 1.0145, 1.0174, 0.9919, 0.9393, 1.0213, 1.0092, 1.0326, 0.9973, 3.8045, 3.8595, 3.8676, 3.8691, 3.8351, 3.8488, 3.8202, 3.8834, 3.7705, 3.8070]), None) . 3. &#49884;&#53248;&#49828;&#51088;&#47308;&#48516;&#49437; . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-19-human_numbers_100.csv&#39;) df . Unnamed: 0 text . 0 0 | one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve... | . 1 1 | one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve... | . 2 2 | one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve... | . 3 3 | one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve... | . 4 4 | one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve... | . ... ... | ... | . 1995 1995 | one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve... | . 1996 1996 | one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve... | . 1997 1997 | one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve... | . 1998 1998 | one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve... | . 1999 1999 | one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve... | . 2000 rows × 2 columns . (1) TextDataLoaders.from_df&#51012; &#51060;&#50857;&#54616;&#50668; dls &#50724;&#48652;&#51229;&#53944; &#49373;&#49457; . dls = TextDataLoaders.from_df(df, is_lm = True, seq_len = 5, text_col = &#39;text&#39;) dls.show_batch() . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `n_workers` has to be changed to 0 to avoid getting stuck . text text_ . 0 xxbos one , two , | one , two , three | . 1 hundred xxbos one , two | xxbos one , two , | . 2 one hundred xxbos one , | hundred xxbos one , two | . 3 , one hundred xxbos one | one hundred xxbos one , | . 4 nine , one hundred xxbos | , one hundred xxbos one | . 5 ninety nine , one hundred | nine , one hundred xxbos | . 6 , ninety nine , one | ninety nine , one hundred | . 7 eight , ninety nine , | , ninety nine , one | . 8 ninety eight , ninety nine | eight , ninety nine , | . (2) lrnr &#50724;&#48652;&#51229;&#53944; &#49373;&#49457; (arch = AWD_LSTM, metrics = accuracy) . lrnr = language_model_learner(dls, arch = AWD_LSTM, metrics = accuracy) . (3) lrnr &#50724;&#48652;&#51229;&#53944;&#50640;&#49436; fine_tune(3) &#47700;&#49548;&#46300;&#47484; &#51060;&#50857;&#54616;&#50668; &#47784;&#54805;&#51012; &#54617;&#49845; . lrnr.fine_tune(3) . epoch train_loss valid_loss accuracy time . 0 | 0.541494 | 0.157192 | 0.977558 | 00:52 | . epoch train_loss valid_loss accuracy time . 0 | 0.026514 | 0.004046 | 0.999242 | 00:55 | . 1 | 0.002075 | 0.002533 | 0.999315 | 00:55 | . 2 | 0.001414 | 0.002281 | 0.999324 | 00:55 | . lrnr.predict(&#39;one, two,&#39;, n_words = 50) . &#39;one , two , three , four , five , six , seven , eight , nine , ten , eleven , twelve , thirteen , fourteen , fifteen , sixteen , seventeen , eighteen , nineteen , twenty , twenty one , twenty two , twenty three , twenty four , twenty five&#39; . lrnr.predict(&#39;twenty, twenty one,&#39;, n_words = 50) . &#39;twenty , twenty one , thirty two , thirty three , thirty four , thirty five , thirty six , thirty seven , thirty eight , thirty nine , forty , forty one , forty two , forty three , forty four , forty five , forty six , forty seven , forty eight ,&#39; . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/19/IABDL.html",
            "relUrl": "/2022/09/19/IABDL.html",
            "date": " • Sep 19, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "IAB딥러닝 9월 15일",
            "content": "Import . from fastai.vision.all import * from fastai.vision.gan import * . &#51060;&#48120;&#51648;&#48516;&#49437;, &#52628;&#52380;&#49884;&#49828;&#53596;, &#53581;&#49828;&#53944;&#48516;&#49437;&#51032; &#51221;&#47532; . - 데이터는 모두 아래와 비슷하다. . (1) 데이터는 (X, y)의 형태로 정리되어 있음 . (2) y는 알고자 하는 값 즉, y를 적절하게 추정하는 것이 중요 . (3) X는 y를 추정하기 위해 필요한 정보 . $X$ = 설명변수 = 독립변수 $y$ = 반응변수 = 종속변수 비고 순서 예시 . 이미지 | 카테고리 | 합성곱신경망 | 상관없음 | 개/고양이 이미지 구분 | . 유저,아이템 | 평점 | 추천시스템 | 상관없음 | 넷플릭스 영화추천 | . 과거~오늘까지의주가 | 내일주가 | 순환신경망 | 순서상관있음 | 주가예측 | . 처음 $m$개의 단어(혹은 문장) | 이후 1개의 단어(혹은 문장) | 순환신경망 | 순서상관있음 | 챗봇, 텍스트생성 | . 처음 $m$개의 단어(혹은 문장) | 카테고리 | 순환신경망 | 순서상관있음 | 영화리뷰 텍스트 감정분류 | . - 학습이란 주어진 자료 (X, y)를 잘 분석하여 X에서 y로 가는 어떠한 규칙(맵핑, 함수, 모델, 네트워크) 혹은 원리를 찾는 것 . GAN . - GAN은 생성모형 중 하나 . - GAN의 원리는 경찰과 위조지폐범이 서로 경쟁을 통해 발전하는 모형으로 설명 가능 . - 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 생성(generate) . - 상황극 . 위조범 : 가짜 돈을 만들어보자! (가짜 돈 생성) . | 경찰 : 가짜 돈을 판별함 . | 위조범 : 더 정교하게 만들어야겠다! . | 경찰 : 진짜 돈인가? 가짜 돈인가? (구분이 어려워짐) . | 위조범 : 더 더 정교하게 만들자! . | 경찰 : 판별능력을 업그레이드 하자! . | 반복... . | . - 경찰이 진짜 돈과 가짜 돈을 구분하지 못할 때( = 진짜 이미지를 0.5의 확률로 진짜라고 판단할 때 = 가짜 이미지를 0.5의 확률로 가짜라고 판단할 때) 학습을 멈춤 . 1&#45800;&#44228; . path = untar_data(URLs.MNIST_SAMPLE) . . 100.14% [3219456/3214948 00:01&lt;00:00] dblock = DataBlock(blocks = (TransformBlock, ImageBlock), get_x = generate_noise, get_items = get_image_files, item_tfms = Resize(32)) dls = dblock.dataloaders(path) . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `number_workers` is changed to 0 to avoid getting stuck . dls.show_batch() . 2&#45800;&#44228; . counterfeiter = basic_generator(32, n_channels = 3, n_extra_layers = 1) # 32 * 32 컬러 이미지 출력 police = basic_critic(32, n_channels = 3, n_extra_layers = 1) # 32 * 32 컬러 이미지 입력 . lrnr = GANLearner.wgan(dls,counterfeiter,police) . 3&#45800;&#44228; . lrnr.fit(10) . C: Users USER anaconda3 lib site-packages fastai callback core.py:69: UserWarning: You are shadowing an attribute (generator) that exists in the learner. Use `self.learn.generator` to avoid this warn(f&#34;You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this&#34;) C: Users USER anaconda3 lib site-packages fastai callback core.py:69: UserWarning: You are shadowing an attribute (critic) that exists in the learner. Use `self.learn.critic` to avoid this warn(f&#34;You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this&#34;) C: Users USER anaconda3 lib site-packages fastai callback core.py:69: UserWarning: You are shadowing an attribute (gen_mode) that exists in the learner. Use `self.learn.gen_mode` to avoid this warn(f&#34;You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this&#34;) . epoch train_loss valid_loss gen_loss crit_loss time . 0 | -0.536390 | 0.351954 | 0.351954 | -0.755480 | 00:19 | . 1 | -0.575676 | 0.368697 | 0.368697 | -0.764731 | 00:17 | . 2 | -0.579221 | 0.401217 | 0.401217 | -0.761131 | 00:17 | . 3 | -0.578511 | 0.267153 | 0.267153 | -0.764614 | 00:16 | . 4 | -0.577176 | 0.245672 | 0.245672 | -0.754542 | 00:17 | . 5 | -0.561378 | 0.314552 | 0.314552 | -0.735245 | 00:17 | . 6 | -0.563071 | 0.291162 | 0.291162 | -0.738663 | 00:17 | . 7 | -0.551359 | 0.266653 | 0.266653 | -0.733204 | 00:17 | . 8 | -0.535449 | 0.339633 | 0.339633 | -0.735344 | 00:17 | . 9 | -0.502449 | 0.206701 | 0.206701 | -0.687934 | 00:17 | . lrnr.show_results() . lrnr.fit(20) # 추가로 20회 더 진행 . epoch train_loss valid_loss gen_loss crit_loss time . 0 | -0.463692 | 0.356721 | 0.356721 | -0.649763 | 00:17 | . 1 | -0.517553 | 0.192659 | 0.192659 | -0.432233 | 00:17 | . 2 | -0.537279 | 0.309562 | 0.309562 | -0.716175 | 00:17 | . 3 | -0.498665 | 0.248254 | 0.248254 | -0.710489 | 00:17 | . 4 | -0.516934 | 0.245185 | 0.245185 | -0.664505 | 00:17 | . 5 | -0.530214 | 0.292247 | 0.292247 | -0.728173 | 00:16 | . 6 | -0.512573 | 0.280468 | 0.280468 | -0.712356 | 00:16 | . 7 | -0.492679 | 0.284331 | 0.284331 | -0.664606 | 00:16 | . 8 | -0.365144 | 0.193021 | 0.193021 | -0.294480 | 00:16 | . 9 | -0.501201 | 0.332451 | 0.332451 | -0.693011 | 00:16 | . 10 | -0.342812 | 0.284920 | 0.284920 | -0.495047 | 00:16 | . 11 | -0.378736 | -0.022325 | -0.022325 | -0.185245 | 00:16 | . 12 | -0.470577 | 0.248631 | 0.248631 | -0.715788 | 00:16 | . 13 | -0.441847 | 0.215741 | 0.215741 | -0.645985 | 00:16 | . 14 | -0.449947 | -0.244867 | -0.244867 | -0.248203 | 00:16 | . 15 | -0.293098 | 0.146590 | 0.146590 | -0.276759 | 00:16 | . 16 | -0.443047 | 0.297963 | 0.297963 | -0.643778 | 00:16 | . 17 | -0.385012 | 0.259445 | 0.259445 | -0.578367 | 00:16 | . 18 | -0.372060 | 0.210893 | 0.210893 | -0.552931 | 00:16 | . 19 | -0.358579 | 0.086571 | 0.086571 | -0.561554 | 00:16 | . lrnr.show_results() . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/15/IABDL.html",
            "relUrl": "/2022/09/15/IABDL.html",
            "date": " • Sep 15, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "IAB딥러닝 9월 13일",
            "content": "Import . from fastai.collab import * # 추천시스템 from fastai.text.all import * # 텍스트분석 . import pandas as pd . fastai&#47484; &#51060;&#50857;&#54620; &#48516;&#49437; &#45800;&#44228; . 이미지분석(CNN) 추천시스템 텍스트분석 GAN . 1단계 | ImageDataLoaders | CollabDataLoaders | TextDataLoaders | DataBlock -&gt; dls | . 2단계 | cnn_learner() | collab_learner() | language_model_learner() | GANLearner.wgan() | . 3단계 | lrnr.fine_tune(1) | lrnr.fit() | lrnr.fit() | lrnr.fit() | . 4단계 | lrnr.predict(), lrnr.model(X) | lrnr.model(X) | lrnr.predict() | | . &#52628;&#52380;&#49884;&#49828;&#53596; . 1&#45800;&#44228; . df_view = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_view.csv&#39;) df_view . 커피1 커피2 커피3 커피4 커피5 커피6 커피7 커피8 커피9 커피10 홍차1 홍차2 홍차3 홍차4 홍차5 홍차6 홍차7 홍차8 홍차9 홍차10 . 0 4.149209 | NaN | NaN | 4.078139 | 4.033415 | 4.071871 | NaN | NaN | NaN | NaN | 1.142659 | 1.109452 | NaN | 0.603118 | 1.084308 | NaN | 0.906524 | NaN | NaN | 0.903826 | . 1 4.031811 | NaN | NaN | 3.822704 | NaN | NaN | NaN | 4.071410 | 3.996206 | NaN | NaN | 0.839565 | 1.011315 | NaN | 1.120552 | 0.911340 | NaN | 0.860954 | 0.871482 | NaN | . 2 4.082178 | 4.196436 | NaN | 3.956876 | NaN | NaN | NaN | 4.450931 | 3.972090 | NaN | NaN | NaN | NaN | 0.983838 | NaN | 0.918576 | 1.206796 | 0.913116 | NaN | 0.956194 | . 3 NaN | 4.000621 | 3.895570 | NaN | 3.838781 | 3.967183 | NaN | NaN | NaN | 4.105741 | 1.147554 | NaN | 1.346860 | NaN | 0.614099 | 1.297301 | NaN | NaN | NaN | 1.147545 | . 4 NaN | NaN | NaN | NaN | 3.888208 | NaN | 3.970330 | 3.979490 | NaN | 4.010982 | NaN | 0.920995 | 1.081111 | 0.999345 | NaN | 1.195183 | NaN | 0.818332 | 1.236331 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 95 0.511905 | 1.066144 | NaN | 1.315430 | NaN | 1.285778 | NaN | 0.678400 | 1.023020 | 0.886803 | NaN | 4.055996 | NaN | NaN | 4.156489 | 4.127622 | NaN | NaN | NaN | NaN | . 96 NaN | 1.035022 | NaN | 1.085834 | NaN | 0.812558 | NaN | 1.074543 | NaN | 0.852806 | 3.894772 | NaN | 4.071385 | 3.935935 | NaN | NaN | 3.989815 | NaN | NaN | 4.267142 | . 97 NaN | 1.115511 | NaN | 1.101395 | 0.878614 | NaN | NaN | NaN | 1.329319 | NaN | 4.125190 | NaN | 4.354638 | 3.811209 | 4.144648 | NaN | NaN | 4.116915 | 3.887823 | NaN | . 98 NaN | 0.850794 | NaN | NaN | 0.927884 | 0.669895 | NaN | NaN | 0.665429 | 1.387329 | NaN | NaN | 4.329404 | 4.111706 | 3.960197 | NaN | NaN | NaN | 3.725288 | 4.122072 | . 99 NaN | NaN | 1.413968 | 0.838720 | NaN | NaN | 1.094826 | 0.987888 | NaN | 1.177387 | 3.957383 | 4.136731 | NaN | 4.026915 | NaN | NaN | 4.164773 | 4.104276 | NaN | NaN | . 100 rows × 20 columns . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv&#39;) df . user item rating item_name . 0 1 | 15 | 1.084308 | 홍차5 | . 1 1 | 1 | 4.149209 | 커피1 | . 2 1 | 11 | 1.142659 | 홍차1 | . 3 1 | 5 | 4.033415 | 커피5 | . 4 1 | 4 | 4.078139 | 커피4 | . ... ... | ... | ... | ... | . 995 100 | 18 | 4.104276 | 홍차8 | . 996 100 | 17 | 4.164773 | 홍차7 | . 997 100 | 14 | 4.026915 | 홍차4 | . 998 100 | 4 | 0.838720 | 커피4 | . 999 100 | 7 | 1.094826 | 커피7 | . 1000 rows × 4 columns . df.item.unique(), df.user.unique() # unique()는 데이터에 고유값들이 어떠한 종류들이 있는지 알고 싶을 때 사용하는 함수 . (array([15, 1, 11, 5, 4, 14, 6, 20, 12, 17, 8, 9, 13, 19, 18, 16, 2, 3, 10, 7], dtype=int64), array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100], dtype=int64)) . dls = CollabDataLoaders.from_df(df) #협업 필터링에 적합한 항목 생성 . dls.show_batch() . user item rating . 0 78 | 13 | 4.020114 | . 1 14 | 1 | 4.329083 | . 2 52 | 16 | 4.008471 | . 3 79 | 15 | 4.105639 | . 4 16 | 14 | 0.946549 | . 5 98 | 11 | 4.125190 | . 6 12 | 9 | 4.502565 | . 7 80 | 13 | 3.725410 | . 8 5 | 10 | 4.010983 | . 9 76 | 2 | 0.725603 | . X, y = dls.one_batch() . X[0], y[0] # 60번 유저가 3번 아이템을 먹었을 때, 평점 1.1309 . (tensor([60, 3]), tensor([1.1309])) . 2&#45800;&#44228; . lrnr = collab_learner(dls, y_range = (0, 5)) . lrnr.fit(30) . epoch train_loss valid_loss time . 0 | 0.982962 | 0.960218 | 00:00 | . 1 | 0.854534 | 0.739310 | 00:00 | . 2 | 0.728671 | 0.549827 | 00:00 | . 3 | 0.612306 | 0.398833 | 00:00 | . 4 | 0.508047 | 0.283823 | 00:00 | . 5 | 0.416964 | 0.201994 | 00:00 | . 6 | 0.340235 | 0.146098 | 00:00 | . 7 | 0.277236 | 0.109585 | 00:00 | . 8 | 0.226001 | 0.086219 | 00:00 | . 9 | 0.185047 | 0.071640 | 00:00 | . 10 | 0.152903 | 0.062686 | 00:00 | . 11 | 0.127411 | 0.057081 | 00:00 | . 12 | 0.107212 | 0.053650 | 00:00 | . 13 | 0.091557 | 0.051878 | 00:00 | . 14 | 0.078987 | 0.050590 | 00:00 | . 15 | 0.069260 | 0.050028 | 00:00 | . 16 | 0.061507 | 0.049620 | 00:00 | . 17 | 0.055520 | 0.049438 | 00:00 | . 18 | 0.050674 | 0.049544 | 00:00 | . 19 | 0.046964 | 0.049867 | 00:00 | . 20 | 0.043926 | 0.049945 | 00:00 | . 21 | 0.041574 | 0.050093 | 00:00 | . 22 | 0.039657 | 0.049922 | 00:00 | . 23 | 0.038015 | 0.049928 | 00:00 | . 24 | 0.036744 | 0.049870 | 00:00 | . 25 | 0.035572 | 0.049686 | 00:00 | . 26 | 0.034816 | 0.049891 | 00:00 | . 27 | 0.034127 | 0.049548 | 00:00 | . 28 | 0.033472 | 0.049744 | 00:00 | . 29 | 0.032938 | 0.049897 | 00:00 | . 4&#45800;&#44228; . yhat = lrnr.model(X.to(&quot;cuda:0&quot;)) yhat . tensor([1.0497, 1.0491, 3.8868, 1.0842, 1.0308, 3.9974, 3.9883, 3.9073, 3.8864, 3.9928, 1.0348, 4.0798, 1.0885, 0.9187, 4.1383, 4.0982, 4.1652, 3.8058, 0.9393, 4.0877, 4.0433, 1.0097, 0.8921, 0.8991, 4.1124, 0.9828, 1.0059, 1.0155, 0.9488, 0.9874, 3.9683, 1.0021, 1.0736, 0.9726, 0.9243, 0.9903, 4.0987, 3.9215, 4.0557, 0.8602, 3.8443, 4.0904, 4.0177, 0.9665, 1.0474, 4.0748, 1.1496, 0.9478, 4.0791, 1.1091, 4.0488, 1.0230, 4.0360, 4.0741, 0.7673, 3.9696, 1.0462, 3.9625, 4.1699, 1.0259, 4.0511, 3.9820, 0.9829, 3.9767], device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;) . X.shape . torch.Size([64, 2]) . X[0:1] . tensor([[60, 3]]) . lrnr.model(X[0:1].to(&quot;cuda:0&quot;)) . tensor([1.0497], device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;) . - 새로운 데이터 생성 후 예측 . Xnew = torch.tensor([[1, 2]]) . lrnr.model(Xnew.to(&quot;cuda:0&quot;)) . tensor([3.9995], device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;) . &#53581;&#49828;&#53944;&#48516;&#49437; . 1&#45800;&#44228; . df = pd.DataFrame({&#39;text&#39; : [&#39;h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??&#39;] * 20000}) df . text . 0 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 1 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 2 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 3 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 4 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . ... ... | . 19995 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19996 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19997 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19998 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19999 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 20000 rows × 1 columns . dls = TextDataLoaders.from_df(df, text_col = &#39;text&#39;, is_lm = True) . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `n_workers` has to be changed to 0 to avoid getting stuck . dls.show_batch() . text text_ . 0 xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o | h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . | . 1 ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l | xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o | . 2 ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l | ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l | . 3 o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e | ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l | . 4 l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h | o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e | . 5 l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos | l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h | . 6 e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? | l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos | . 7 h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? | e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? | . 8 ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o | h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? | . 2&#45800;&#44228; . lrnr = language_model_learner(dls, AWD_LSTM) . . 100.00% [105070592/105067061 00:07&lt;00:00] lrnr.fit(20) . epoch train_loss valid_loss time . 0 | 0.953486 | 0.372985 | 00:13 | . 1 | 0.617590 | 0.249084 | 00:13 | . 2 | 0.475271 | 0.214262 | 00:13 | . 3 | 0.382338 | 0.186492 | 00:13 | . 4 | 0.365782 | 0.170414 | 00:13 | . 5 | 0.324649 | 0.150192 | 00:13 | . 6 | 0.322575 | 0.135068 | 00:13 | . 7 | 0.297149 | 0.119661 | 00:13 | . 8 | 0.268460 | 0.103948 | 00:13 | . 9 | 0.236526 | 0.085444 | 00:13 | . 10 | 0.234326 | 0.071486 | 00:13 | . 11 | 0.202645 | 0.055195 | 00:13 | . 12 | 0.180042 | 0.041449 | 00:13 | . 13 | 0.181329 | 0.032187 | 00:13 | . 14 | 0.160750 | 0.025342 | 00:13 | . 15 | 0.157359 | 0.021769 | 00:13 | . 16 | 0.141533 | 0.017457 | 00:13 | . 17 | 0.133610 | 0.015023 | 00:13 | . 18 | 0.128645 | 0.012770 | 00:13 | . 19 | 0.100870 | 0.011586 | 00:13 | . lrnr.predict(&#39;h &#39;, n_words = 30) . &#39;h e l l o . h e l l o ! h e l l o ? ? h e l l o . h e l l o&#39; . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/13/IABDL.html",
            "relUrl": "/2022/09/13/IABDL.html",
            "date": " • Sep 13, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "IAB딥러닝 9월 8일",
            "content": "Import . from fastai.vision.all import * . &#48373;&#49845; . (1) &#45936;&#51060;&#53552; &#51221;&#47532; . path = untar_data(URLs.PETS) / &#39;images&#39; . fnames = get_image_files(path) . def label_func(fname): if fname[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . dls = ImageDataLoaders.from_name_func(path, fnames, label_func, item_tfms = Resize(224)) . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `number_workers` is changed to 0 to avoid getting stuck . (2) lrnr &#50724;&#48652;&#51229;&#53944; &#49373;&#49457; . lrnr = vision_learner(dls, resnet34, metrics = error_rate) . (3) lrnr &#54617;&#49845; . lrnr.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.150615 | 0.036099 | 0.011502 | 00:35 | . epoch train_loss valid_loss error_rate time . 0 | 0.063639 | 0.034654 | 0.009472 | 00:38 | . (4) lrnr &#50696;&#52769; . lrnr.predict(path.ls()[0]) # 방법1 # lrnr.predict(&#39;2022-09-06-hani03.jpg&#39;) 방법2 # X, y = dls.one_batch() # lrnr.model(X[0 : 1]) 방법3 . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 9.7220e-09])) . &#54532;&#47196;&#44536;&#47000;&#48141; &#44284;&#51221; overview . dls &#50724;&#48652;&#51229;&#53944; &#49373;&#49457; --&gt; lrnr &#50724;&#48652;&#51229;&#53944; &#49373;&#49457; --&gt; lrnr &#54617;&#49845; --&gt; lrnr &#50696;&#52769; . &#48708;&#44368; . 회귀분석(R) 이미지분석(CNN) 추천시스템 . 1단계 | data.frame() | ImageDataLoaders.from_name_func() | CollabDataLoaders.from_df() | . 2단계 | None | cnn_learner() | collab_learner() | . 3단계 | lm(y~x1+x2,df) | lrnr.fine_tune(1) | lrnr.fit() | . 4단계 | predict(ob,newdf) | lrnr.predict(), lrnr.model(X) | lrnr.model(X) | . ImageDataLoaders.from_name_func? # 함수의 경로 확인 가능 . cnn_learner? . vision_learner? . lrnr.fine_tune? . lrnr.predict? . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/08/IABDL.html",
            "relUrl": "/2022/09/08/IABDL.html",
            "date": " • Sep 8, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "IAB딥러닝 9월 6일",
            "content": "Import . from fastai.vision.all import * . &#45936;&#51060;&#53552; &#51200;&#51109; . path = untar_data(URLs.PETS) / &#39;images&#39; . path . Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images&#39;) . PILImage.create(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;) . files = get_image_files(path) files . (#7390) [Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_102.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_103.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_104.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_105.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_106.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_107.jpg&#39;)...] . files[0] . Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;) . PILImage.create(files[0]) . print(files[2]) PILImage.create(files[2]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_100.jpg . print(files[3]) PILImage.create(files[3]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_101.jpg . print(files[4]) PILImage.create(files[4]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_102.jpg . print(files[5]) PILImage.create(files[5]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_103.jpg . print(files[6]) PILImage.create(files[6]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_104.jpg . print(files[7]) PILImage.create(files[7]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_105.jpg . print(files[8]) PILImage.create(files[8]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_106.jpg . def label_func(fname): if fname[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms = Resize(224)) . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `number_workers` is changed to 0 to avoid getting stuck . dls.show_batch(max_n=16) . &#54617;&#49845; . clsfr = cnn_learner(dls, resnet34, metrics = error_rate) . clsfr.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.150200 | 0.021279 | 0.006766 | 00:35 | . epoch train_loss valid_loss error_rate time . 0 | 0.059970 | 0.032037 | 0.010149 | 00:39 | . &#44592;&#51316; &#45936;&#51060;&#53552;&#47484; &#53685;&#54644; &#51221;&#54869;&#46020; &#52769;&#51221; . files[0] # 고양이 . Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;) . clsfr.predict(files[0]) . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 3.2232e-09])) . files[7] # 고양이 . Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_105.jpg&#39;) . clsfr.predict(files[7]) . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 4.8954e-11])) . clsfr.show_results() . &#50724;&#45813;&#48516;&#49437; . interpreter = Interpretation.from_learner(clsfr) . interpreter.plot_top_losses(16) . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/06/IABDL.html",
            "relUrl": "/2022/09/06/IABDL.html",
            "date": " • Sep 6, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About Me! . 데이터 분석과 인공지능 개발에 관심이 있습니다. | . Contact . Mail | wnsgud6232@naver.com | . | github | https://github.com/Semibro | . | . 경력 . 전북대학교 바이오메디컬공학부(헬스케어정보전공) (2017-03-01 ~ 2023-02-28) . | 전북대학교 IAB융합전공(IoT, AI, Big Data) (2021-03-01 ~ 2023-02-28) . | 전북대학교 의광학연구실(Vision AI) (2022-06-01 ~ ) . | . 수상 . 전북대학교 캡스톤디자인 경진대회 은상(전기/전자/IT) (2022-06-27) | . 프로젝트 . 한이음ICT멘토링 (2022-04-12 ~ 2022-11-30) | . 자격증 . 자동차운전면허 1종보통 (2017-01-25) . | 한국사능력검정시험 2급 (2019-11-08) . | 컴퓨터활용능력 1급 (2021-07-16) . | 정보처리기사 (2022-09-02) . | . 논문 . IoT센서를 활용한 환경을 생각하는 푸드쉐어링 시스템 구현 및 고찰(Sharing food system implementation that considers the environment using IoT sensors) | . 프로그래밍 언어 . Python . | R . | . 관심분야 . 인공지능 (머신러닝, 딥러닝) . | 빅데이터 . | 데이터 분석 . | .",
          "url": "https://semibro.github.io/socket/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://semibro.github.io/socket/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}