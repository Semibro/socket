{
  
    
        "post0": {
            "title": "IAB딥러닝 9월 13일",
            "content": "Import . from fastai.collab import * # 추천시스템 from fastai.text.all import * # 텍스트분석 . import pandas as pd . fastai&#47484; &#51060;&#50857;&#54620; &#48516;&#49437; &#45800;&#44228; . 이미지분석(CNN) 추천시스템 텍스트분석 GAN . 1단계 | ImageDataLoaders | CollabDataLoaders | TextDataLoaders | DataBlock -&gt; dls | . 2단계 | cnn_learner() | collab_learner() | language_model_learner() | GANLearner.wgan() | . 3단계 | lrnr.fine_tune(1) | lrnr.fit() | lrnr.fit() | lrnr.fit() | . 4단계 | lrnr.predict(), lrnr.model(X) | lrnr.model(X) | lrnr.predict() | | . &#52628;&#52380;&#49884;&#49828;&#53596; . 1&#45800;&#44228; . df_view = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_view.csv&#39;) df_view . 커피1 커피2 커피3 커피4 커피5 커피6 커피7 커피8 커피9 커피10 홍차1 홍차2 홍차3 홍차4 홍차5 홍차6 홍차7 홍차8 홍차9 홍차10 . 0 4.149209 | NaN | NaN | 4.078139 | 4.033415 | 4.071871 | NaN | NaN | NaN | NaN | 1.142659 | 1.109452 | NaN | 0.603118 | 1.084308 | NaN | 0.906524 | NaN | NaN | 0.903826 | . 1 4.031811 | NaN | NaN | 3.822704 | NaN | NaN | NaN | 4.071410 | 3.996206 | NaN | NaN | 0.839565 | 1.011315 | NaN | 1.120552 | 0.911340 | NaN | 0.860954 | 0.871482 | NaN | . 2 4.082178 | 4.196436 | NaN | 3.956876 | NaN | NaN | NaN | 4.450931 | 3.972090 | NaN | NaN | NaN | NaN | 0.983838 | NaN | 0.918576 | 1.206796 | 0.913116 | NaN | 0.956194 | . 3 NaN | 4.000621 | 3.895570 | NaN | 3.838781 | 3.967183 | NaN | NaN | NaN | 4.105741 | 1.147554 | NaN | 1.346860 | NaN | 0.614099 | 1.297301 | NaN | NaN | NaN | 1.147545 | . 4 NaN | NaN | NaN | NaN | 3.888208 | NaN | 3.970330 | 3.979490 | NaN | 4.010982 | NaN | 0.920995 | 1.081111 | 0.999345 | NaN | 1.195183 | NaN | 0.818332 | 1.236331 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 95 0.511905 | 1.066144 | NaN | 1.315430 | NaN | 1.285778 | NaN | 0.678400 | 1.023020 | 0.886803 | NaN | 4.055996 | NaN | NaN | 4.156489 | 4.127622 | NaN | NaN | NaN | NaN | . 96 NaN | 1.035022 | NaN | 1.085834 | NaN | 0.812558 | NaN | 1.074543 | NaN | 0.852806 | 3.894772 | NaN | 4.071385 | 3.935935 | NaN | NaN | 3.989815 | NaN | NaN | 4.267142 | . 97 NaN | 1.115511 | NaN | 1.101395 | 0.878614 | NaN | NaN | NaN | 1.329319 | NaN | 4.125190 | NaN | 4.354638 | 3.811209 | 4.144648 | NaN | NaN | 4.116915 | 3.887823 | NaN | . 98 NaN | 0.850794 | NaN | NaN | 0.927884 | 0.669895 | NaN | NaN | 0.665429 | 1.387329 | NaN | NaN | 4.329404 | 4.111706 | 3.960197 | NaN | NaN | NaN | 3.725288 | 4.122072 | . 99 NaN | NaN | 1.413968 | 0.838720 | NaN | NaN | 1.094826 | 0.987888 | NaN | 1.177387 | 3.957383 | 4.136731 | NaN | 4.026915 | NaN | NaN | 4.164773 | 4.104276 | NaN | NaN | . 100 rows × 20 columns . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv&#39;) df . user item rating item_name . 0 1 | 15 | 1.084308 | 홍차5 | . 1 1 | 1 | 4.149209 | 커피1 | . 2 1 | 11 | 1.142659 | 홍차1 | . 3 1 | 5 | 4.033415 | 커피5 | . 4 1 | 4 | 4.078139 | 커피4 | . ... ... | ... | ... | ... | . 995 100 | 18 | 4.104276 | 홍차8 | . 996 100 | 17 | 4.164773 | 홍차7 | . 997 100 | 14 | 4.026915 | 홍차4 | . 998 100 | 4 | 0.838720 | 커피4 | . 999 100 | 7 | 1.094826 | 커피7 | . 1000 rows × 4 columns . df.item.unique(), df.user.unique() # unique()는 데이터에 고유값들이 어떠한 종류들이 있는지 알고 싶을 때 사용하는 함수 . (array([15, 1, 11, 5, 4, 14, 6, 20, 12, 17, 8, 9, 13, 19, 18, 16, 2, 3, 10, 7], dtype=int64), array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100], dtype=int64)) . dls = CollabDataLoaders.from_df(df) #협업 필터링에 적합한 항목 생성 . dls.show_batch() . user item rating . 0 78 | 13 | 4.020114 | . 1 14 | 1 | 4.329083 | . 2 52 | 16 | 4.008471 | . 3 79 | 15 | 4.105639 | . 4 16 | 14 | 0.946549 | . 5 98 | 11 | 4.125190 | . 6 12 | 9 | 4.502565 | . 7 80 | 13 | 3.725410 | . 8 5 | 10 | 4.010983 | . 9 76 | 2 | 0.725603 | . X, y = dls.one_batch() . X[0], y[0] # 60번 유저가 3번 아이템을 먹었을 때, 평점 1.1309 . (tensor([60, 3]), tensor([1.1309])) . 2&#45800;&#44228; . lrnr = collab_learner(dls, y_range = (0, 5)) . lrnr.fit(30) . epoch train_loss valid_loss time . 0 | 0.982962 | 0.960218 | 00:00 | . 1 | 0.854534 | 0.739310 | 00:00 | . 2 | 0.728671 | 0.549827 | 00:00 | . 3 | 0.612306 | 0.398833 | 00:00 | . 4 | 0.508047 | 0.283823 | 00:00 | . 5 | 0.416964 | 0.201994 | 00:00 | . 6 | 0.340235 | 0.146098 | 00:00 | . 7 | 0.277236 | 0.109585 | 00:00 | . 8 | 0.226001 | 0.086219 | 00:00 | . 9 | 0.185047 | 0.071640 | 00:00 | . 10 | 0.152903 | 0.062686 | 00:00 | . 11 | 0.127411 | 0.057081 | 00:00 | . 12 | 0.107212 | 0.053650 | 00:00 | . 13 | 0.091557 | 0.051878 | 00:00 | . 14 | 0.078987 | 0.050590 | 00:00 | . 15 | 0.069260 | 0.050028 | 00:00 | . 16 | 0.061507 | 0.049620 | 00:00 | . 17 | 0.055520 | 0.049438 | 00:00 | . 18 | 0.050674 | 0.049544 | 00:00 | . 19 | 0.046964 | 0.049867 | 00:00 | . 20 | 0.043926 | 0.049945 | 00:00 | . 21 | 0.041574 | 0.050093 | 00:00 | . 22 | 0.039657 | 0.049922 | 00:00 | . 23 | 0.038015 | 0.049928 | 00:00 | . 24 | 0.036744 | 0.049870 | 00:00 | . 25 | 0.035572 | 0.049686 | 00:00 | . 26 | 0.034816 | 0.049891 | 00:00 | . 27 | 0.034127 | 0.049548 | 00:00 | . 28 | 0.033472 | 0.049744 | 00:00 | . 29 | 0.032938 | 0.049897 | 00:00 | . 4&#45800;&#44228; . yhat = lrnr.model(X.to(&quot;cuda:0&quot;)) yhat . tensor([1.0497, 1.0491, 3.8868, 1.0842, 1.0308, 3.9974, 3.9883, 3.9073, 3.8864, 3.9928, 1.0348, 4.0798, 1.0885, 0.9187, 4.1383, 4.0982, 4.1652, 3.8058, 0.9393, 4.0877, 4.0433, 1.0097, 0.8921, 0.8991, 4.1124, 0.9828, 1.0059, 1.0155, 0.9488, 0.9874, 3.9683, 1.0021, 1.0736, 0.9726, 0.9243, 0.9903, 4.0987, 3.9215, 4.0557, 0.8602, 3.8443, 4.0904, 4.0177, 0.9665, 1.0474, 4.0748, 1.1496, 0.9478, 4.0791, 1.1091, 4.0488, 1.0230, 4.0360, 4.0741, 0.7673, 3.9696, 1.0462, 3.9625, 4.1699, 1.0259, 4.0511, 3.9820, 0.9829, 3.9767], device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;) . X.shape . torch.Size([64, 2]) . X[0:1] . tensor([[60, 3]]) . lrnr.model(X[0:1].to(&quot;cuda:0&quot;)) . tensor([1.0497], device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;) . - 새로운 데이터 생성 후 예측 . Xnew = torch.tensor([[1, 2]]) . lrnr.model(Xnew.to(&quot;cuda:0&quot;)) . tensor([3.9995], device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;) . &#53581;&#49828;&#53944;&#48516;&#49437; . 1&#45800;&#44228; . df = pd.DataFrame({&#39;text&#39; : [&#39;h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??&#39;] * 20000}) df . text . 0 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 1 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 2 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 3 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 4 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . ... ... | . 19995 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19996 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19997 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19998 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 19999 h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ?? | . 20000 rows × 1 columns . dls = TextDataLoaders.from_df(df, text_col = &#39;text&#39;, is_lm = True) . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `n_workers` has to be changed to 0 to avoid getting stuck . dls.show_batch() . text text_ . 0 xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o | h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . | . 1 ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l | xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o | . 2 ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l | ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l | . 3 o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e | ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l | . 4 l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h | o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e | . 5 l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos | l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h | . 6 e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? | l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos | . 7 h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? | e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? | . 8 ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o | h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? | . 2&#45800;&#44228; . lrnr = language_model_learner(dls, AWD_LSTM) . . 100.00% [105070592/105067061 00:07&lt;00:00] lrnr.fit(20) . epoch train_loss valid_loss time . 0 | 0.953486 | 0.372985 | 00:13 | . 1 | 0.617590 | 0.249084 | 00:13 | . 2 | 0.475271 | 0.214262 | 00:13 | . 3 | 0.382338 | 0.186492 | 00:13 | . 4 | 0.365782 | 0.170414 | 00:13 | . 5 | 0.324649 | 0.150192 | 00:13 | . 6 | 0.322575 | 0.135068 | 00:13 | . 7 | 0.297149 | 0.119661 | 00:13 | . 8 | 0.268460 | 0.103948 | 00:13 | . 9 | 0.236526 | 0.085444 | 00:13 | . 10 | 0.234326 | 0.071486 | 00:13 | . 11 | 0.202645 | 0.055195 | 00:13 | . 12 | 0.180042 | 0.041449 | 00:13 | . 13 | 0.181329 | 0.032187 | 00:13 | . 14 | 0.160750 | 0.025342 | 00:13 | . 15 | 0.157359 | 0.021769 | 00:13 | . 16 | 0.141533 | 0.017457 | 00:13 | . 17 | 0.133610 | 0.015023 | 00:13 | . 18 | 0.128645 | 0.012770 | 00:13 | . 19 | 0.100870 | 0.011586 | 00:13 | . lrnr.predict(&#39;h &#39;, n_words = 30) . &#39;h e l l o . h e l l o ! h e l l o ? ? h e l l o . h e l l o&#39; . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/13/IABDL.html",
            "relUrl": "/2022/09/13/IABDL.html",
            "date": " • Sep 13, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "IAB딥러닝 9월 8일",
            "content": "Import . from fastai.vision.all import * . &#48373;&#49845; . (1) &#45936;&#51060;&#53552; &#51221;&#47532; . path = untar_data(URLs.PETS) / &#39;images&#39; . fnames = get_image_files(path) . def label_func(fname): if fname[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . dls = ImageDataLoaders.from_name_func(path, fnames, label_func, item_tfms = Resize(224)) . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `number_workers` is changed to 0 to avoid getting stuck . (2) lrnr &#50724;&#48652;&#51229;&#53944; &#49373;&#49457; . lrnr = vision_learner(dls, resnet34, metrics = error_rate) . (3) lrnr &#54617;&#49845; . lrnr.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.150615 | 0.036099 | 0.011502 | 00:35 | . epoch train_loss valid_loss error_rate time . 0 | 0.063639 | 0.034654 | 0.009472 | 00:38 | . (4) lrnr &#50696;&#52769; . lrnr.predict(path.ls()[0]) # 방법1 # lrnr.predict(&#39;2022-09-06-hani03.jpg&#39;) 방법2 # X, y = dls.one_batch() # lrnr.model(X[0 : 1]) 방법3 . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 9.7220e-09])) . &#54532;&#47196;&#44536;&#47000;&#48141; &#44284;&#51221; overview . dls &#50724;&#48652;&#51229;&#53944; &#49373;&#49457; --&gt; lrnr &#50724;&#48652;&#51229;&#53944; &#49373;&#49457; --&gt; lrnr &#54617;&#49845; --&gt; lrnr &#50696;&#52769; . &#48708;&#44368; . 회귀분석(R) 이미지분석(CNN) 추천시스템 . 1단계 | data.frame() | ImageDataLoaders.from_name_func() | CollabDataLoaders.from_df() | . 2단계 | None | cnn_learner() | collab_learner() | . 3단계 | lm(y~x1+x2,df) | lrnr.fine_tune(1) | lrnr.fit() | . 4단계 | predict(ob,newdf) | lrnr.predict(), lrnr.model(X) | lrnr.model(X) | . ImageDataLoaders.from_name_func? # 함수의 경로 확인 가능 . cnn_learner? . vision_learner? . lrnr.fine_tune? . lrnr.predict? . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/08/IABDL.html",
            "relUrl": "/2022/09/08/IABDL.html",
            "date": " • Sep 8, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "IAB딥러닝 9월 6일",
            "content": "Import . from fastai.vision.all import * . &#45936;&#51060;&#53552; &#51200;&#51109; . path = untar_data(URLs.PETS) / &#39;images&#39; . path . Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images&#39;) . PILImage.create(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;) . files = get_image_files(path) files . (#7390) [Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_102.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_103.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_104.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_105.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_106.jpg&#39;),Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_107.jpg&#39;)...] . files[0] . Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;) . PILImage.create(files[0]) . print(files[2]) PILImage.create(files[2]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_100.jpg . print(files[3]) PILImage.create(files[3]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_101.jpg . print(files[4]) PILImage.create(files[4]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_102.jpg . print(files[5]) PILImage.create(files[5]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_103.jpg . print(files[6]) PILImage.create(files[6]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_104.jpg . print(files[7]) PILImage.create(files[7]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_105.jpg . print(files[8]) PILImage.create(files[8]) . C: Users USER .fastai data oxford-iiit-pet images Abyssinian_106.jpg . def label_func(fname): if fname[0].isupper(): return &#39;cat&#39; else: return &#39;dog&#39; . dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms = Resize(224)) . Due to IPython and Windows limitation, python multiprocessing isn&#39;t available now. So `number_workers` is changed to 0 to avoid getting stuck . dls.show_batch(max_n=16) . &#54617;&#49845; . clsfr = cnn_learner(dls, resnet34, metrics = error_rate) . clsfr.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.150200 | 0.021279 | 0.006766 | 00:35 | . epoch train_loss valid_loss error_rate time . 0 | 0.059970 | 0.032037 | 0.010149 | 00:39 | . &#44592;&#51316; &#45936;&#51060;&#53552;&#47484; &#53685;&#54644; &#51221;&#54869;&#46020; &#52769;&#51221; . files[0] # 고양이 . Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg&#39;) . clsfr.predict(files[0]) . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 3.2232e-09])) . files[7] # 고양이 . Path(&#39;C:/Users/USER/.fastai/data/oxford-iiit-pet/images/Abyssinian_105.jpg&#39;) . clsfr.predict(files[7]) . (&#39;cat&#39;, TensorBase(0), TensorBase([1.0000e+00, 4.8954e-11])) . clsfr.show_results() . &#50724;&#45813;&#48516;&#49437; . interpreter = Interpretation.from_learner(clsfr) . interpreter.plot_top_losses(16) . - IAB 딥러닝 수업 자료를 기반으로 공부한 내용입니다. .",
            "url": "https://semibro.github.io/socket/2022/09/06/IABDL.html",
            "relUrl": "/2022/09/06/IABDL.html",
            "date": " • Sep 6, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About Me! . 데이터 분석과 인공지능 개발에 관심이 있습니다. | . Contact . Mail | wnsgud6232@naver.com | . | github | https://github.com/Semibro | . | . 경력 . 전북대학교 바이오메디컬공학부(헬스케어정보전공) (2017-03-01 ~ 2023-02-28) . | 전북대학교 IAB융합전공(IoT, AI, Big Data) (2021-03-01 ~ 2023-02-28) . | 전북대학교 의광학연구실(Vision AI) (2022-06-01 ~ ) . | . 수상 . 전북대학교 캡스톤디자인 경진대회 은상(전기/전자/IT) (2022-06-27) | . 프로젝트 . 한이음ICT멘토링 (2022-04-12 ~ 2022-11-30) | . 자격증 . 자동차운전면허 1종보통 (2017-01-25) . | 한국사능력검정시험 2급 (2019-11-08) . | 컴퓨터활용능력 1급 (2021-07-16) . | 정보처리기사 (2022-09-02) . | . 논문 . IoT센서를 활용한 환경을 생각하는 푸드쉐어링 시스템 구현 및 고찰(Sharing food system implementation that considers the environment using IoT sensors) | . 프로그래밍 언어 . Python . | R . | . 관심분야 . 인공지능 (머신러닝, 딥러닝) . | 빅데이터 . | 데이터 분석 . | .",
          "url": "https://semibro.github.io/socket/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://semibro.github.io/socket/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}